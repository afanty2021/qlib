#!/usr/bin/env python3
"""
å¼ºåˆ¶ä¸‹è½½2000-2025è´¢åŠ¡æ•°æ®

åˆ†é˜¶æ®µä¸‹è½½ï¼š
é˜¶æ®µ1: 2020-2022å¹´
é˜¶æ®µ2: 2015-2019å¹´
é˜¶æ®µ3: 2010-2014å¹´
é˜¶æ®µ4: 2005-2009å¹´
é˜¶æ®µ5: 2000-2004å¹´
é˜¶æ®µ6: 2025å¹´ï¼ˆå·²æœ‰å…¬å‘Šï¼‰
"""

import os
import sys
import time
import pandas as pd
from pathlib import Path
from datetime import datetime

print("\nğŸš€ å¼ºåˆ¶ä¸‹è½½2000-2025è´¢åŠ¡æ•°æ®")
print("="*80)

# æ£€æŸ¥Token
token = os.getenv("TUSHARE_TOKEN")
if not token:
    print("âŒ è¯·è®¾ç½®TUSHARE_TOKENç¯å¢ƒå˜é‡")
    sys.exit(1)

# è¾“å‡ºç›®å½•
output_dir = Path.home() / ".qlib/qlib_data/cn_data/financial_data"
output_dir.mkdir(parents=True, exist_ok=True)

# åˆå§‹åŒ–TuShare
import tushare as ts
pro = ts.pro_api(token)
print(f"âœ… TuShareåˆå§‹åŒ–æˆåŠŸ")

# å®šä¹‰ä¸‹è½½é˜¶æ®µ
download_phases = [
    ("2020-2022", "20200101", "20221231"),
    ("2015-2019", "20150101", "20191231"),
    ("2010-2014", "20100101", "20141231"),
    ("2005-2009", "20050101", "20091231"),
    ("2000-2004", "20000101", "20041231"),
    ("2025æœ€æ–°", "20250101", "20251231"),
]

# è·å–è‚¡ç¥¨åˆ—è¡¨
print("\nğŸ“Š è·å–Aè‚¡åˆ—è¡¨...")
stock_list = pro.stock_basic(
    exchange='',
    list_status='L',
    fields='ts_code,name,list_date'
).sort_values('ts_code')

total_stocks = len(stock_list)
print(f"âœ… Aè‚¡æ€»æ•°: {total_stocks} åª")

# é…ç½®
BATCH_SIZE = 200
DELAY = 0.2

print(f"\nâš™ï¸  ä¸‹è½½é…ç½®:")
print(f"   æ‰¹å¤„ç†å¤§å°: {BATCH_SIZE}")
print(f"   è¯·æ±‚é—´éš”: {DELAY}ç§’")
print(f"   é¢„è®¡æ€»è€—æ—¶: {len(download_phases) * total_stocks * DELAY / 60:.1f} åˆ†é’Ÿ")

# å¼€å§‹åˆ†é˜¶æ®µä¸‹è½½
all_phase_data = []

for phase_name, start_date, end_date in download_phases:
    print("\n" + "="*80)
    print(f"ğŸ“¥ é˜¶æ®µ: {phase_name}")
    print(f"   æ—¶é—´èŒƒå›´: {start_date} - {end_date}")
    print("="*80)

    phase_data = []
    success_count = 0

    for idx in range(total_stocks):
        row = stock_list.iloc[idx]
        ts_code = row['ts_code']
        name = row['name']
        list_date = row['list_date']

        # è·³è¿‡æœªä¸Šå¸‚çš„
        if list_date and pd.notna(list_date):
            if int(str(list_date)[:4]) > int(end_date[:4]):
                continue

        # è¿›åº¦
        progress = (idx + 1) / total_stocks * 100

        try:
            # ä¸‹è½½æ•°æ®
            df = pro.fina_indicator(
                ts_code=ts_code,
                start_date=start_date,
                end_date=end_date
            )

            if df is not None and not df.empty:
                phase_data.append(df)
                success_count += 1
                print(f"[{idx+1}/{total_stocks}] ({progress:.1f}%) {ts_code} âœ… {len(df)}æ¡")
            else:
                print(f"[{idx+1}/{total_stocks}] ({progress:.1f}%) {ts_code} âš ï¸ æ— æ•°æ®")

        except Exception as e:
            print(f"[{idx+1}/{total_stocks}] ({progress:.1f}%) {ts_code} âŒ {str(e)[:30]}")

        # æ¯BATCH_SIZEä¿å­˜ä¸€æ¬¡
        if (idx + 1) % BATCH_SIZE == 0 or (idx + 1) == total_stocks:
            if phase_data:
                # ä¿å­˜é˜¶æ®µæ•°æ®
                phase_df = pd.concat(phase_data, ignore_index=True)
                phase_file = output_dir / f"phase_{phase_name.replace('-', '_').replace(' ', '_')}.csv"
                phase_df.to_csv(phase_file, index=False, encoding='utf-8-sig')
                print(f"  ğŸ’¾ é˜¶æ®µä¿å­˜: {len(phase_df)} æ¡")
                all_phase_data.append(phase_df)
                phase_data = []

        # APIé™æµ
        time.sleep(DELAY)

    print(f"âœ… {phase_name} å®Œæˆ: {success_count}/{total_stocks} åªè‚¡ç¥¨")

# åˆå¹¶æ‰€æœ‰æ•°æ®
print("\n" + "="*80)
print("ğŸ“Š åˆå¹¶æ‰€æœ‰é˜¶æ®µæ•°æ®...")
print("="*80)

# è¯»å–ç°æœ‰æ•°æ®
existing_file = output_dir / "a_share_financial_latest.csv"
if existing_file.exists():
    existing_data = pd.read_csv(existing_file)
    all_phase_data.append(existing_data)
    print(f"âœ… ç°æœ‰æ•°æ®: {len(existing_data)} æ¡")

# è¯»å–é˜¶æ®µæ–‡ä»¶
for phase_name, _, _ in download_phases:
    phase_file = output_dir / f"phase_{phase_name.replace('-', '_').replace(' ', '_')}.csv"
    if phase_file.exists():
        phase_df = pd.read_csv(phase_file)
        all_phase_data.append(phase_df)
        print(f"âœ… {phase_name}: {len(phase_df)} æ¡")

if all_phase_data:
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    print("\næ­£åœ¨åˆå¹¶...")
    combined_df = pd.concat(all_phase_data, ignore_index=True)

    # å»é‡
    print("æ­£åœ¨å»é‡...")
    combined_df['end_date'] = combined_df['end_date'].astype(int)
    combined_df = combined_df.sort_values(['ts_code', 'end_date', 'ann_date'])
    combined_df = combined_df.drop_duplicates(
        subset=['ts_code', 'end_date'],
        keep='last'
    )

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ä¿å­˜å®Œæ•´æ•°æ®
    final_file = output_dir / f"a_share_financial_2000_2025_{timestamp}.csv"
    combined_df.to_csv(final_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… å®Œæ•´æ•°æ®: {final_file}")

    # ä¿å­˜æœ€æ–°ç‰ˆæœ¬
    latest_file = output_dir / "a_share_financial_latest.csv"
    combined_df.to_csv(latest_file, index=False, encoding='utf-8-sig')
    print(f"âœ… æœ€æ–°ç‰ˆæœ¬: {latest_file}")

    # ç»Ÿè®¡
    print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"   æ€»è®°å½•: {len(combined_df):,} æ¡")
    print(f"   è‚¡ç¥¨æ•°: {combined_df['ts_code'].nunique()} åª")
    print(f"   å­—æ®µæ•°: {len(combined_df.columns)} ä¸ª")

    # å¹´ä»½ç»Ÿè®¡
    combined_df['year'] = combined_df['end_date'].astype(str).str[:4]
    year_counts = combined_df['year'].value_counts().sort_index()
    print(f"\n   å¹´ä»½åˆ†å¸ƒ ({len(year_counts)} å¹´):")
    for year in sorted(year_counts.index):
        print(f"     {year}: {year_counts[year]:,} æ¡")

    print(f"\n   æ—¶é—´èŒƒå›´: {year_counts.index.min()} - {year_counts.index.max()}")

print("\nâœ… å…¨éƒ¨å®Œæˆ!")
