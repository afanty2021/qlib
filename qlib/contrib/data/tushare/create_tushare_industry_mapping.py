#!/usr/bin/env python3
"""
TuShareè¡Œä¸šåˆ†ç±»å®Œæ•´æ˜ å°„ç”Ÿæˆå·¥å…·

åŠŸèƒ½ï¼š
1. ä½¿ç”¨TuShareçš„stock_basic.industryå­—æ®µï¼ˆ110ä¸ªäºŒçº§è¡Œä¸šï¼‰
2. åˆ›å»ºè¡Œä¸šåˆ°ä¸€çº§è¡Œä¸šçš„æ˜ å°„å…³ç³»
3. ç”Ÿæˆå®Œæ•´çš„è‚¡ç¥¨-è¡Œä¸šæ˜ å°„è¡¨ï¼ˆè¦†ç›–æ‰€æœ‰5466åªAè‚¡ï¼‰
4. æä¾›ä¾¿æ·çš„æŸ¥è¯¢å’Œä½¿ç”¨æ–¹æ³•

ä½¿ç”¨æ–¹æ³•ï¼š
    export TUSHARE_TOKEN="your_token"
    python create_tushare_industry_mapping.py
"""

import os
import sys
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import time

def create_industry_mapping():
    """åˆ›å»ºTuShareè¡Œä¸šåˆ†ç±»æ˜ å°„"""

    token = os.getenv("TUSHARE_TOKEN")
    if not token:
        print("âŒ è¯·è®¾ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
        return None

    print("ğŸ¯ TuShareè¡Œä¸šåˆ†ç±»å®Œæ•´æ˜ å°„ç”Ÿæˆå·¥å…·")
    print("="*80)

    # åˆå§‹åŒ–TuShare
    import tushare as ts
    pro = ts.pro_api(token)

    # è¾“å‡ºç›®å½•
    output_dir = Path("~/.qlib/qlib_data/cn_data/industry_data").expanduser()
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. å®šä¹‰TuShareè¡Œä¸šåˆ°ä¸€çº§è¡Œä¸šçš„æ˜ å°„
    print("\nğŸ“‹ åŠ è½½è¡Œä¸šæ˜ å°„è§„åˆ™...")

    # åŸºäºTuShareçš„110ä¸ªäºŒçº§è¡Œä¸šï¼Œæ‰‹åŠ¨å®šä¹‰ä¸€çº§è¡Œä¸šæ˜ å°„
    industry_level_mapping = {
        # å†œæ—ç‰§æ¸” (6ä¸ª)
        'ç§æ¤ä¸š': 'å†œæ—ç‰§æ¸”',
        'æ¸”ä¸š': 'å†œæ—ç‰§æ¸”',
        'æ—ä¸š': 'å†œæ—ç‰§æ¸”',
        'å†œä¸šç»¼åˆ': 'å†œæ—ç‰§æ¸”',
        'å†œè¯åŒ–è‚¥': 'å†œæ—ç‰§æ¸”',
        'é¥²æ–™': 'å†œæ—ç‰§æ¸”',
        'ç•œç¦½å…»æ®–': 'å†œæ—ç‰§æ¸”',

        # é‡‡æ˜ (4ä¸ª)
        'ç…¤ç‚­å¼€é‡‡': 'é‡‡æ˜',
        'çŸ³æ²¹å¼€é‡‡': 'é‡‡æ˜',
        'å…¶ä»–é‡‡æ˜': 'é‡‡æ˜',
        'é‡‡æ˜æœåŠ¡': 'é‡‡æ˜',

        # åŒ–å·¥ (7ä¸ª)
        'åŒ–å·¥åŸæ–™': 'åŒ–å·¥',
        'åŒ–å­¦åˆ¶å“': 'åŒ–å·¥',
        'åŒ–çº¤': 'åŒ–å·¥',
        'å¡‘æ–™': 'åŒ–å·¥',
        'æ©¡èƒ¶': 'åŒ–å·¥',
        'æ—¥ç”¨åŒ–å·¥': 'åŒ–å·¥',
        'çŸ³æ²¹åŠ å·¥': 'åŒ–å·¥',

        # é’¢é“ (3ä¸ª)
        'æ™®é’¢': 'é’¢é“',
        'ç‰¹é’¢': 'é’¢é“',
        'é’¢åŠ å·¥': 'é’¢é“',

        # æœ‰è‰²é‡‘å± (7ä¸ª)
        'å·¥ä¸šé‡‘å±': 'æœ‰è‰²é‡‘å±',
        'ç¨€æœ‰é‡‘å±': 'æœ‰è‰²é‡‘å±',
        'å°é‡‘å±': 'æœ‰è‰²é‡‘å±',
        'é»„é‡‘': 'æœ‰è‰²é‡‘å±',
        'é“œ': 'æœ‰è‰²é‡‘å±',
        'é“': 'æœ‰è‰²é‡‘å±',
        'é“…é”Œ': 'æœ‰è‰²é‡‘å±',

        # ç”µå­ (4ä¸ª)
        'å…ƒå™¨ä»¶': 'ç”µå­',
        'åŠå¯¼ä½“': 'ç”µå­',
        'å…‰å­¦å…‰ç”µå­': 'ç”µå­',
        'å…¶ä»–ç”µå­': 'ç”µå­',
        'ITè®¾å¤‡': 'ç”µå­',

        # æ±½è½¦ (3ä¸ª)
        'æ±½è½¦æ•´è½¦': 'æ±½è½¦',
        'æ±½è½¦é…ä»¶': 'æ±½è½¦',
        'æ±½è½¦æœåŠ¡': 'æ±½è½¦',

        # å®¶ç”¨ç”µå™¨ (1ä¸ª)
        'å®¶ç”¨ç”µå™¨': 'å®¶ç”¨ç”µå™¨',

        # é£Ÿå“é¥®æ–™ (4ä¸ª)
        'é£Ÿå“': 'é£Ÿå“é¥®æ–™',
        'ç™½é…’': 'é£Ÿå“é¥®æ–™',
        'è½¯é¥®æ–™': 'é£Ÿå“é¥®æ–™',
        'ä¹³åˆ¶å“': 'é£Ÿå“é¥®æ–™',

        # çººç»‡æœè£… (2ä¸ª)
        'çººç»‡': 'çººç»‡æœè£…',
        'æœé¥°': 'çººç»‡æœè£…',

        # è½»å·¥åˆ¶é€  (4ä¸ª)
        'é€ çº¸': 'è½»å·¥åˆ¶é€ ',
        'åŒ…è£…å°åˆ·': 'è½»å·¥åˆ¶é€ ',
        'å®¶ç”¨è½»å·¥': 'è½»å·¥åˆ¶é€ ',
        'å…¶ä»–è½»å·¥åˆ¶é€ ': 'è½»å·¥åˆ¶é€ ',

        # åŒ»è¯ç”Ÿç‰© (6ä¸ª)
        'åŒ–å­¦åˆ¶è¯': 'åŒ»è¯ç”Ÿç‰©',
        'ä¸­æˆè¯': 'åŒ»è¯ç”Ÿç‰©',
        'ç”Ÿç‰©åˆ¶è¯': 'åŒ»è¯ç”Ÿç‰©',
        'åŒ»ç–—å™¨æ¢°': 'åŒ»è¯ç”Ÿç‰©',
        'åŒ»è¯å•†ä¸š': 'åŒ»è¯ç”Ÿç‰©',
        'åŒ»ç–—ä¿å¥': 'åŒ»è¯ç”Ÿç‰©',

        # å…¬ç”¨äº‹ä¸š (4ä¸ª)
        'ç«åŠ›å‘ç”µ': 'å…¬ç”¨äº‹ä¸š',
        'æ°´åŠ›å‘ç”µ': 'å…¬ç”¨äº‹ä¸š',
        'æ–°å‹ç”µåŠ›': 'å…¬ç”¨äº‹ä¸š',
        'æ°´åŠ¡': 'å…¬ç”¨äº‹ä¸š',
        'ä¾›æ°”ä¾›çƒ­': 'å…¬ç”¨äº‹ä¸š',
        'ç¯å¢ƒä¿æŠ¤': 'å…¬ç”¨äº‹ä¸š',

        # äº¤é€šè¿è¾“ (8ä¸ª)
        'é“è·¯': 'äº¤é€šè¿è¾“',
        'å…¬è·¯': 'äº¤é€šè¿è¾“',
        'æ°´è¿': 'äº¤é€šè¿è¾“',
        'èˆªç©º': 'äº¤é€šè¿è¾“',
        'ç©ºè¿': 'äº¤é€šè¿è¾“',
        'æœºåœº': 'äº¤é€šè¿è¾“',
        'æ¸¯å£': 'äº¤é€šè¿è¾“',
        'èˆªè¿': 'äº¤é€šè¿è¾“',

        # æˆ¿åœ°äº§ (3ä¸ª)
        'å…¨å›½åœ°äº§': 'æˆ¿åœ°äº§',
        'åŒºåŸŸåœ°äº§': 'æˆ¿åœ°äº§',
        'æˆ¿äº§æœåŠ¡': 'æˆ¿åœ°äº§',

        # å•†è´¸é›¶å”® (5ä¸ª)
        'ç™¾è´§': 'å•†è´¸é›¶å”®',
        'è¶…å¸‚è¿é”': 'å•†è´¸é›¶å”®',
        'ä¸€èˆ¬é›¶å”®': 'å•†è´¸é›¶å”®',
        'ä¸“ä¸šé›¶å”®': 'å•†è´¸é›¶å”®',
        'å•†è´¸ä»£ç†': 'å•†è´¸é›¶å”®',
        'å…¶ä»–å•†ä¸š': 'å•†è´¸é›¶å”®',

        # ä¼ åª’ (4ä¸ª)
        'å‡ºç‰ˆä¸š': 'ä¼ åª’',
        'å½±è§†éŸ³åƒ': 'ä¼ åª’',
        'å¹¿å‘ŠåŒ…è£…': 'ä¼ åª’',
        'äº’è”ç½‘': 'ä¼ åª’',
        'æ–‡åŒ–ä¼ æ’­': 'ä¼ åª’',

        # é“¶è¡Œ (1ä¸ª)
        'é“¶è¡Œ': 'é“¶è¡Œ',

        # éé“¶é‡‘è (3ä¸ª)
        'è¯åˆ¸': 'éé“¶é‡‘è',
        'ä¿é™©': 'éé“¶é‡‘è',
        'å¤šå…ƒé‡‘è': 'éé“¶é‡‘è',

        # ç»¼åˆ (1ä¸ª)
        'ç»¼åˆç±»': 'ç»¼åˆ',

        # é€šä¿¡ (2ä¸ª)
        'é€šä¿¡è®¾å¤‡': 'é€šä¿¡',
        'ç”µä¿¡è¿è¥': 'é€šä¿¡',

        # è®¡ç®—æœº (2ä¸ª)
        'è½¯ä»¶æœåŠ¡': 'è®¡ç®—æœº',
        'è®¡ç®—æœºè®¾å¤‡': 'è®¡ç®—æœº',

        # æœºæ¢°è®¾å¤‡ (7ä¸ª)
        'é€šç”¨æœºæ¢°': 'æœºæ¢°è®¾å¤‡',
        'ä¸“ç”¨æœºæ¢°': 'æœºæ¢°è®¾å¤‡',
        'ä»ªå™¨ä»ªè¡¨': 'æœºæ¢°è®¾å¤‡',
        'å·¥ç¨‹æœºæ¢°': 'æœºæ¢°è®¾å¤‡',
        'æœºåºŠåˆ¶é€ ': 'æœºæ¢°è®¾å¤‡',
        'æœºæ¢°åŸºä»¶': 'æœºæ¢°è®¾å¤‡',
        'åŒ–å·¥æœºæ¢°': 'æœºæ¢°è®¾å¤‡',
        'å†œç”¨æœºæ¢°': 'æœºæ¢°è®¾å¤‡',
        'è½»å·¥æœºæ¢°': 'æœºæ¢°è®¾å¤‡',
        'çººç»‡æœºæ¢°': 'æœºæ¢°è®¾å¤‡',
        'ç”µæ°”è®¾å¤‡': 'æœºæ¢°è®¾å¤‡',
        'ç”µå™¨ä»ªè¡¨': 'æœºæ¢°è®¾å¤‡',

        # å»ºç­‘ææ–™ (3ä¸ª)
        'æ°´æ³¥': 'å»ºç­‘ææ–™',
        'ç»ç’ƒ': 'å»ºç­‘ææ–™',
        'å…¶ä»–å»ºæ': 'å»ºç­‘ææ–™',
        'çŸ¿ç‰©åˆ¶å“': 'å»ºç­‘ææ–™',

        # å»ºç­‘è£…é¥° (4ä¸ª)
        'æˆ¿å±‹å»ºè®¾': 'å»ºç­‘è£…é¥°',
        'åŸºç¡€å»ºè®¾': 'å»ºç­‘è£…é¥°',
        'ä¸“ä¸šå·¥ç¨‹': 'å»ºç­‘è£…é¥°',
        'è£…ä¿®è£…é¥°': 'å»ºç­‘è£…é¥°',
        'å›­æ—å·¥ç¨‹': 'å»ºç­‘è£…é¥°',

        # å›½é˜²å†›å·¥ (4ä¸ª)
        'èˆªå¤©è£…å¤‡': 'å›½é˜²å†›å·¥',
        'èˆªç©ºè£…å¤‡': 'å›½é˜²å†›å·¥',
        'åœ°é¢å…µè£…': 'å›½é˜²å†›å·¥',
        'èˆ¹èˆ¶åˆ¶é€ ': 'å›½é˜²å†›å·¥',

        # ç¯ä¿ (1ä¸ª)
        'ç¯ä¿å·¥ç¨‹åŠæœåŠ¡': 'ç¯ä¿',
        'ç¯å¢ƒä¿æŠ¤': 'ç¯ä¿',

        # ç¤¾ä¼šæœåŠ¡ (2ä¸ª)
        'æ™¯ç‚¹': 'ç¤¾ä¼šæœåŠ¡',
        'æ—…æ¸¸æœåŠ¡': 'ç¤¾ä¼šæœåŠ¡',
        'é…’åº—é¤é¥®': 'ç¤¾ä¼šæœåŠ¡',
        'æ•™è‚²': 'ç¤¾ä¼šæœåŠ¡',

        # ç”µåŠ›è®¾å¤‡ (1ä¸ª)
        'ç”µæºè®¾å¤‡': 'ç”µåŠ›è®¾å¤‡',
        'ç”µæœº': 'ç”µåŠ›è®¾å¤‡',
        'ç”µæ°”è‡ªåŠ¨åŒ–è®¾å¤‡': 'ç”µåŠ›è®¾å¤‡',
        'é«˜ä½å‹è®¾å¤‡': 'ç”µåŠ›è®¾å¤‡',

        # ä¿¡æ¯
        'æ–‡æ•™ä¼‘é—²': 'ä¼ åª’',
        'æ—…æ¸¸é…’åº—': 'ç¤¾ä¼šæœåŠ¡',
        'è¿è¾“è®¾å¤‡': 'äº¤è¿è®¾å¤‡',
        'å•†è´¸': 'å•†è´¸é›¶å”®',
    }

    print(f"  âœ… å®šä¹‰äº† {len(industry_level_mapping)} ä¸ªäºŒçº§è¡Œä¸šæ˜ å°„")

    # 2. ä¸‹è½½è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    print("\nğŸ“¥ ä¸‹è½½è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
    stock_basic = pro.stock_basic(
        exchange='',
        list_status='L',
        fields='ts_code,symbol,name,area,industry,market,list_date'
    )

    print(f"  âœ… è·å– {len(stock_basic)} åªè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")

    # 3. åˆ›å»ºè¡Œä¸šæ˜ å°„è¡¨
    print("\nğŸ”— åˆ›å»ºè¡Œä¸šæ˜ å°„è¡¨...")

    # æ·»åŠ ä¸€çº§è¡Œä¸š
    stock_basic['industry_l1'] = stock_basic['industry'].map(industry_level_mapping)

    # ä¸ºæ— æ³•æ˜ å°„çš„è¡Œä¸šè®¾ç½®"å…¶ä»–"
    stock_basic['industry_l1'] = stock_basic['industry_l1'].fillna('å…¶ä»–')

    # ç»Ÿè®¡ä¸€çº§è¡Œä¸šæ•°é‡
    l1_count = stock_basic['industry_l1'].nunique()
    l2_count = stock_basic['industry'].nunique()

    print(f"  âœ… ä¸€çº§è¡Œä¸š: {l1_count}ä¸ª")
    print(f"  âœ… äºŒçº§è¡Œä¸š: {l2_count}ä¸ª")

    # 4. åˆ›å»ºè¡Œä¸šå±‚çº§ç»“æ„
    print("\nğŸ“Š åˆ›å»ºè¡Œä¸šå±‚çº§ç»“æ„...")

    # æŒ‰ä¸€çº§è¡Œä¸šåˆ†ç»„
    industry_structure = {}
    for l1 in sorted(stock_basic['industry_l1'].unique()):
        l2_list = stock_basic[stock_basic['industry_l1'] == l1]['industry'].unique().tolist()
        industry_structure[l1] = l2_list

    # ä¿å­˜è¡Œä¸šå±‚çº§ç»“æ„
    structure_file = output_dir / "tushare_industry_structure.json"
    with open(structure_file, 'w', encoding='utf-8') as f:
        json.dump(industry_structure, f, ensure_ascii=False, indent=2)
    print(f"  âœ… è¡Œä¸šå±‚çº§ç»“æ„å·²ä¿å­˜")

    # 5. ä¿å­˜å®Œæ•´æ˜ å°„è¡¨
    print("\nğŸ’¾ ä¿å­˜æ˜ å°„æ•°æ®...")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # CSVæ ¼å¼
    csv_file = output_dir / f"tushare_industry_mapping_complete_{timestamp}.csv"
    stock_basic[['ts_code', 'symbol', 'name', 'industry', 'industry_l1', 'area', 'market', 'list_date']].to_csv(
        csv_file, index=False, encoding='utf-8-sig'
    )
    print(f"  âœ… {csv_file.name}")

    # æ›´æ–°latesté“¾æ¥
    latest_csv = output_dir / "tushare_industry_mapping__latest.csv"
    import shutil
    shutil.copy2(csv_file, latest_csv)
    print(f"  âœ… å·²æ›´æ–°latesté“¾æ¥")

    # 6. åˆ›å»ºä¾¿æ·æŸ¥è¯¢å­—å…¸
    print("\nğŸ“– åˆ›å»ºæŸ¥è¯¢å­—å…¸...")

    # è‚¡ç¥¨ä»£ç  -> è¡Œä¸šä¿¡æ¯
    stock_to_industry = {}
    for _, row in stock_basic.iterrows():
        stock_to_industry[row['ts_code']] = {
            'industry_l2': row['industry'],
            'industry_l1': row['industry_l1'],
            'symbol': row['symbol'],
            'name': row['name']
        }

    dict_file = output_dir / f"tushare_stock_to_industry_dict_{timestamp}.json"
    with open(dict_file, 'w', encoding='utf-8') as f:
        json.dump(stock_to_industry, f, ensure_ascii=False, indent=2)
    print(f"  âœ… {dict_file.name} ({len(stock_to_industry)}æ¡)")

    # è¡Œä¸š -> è‚¡ç¥¨åˆ—è¡¨å­—å…¸
    industry_to_stocks = {}
    for l1 in stock_basic['industry_l1'].unique():
        l1_stocks = stock_basic[stock_basic['industry_l1'] == l1][['ts_code', 'symbol', 'name']].to_dict('records')
        industry_to_stocks[l1] = l1_stocks

        # åŒæ—¶ä¸ºäºŒçº§è¡Œä¸šåˆ›å»º
        for l2 in stock_basic[stock_basic['industry_l1'] == l1]['industry'].unique():
            l2_stocks = stock_basic[stock_basic['industry'] == l2][['ts_code', 'symbol', 'name']].to_dict('records')
            industry_to_stocks[f"{l1}_{l2}"] = l2_stocks

    industry_dict_file = output_dir / f"tushare_industry_to_stocks_dict_{timestamp}.json"
    with open(industry_dict_file, 'w', encoding='utf-8') as f:
        json.dump(industry_to_stocks, f, ensure_ascii=False, indent=2)
    print(f"  âœ… {Path(industry_dict_file).name}")

    # 7. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    print("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")

    report_lines = []
    report_lines.append("# TuShareè¡Œä¸šåˆ†ç±»å®Œæ•´æ˜ å°„æŠ¥å‘Š")
    report_lines.append(f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"\n## æ•°æ®æ¥æº")
    report_lines.append(f"- TuShare stock_basic.industryå­—æ®µ")
    report_lines.append(f"- è¦†ç›–è‚¡ç¥¨: {len(stock_basic)}åª")

    report_lines.append(f"\n## è¡Œä¸šç»Ÿè®¡")
    report_lines.append(f"- ä¸€çº§è¡Œä¸š: {l1_count}ä¸ª")
    report_lines.append(f"- äºŒçº§è¡Œä¸š: {l2_count}ä¸ª")

    report_lines.append(f"\n## ä¸€çº§è¡Œä¸šåˆ†å¸ƒï¼ˆæŒ‰è‚¡ç¥¨æ•°é‡æ’åºï¼‰")
    l1_dist = stock_basic['industry_l1'].value_counts()
    for idx, (industry, count) in enumerate(l1_dist.items(), 1):
        pct = count / len(stock_basic) * 100
        report_lines.append(f"{idx}. {industry}: {count}åª ({pct:.2f}%)")

    report_lines.append(f"\n## äºŒçº§è¡Œä¸šåˆ†å¸ƒï¼ˆTop 20ï¼‰")
    l2_dist = stock_basic['industry'].value_counts().head(20)
    for idx, (industry, count) in enumerate(l2_dist.items(), 1):
        pct = count / len(stock_basic) * 100
        report_lines.append(f"{idx}. {industry}: {count}åª ({pct:.2f}%)")

    report_lines.append(f"\n## è¡Œä¸šå±‚çº§ç»“æ„")
    for l1 in sorted(industry_structure.keys()):
        l2_list = industry_structure[l1]
        report_lines.append(f"\n### {l1}")
        # è¿‡æ»¤Noneå€¼å¹¶æ’åº
        valid_l2_list = [l2 for l2 in l2_list if l2 is not None]
        for l2 in sorted(valid_l2_list):
            count = len(stock_basic[stock_basic['industry'] == l2])
            report_lines.append(f"  - {l2}: {count}åª")

    # ä¿å­˜æŠ¥å‘Š
    report_file = output_dir / "tushare_industry_mapping_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))
    print(f"  âœ… {Path(report_file).name}")

    # 8. åˆ›å»ºä½¿ç”¨ç¤ºä¾‹ä»£ç 
    print("\nğŸ’» åˆ›å»ºä½¿ç”¨ç¤ºä¾‹...")

    example_code = '''#!/usr/bin/env python3
"""
TuShareè¡Œä¸šåˆ†ç±»ä½¿ç”¨ç¤ºä¾‹
"""

import pandas as pd
import json
from pathlib import Path

# æ•°æ®ç›®å½•
data_dir = Path("~/.qlib/qlib_data/cn_data/industry_data").expanduser()

def example_1_load_mapping():
    """ç¤ºä¾‹1ï¼šåŠ è½½å®Œæ•´æ˜ å°„è¡¨"""
    mapping_df = pd.read_csv(data_dir / "tushare_industry_mapping__latest.csv")

    print("å®Œæ•´æ˜ å°„è¡¨ï¼ˆå‰10è¡Œï¼‰:")
    print(mapping_df[['ts_code', 'name', 'industry', 'industry_l1']].head(10))
    return mapping_df

def example_2_query_stock_industry():
    """ç¤ºä¾‹2ï¼šæŸ¥è¯¢è‚¡ç¥¨æ‰€å±è¡Œä¸š"""
    stock_to_industry_file = list(data_dir.glob("tushare_stock_to_industry_dict_*.json"))[0]

    with open(stock_to_industry_file, 'r', encoding='utf-8') as f:
        stock_to_industry = json.load(f)

    # æŸ¥è¯¢è‚¡ç¥¨è¡Œä¸š
    ts_codes = ['000001.SZ', '000002.SZ', '600000.SH']
    for ts_code in ts_codes:
        if ts_code in stock_to_industry:
            info = stock_to_industry[ts_code]
            print(f"{ts_code} {info['name']}: {info['industry_l1']} - {info['industry_l2']}")

    return stock_to_industry

def example_3_get_industry_stocks():
    """ç¤ºä¾‹3ï¼šè·å–æŸä¸ªè¡Œä¸šçš„æ‰€æœ‰è‚¡ç¥¨"""
    industry_to_stocks_file = list(data_dir.glob("tushare_industry_to_stocks_dict_*.json"))[0]

    with open(industry_to_stocks_file, 'r', encoding='utf-8') as f:
        industry_to_stocks = json.load(f)

    # è·å–"ç”µå­"è¡Œä¸šçš„æ‰€æœ‰è‚¡ç¥¨
    print("\\nç”µå­è¡Œä¸šè‚¡ç¥¨ï¼ˆå‰10åªï¼‰:")
    if 'ç”µå­' in industry_to_stocks:
        stocks = industry_to_stocks['ç”µå­'][:10]
        for stock in stocks:
            print(f"  {stock['ts_code']} {stock['name']}")

    return industry_to_stocks

def example_4_industry_analysis():
    """ç¤ºä¾‹4ï¼šè¡Œä¸šç»Ÿè®¡åˆ†æ"""
    mapping_df = pd.read_csv(data_dir / "tushare_industry_mapping__latest.csv")

    print("\\nä¸€çº§è¡Œä¸šåˆ†å¸ƒ:")
    l1_dist = mapping_df['industry_l1'].value_counts()
    print(l1_dist)

    print("\\näºŒçº§è¡Œä¸šåˆ†å¸ƒï¼ˆTop 10ï¼‰:")
    l2_dist = mapping_df['industry'].value_counts().head(10)
    print(l2_dist)

    # äº¤æ˜“æ‰€åˆ†å¸ƒ
    print("\\näº¤æ˜“æ‰€åˆ†å¸ƒ:")
    mapping_df['exchange'] = mapping_df['ts_code'].str[-2:]
    exchange_dist = mapping_df['exchange'].value_counts()
    print(exchange_dist)

if __name__ == "__main__":
    print("TuShareè¡Œä¸šåˆ†ç±»ä½¿ç”¨ç¤ºä¾‹")
    print("="*80)

    example_1_load_mapping()
    example_2_query_stock_industry()
    example_3_get_industry_stocks()
    example_4_industry_analysis()
'''

    example_file = output_dir / "tushare_industry_usage_examples.py"
    with open(example_file, 'w', encoding='utf-8') as f:
        f.write(example_code)
    print(f"  âœ… {example_file.name}")

    print("\n" + "="*80)
    print("âœ… TuShareè¡Œä¸šåˆ†ç±»å®Œæ•´æ˜ å°„ç”Ÿæˆå®Œæˆï¼")
    print("="*80)

    print(f"\nğŸ“ æ•°æ®æ–‡ä»¶ä½ç½®: {output_dir}")
    print("\nä¸»è¦æ–‡ä»¶:")
    print(f"  - tushare_industry_mapping__latest.csv  # å®Œæ•´æ˜ å°„è¡¨ï¼ˆ5466åªè‚¡ç¥¨ï¼‰")
    print(f"  - tushare_stock_to_industry_dict_*.json  # è‚¡ç¥¨->è¡Œä¸šå­—å…¸")
    print(f"  - tushare_industry_to_stocks_dict_*.json  # è¡Œä¸š->è‚¡ç¥¨åˆ—è¡¨å­—å…¸")
    print(f"  - tushare_industry_structure.json  # è¡Œä¸šå±‚çº§ç»“æ„")
    print(f"  - tushare_industry_mapping_report.md  # è¯¦ç»†æŠ¥å‘Š")
    print(f"  - tushare_industry_usage_examples.py  # ä½¿ç”¨ç¤ºä¾‹ä»£ç ")

    return {
        'mapping_df': stock_basic,
        'stock_to_industry': stock_to_industry,
        'industry_to_stocks': industry_to_stocks,
        'industry_structure': industry_structure
    }

if __name__ == "__main__":
    result = create_industry_mapping()

    if result:
        print("\nğŸ‰ ä»»åŠ¡å®Œæˆï¼æ‰€æœ‰Aè‚¡è‚¡ç¥¨å·²æˆåŠŸæ˜ å°„åˆ°TuShareè¡Œä¸šåˆ†ç±»")
