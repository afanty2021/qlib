#!/usr/bin/env python3
"""
TuShareæ•°æ®æºæ¼”ç¤º

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨TuShareæ•°æ®æºè·å–Aè‚¡æ•°æ®ã€‚
"""

import os
import sys
import pandas as pd
from datetime import datetime

# æ·»åŠ Qlibè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../../../.."))

from qlib.contrib.data.tushare import TuShareConfig, TuShareProvider
from qlib.contrib.data.tushare.utils import (
    TuShareCodeConverter,
    TuShareDataProcessor,
    TuShareDateUtils
)


def demo_basic_usage():
    """æ¼”ç¤ºåŸºæœ¬ä½¿ç”¨"""
    print("ğŸ¯ TuShareæ•°æ®æºåŸºæœ¬ä½¿ç”¨æ¼”ç¤º")
    print("=" * 60)

    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("TUSHARE_TOKEN"):
        print("âš ï¸ è­¦å‘Š: æœªè®¾ç½®TUSHARE_TOKENç¯å¢ƒå˜é‡")
        print("   è¯·è®¾ç½®: export TUSHARE_TOKEN='your_token_here'")
        print("   æ­¤æ¼”ç¤ºå°†è·³è¿‡å®é™…APIè°ƒç”¨")
        return

    # 2. åˆ›å»ºé…ç½®
    config = TuShareConfig.from_env()
    print(f"âœ… é…ç½®åŠ è½½å®Œæˆ")
    print(f"   - Token: {config.token[:10]}...")
    print(f"   - ç¼“å­˜å¯ç”¨: {config.enable_cache}")
    print(f"   - æœ€å¤§é‡è¯•: {config.max_retries}")

    # 3. æ¼”ç¤ºå·¥å…·åŠŸèƒ½
    print("\nğŸ”§ å·¥å…·åŠŸèƒ½æ¼”ç¤º:")

    # ä»£ç è½¬æ¢
    test_codes = ["000001", "600000", "300001"]
    print("\n   è‚¡ç¥¨ä»£ç è½¬æ¢:")
    for code in test_codes:
        tushare_code = TuShareCodeConverter.to_tushare_format(code)
        qlib_code = TuShareCodeConverter.to_qlib_format(tushare_code)
        print(f"     {code} -> {tushare_code} -> {qlib_code}")

    # æ—¥æœŸè½¬æ¢
    test_dates = ["2024-01-01", "2024/01/01", "20240101"]
    print("\n   æ—¥æœŸè½¬æ¢:")
    for date in test_dates:
        tushare_date = TuShareDateUtils.to_tushare_date(date)
        dt_obj = TuShareDateUtils.from_tushare_date(tushare_date)
        print(f"     {date} -> {tushare_date} -> {dt_obj.strftime('%Y-%m-%d')}")

    # 4. æ¨¡æ‹Ÿæ•°æ®å¤„ç†
    print("\nğŸ“Š æ•°æ®å¤„ç†æ¼”ç¤º:")

    # åˆ›å»ºæ¨¡æ‹Ÿäº¤æ˜“æ•°æ®
    sample_data = pd.DataFrame({
        "date": pd.date_range("2024-01-01", periods=10),
        "open": [10.0, 10.2, 10.5, 10.3, 10.8, 11.0, 10.9, 11.2, 11.5, 11.3],
        "high": [10.3, 10.6, 10.8, 10.7, 11.1, 11.3, 11.2, 11.6, 11.8, 11.5],
        "low": [9.8, 10.0, 10.2, 10.0, 10.5, 10.7, 10.6, 10.9, 11.1, 10.9],
        "close": [10.2, 10.4, 10.6, 10.5, 10.9, 11.1, 11.0, 11.4, 11.6, 11.2],
        "volume": [1000, 1200, 900, 1100, 1300, 1500, 1200, 1400, 1600, 1300]
    })

    print(f"   åŸå§‹æ•°æ®: {sample_data.shape}")
    print(f"   æ•°æ®åˆ—: {list(sample_data.columns)}")

    # æ•°æ®éªŒè¯
    is_valid, errors = TuShareDataProcessor.validate_trading_data(sample_data)
    print(f"   æ•°æ®éªŒè¯: {'âœ… é€šè¿‡' if is_valid else 'âŒ å¤±è´¥'}")
    if errors:
        print(f"   é”™è¯¯: {errors}")

    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    indicators_df = TuShareDataProcessor.calculate_technical_indicators(sample_data)
    indicator_cols = [col for col in indicators_df.columns if col.startswith(('ma_', 'rsi', 'macd'))]
    print(f"   æŠ€æœ¯æŒ‡æ ‡: {indicator_cols}")

    if indicator_cols:
        print(f"   æœ€æ–°æŒ‡æ ‡å€¼:")
        latest_values = indicators_df[indicator_cols].iloc[-1]
        for col, val in latest_values.items():
            print(f"     {col}: {val:.4f}")


def demo_config_management():
    """æ¼”ç¤ºé…ç½®ç®¡ç†"""
    print("\nğŸ“‹ é…ç½®ç®¡ç†æ¼”ç¤º")
    print("=" * 60)

    # 1. ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®
    env_config = TuShareConfig.from_env()
    print("ğŸŒ ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®:")
    print(f"   - ç¼“å­˜ç›®å½•: {env_config.cache_dir}")
    print(f"   - ç¼“å­˜TTL: {env_config.cache_ttl}ç§’")

    # 2. ä»å­—å…¸åˆ›å»ºé…ç½®
    dict_config = TuShareConfig.from_dict({
        "token": "demo_token",
        "max_retries": 5,
        "enable_cache": True,
        "rate_limit": 180
    })
    print("\nğŸ“– ä»å­—å…¸åˆ›å»ºé…ç½®:")
    print(f"   - Token: {dict_config.token}")
    print(f"   - æœ€å¤§é‡è¯•: {dict_config.max_retries}")
    print(f"   - é¢‘ç‡é™åˆ¶: {dict_config.rate_limit}")

    # 3. é…ç½®åˆå¹¶
    merged_config = dict_config.merge_with(env_config)
    print("\nğŸ”„ é…ç½®åˆå¹¶:")
    print(f"   - Token: {merged_config.token[:10] if merged_config.token else 'None'}...")
    print(f"   - æœ€å¤§é‡è¯•: {merged_config.max_retries}")
    print(f"   - é¢‘ç‡é™åˆ¶: {merged_config.rate_limit}")

    # 4. ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
    try:
        config_path = "demo_tushare_config.json"
        dict_config.save_to_file(config_path, format="json")
        print(f"\nğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {config_path}")

        # ä»æ–‡ä»¶åŠ è½½é…ç½®
        loaded_config = TuShareConfig.from_file(config_path)
        print(f"âœ… ä»æ–‡ä»¶åŠ è½½é…ç½®æˆåŠŸ: {loaded_config.token}")
    except Exception as e:
        print(f"âš ï¸ é…ç½®æ–‡ä»¶æ“ä½œå¤±è´¥: {e}")


def demo_performance_features():
    """æ¼”ç¤ºæ€§èƒ½ç‰¹æ€§"""
    print("\nâš¡ æ€§èƒ½ç‰¹æ€§æ¼”ç¤º")
    print("=" * 60)

    # 1. ç¼“å­˜ç³»ç»Ÿæ¼”ç¤º
    config = TuShareConfig(enable_cache=True, cache_ttl=3600)

    from qlib.contrib.data.tushare.cache import TuShareCacheManager
    cache_manager = TuShareCacheManager(config)

    # æ¼”ç¤ºç¼“å­˜é”®ç”Ÿæˆ
    keys = []
    for i in range(5):
        key = cache_manager.generate_key("demo", f"symbol_{i}", "20240101", "20240131")
        keys.append(key)

    print(f"ğŸ”‘ ç¼“å­˜é”®ç”Ÿæˆ:")
    for i, key in enumerate(keys):
        print(f"   symbol_{i}: {key[:16]}...")

    # æ¼”ç¤ºç¼“å­˜å­˜å–
    test_data = {"price": 10.5, "volume": 1000, "timestamp": datetime.now()}
    cache_manager.set(keys[0], test_data, level="memory")
    retrieved_data = cache_manager.get(keys[0], level="memory")

    print(f"\nğŸ’¾ ç¼“å­˜å­˜å–:")
    print(f"   åŸå§‹æ•°æ®: {test_data}")
    print(f"   ç¼“å­˜æ•°æ®: {retrieved_data}")
    print(f"   æ•°æ®ä¸€è‡´: {'âœ…' if retrieved_data == test_data else 'âŒ'}")

    # 2. ç¼“å­˜ç»Ÿè®¡
    stats = cache_manager.get_stats()
    print(f"\nğŸ“Š ç¼“å­˜ç»Ÿè®¡:")
    print(f"   - å¯ç”¨çŠ¶æ€: {stats['enabled']}")
    if stats.get("memory"):
        mem_stats = stats["memory"]
        print(f"   - å†…å­˜ç¼“å­˜: {mem_stats['size']} æ¡ç›®")
        print(f"   - ä½¿ç”¨ç‡: {mem_stats['usage_ratio']:.1%}")

    # 3. æ•°æ®å¤„ç†æ€§èƒ½
    print(f"\nğŸš€ æ•°æ®å¤„ç†æ€§èƒ½:")

    # åˆ›å»ºè¾ƒå¤§çš„æµ‹è¯•æ•°æ®é›†
    large_data = pd.DataFrame({
        "date": pd.date_range("2020-01-01", periods=1000),
        "open": [10.0 + i * 0.001 for i in range(1000)],
        "high": [10.2 + i * 0.001 for i in range(1000)],
        "low": [9.8 + i * 0.001 for i in range(1000)],
        "close": [10.1 + i * 0.001 for i in range(1000)],
        "volume": [1000 + i * 10 for i in range(1000)]
    })

    import time

    # æ•°æ®éªŒè¯æ€§èƒ½
    start_time = time.time()
    is_valid, errors = TuShareDataProcessor.validate_trading_data(large_data)
    validation_time = time.time() - start_time
    print(f"   - æ•°æ®éªŒè¯: {validation_time:.4f}ç§’ ({len(large_data)}è¡Œ)")

    # æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æ€§èƒ½
    start_time = time.time()
    indicators_df = TuShareDataProcessor.calculate_technical_indicators(large_data)
    calculation_time = time.time() - start_time
    print(f"   - æŒ‡æ ‡è®¡ç®—: {calculation_time:.4f}ç§’ ({len(indicators_df)}è¡Œ)")

    # æ•°æ®æ¸…æ´—æ€§èƒ½
    start_time = time.time()
    cleaned_data = TuShareDataProcessor.clean_trading_data(large_data)
    cleaning_time = time.time() - start_time
    print(f"   - æ•°æ®æ¸…æ´—: {cleaning_time:.4f}ç§’ ({len(cleaned_data)}è¡Œ)")


def demo_error_handling():
    """æ¼”ç¤ºé”™è¯¯å¤„ç†"""
    print("\nğŸ›¡ï¸ é”™è¯¯å¤„ç†æ¼”ç¤º")
    print("=" * 60)

    from qlib.contrib.data.tushare.exceptions import (
        TuShareConfigError,
        TuShareDataError
    )

    # 1. é…ç½®é”™è¯¯æ¼”ç¤º
    print("1ï¸âƒ£ é…ç½®é”™è¯¯å¤„ç†:")
    try:
        invalid_config = TuShareConfig(
            max_retries=-1,  # æ— æ•ˆå€¼
            log_level="INVALID_LEVEL"  # æ— æ•ˆæ—¥å¿—çº§åˆ«
        )
    except TuShareConfigError as e:
        print(f"   âœ… æˆåŠŸæ•è·é…ç½®é”™è¯¯: {e.error_code}")
        print(f"   è¯¦æƒ…: {len(e.details.get('validation_errors', []))} ä¸ªéªŒè¯é”™è¯¯")

    # 2. æ•°æ®éªŒè¯é”™è¯¯æ¼”ç¤º
    print("\n2ï¸âƒ£ æ•°æ®éªŒè¯é”™è¯¯å¤„ç†:")
    # åˆ›å»ºåŒ…å«æ— æ•ˆæ•°æ®çš„DataFrame
    invalid_data = pd.DataFrame({
        "date": pd.date_range("2024-01-01", periods=3),
        "open": [-1, 0, 10],  # è´Ÿä»·æ ¼å’Œé›¶ä»·æ ¼
        "high": [5, 15, 8],   # high < low
        "low": [8, 5, 15],    # low > high
        "close": [12, 8, 12],  # closeè¶…å‡ºèŒƒå›´
        "volume": [-100, 1000, 500]  # è´Ÿæˆäº¤é‡
    })

    is_valid, errors = TuShareDataProcessor.validate_trading_data(invalid_data)
    if not is_valid:
        print(f"   âœ… æˆåŠŸæ£€æµ‹åˆ° {len(errors)} ä¸ªæ•°æ®é”™è¯¯:")
        for i, error in enumerate(errors, 1):
            print(f"     {i}. {error}")

    # 3. å­—æ®µéªŒè¯é”™è¯¯æ¼”ç¤º
    print("\n3ï¸âƒ£ å­—æ®µéªŒè¯é”™è¯¯å¤„ç†:")
    incomplete_data = pd.DataFrame({
        "date": pd.date_range("2024-01-01", periods=3),
        "close": [10.0, 10.5, 11.0]
        # ç¼ºå°‘å¿…éœ€çš„å­—æ®µ: open, high, low, volume
    })

    try:
        from qlib.contrib.data.tushare.field_mapping import TuShareFieldMapping
        required_fields = ["open", "high", "low", "close", "volume"]
        TuShareFieldMapping.validate_required_fields(incomplete_data, required_fields)
    except TuShareDataError as e:
        print(f"   âœ… æˆåŠŸæ•è·å­—æ®µéªŒè¯é”™è¯¯")
        print(f"   ç¼ºå°‘å­—æ®µ: {e.details.get('missing_fields', [])}")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸª TuShareæ•°æ®æºå®Œæ•´æ¼”ç¤º")
    print("=" * 80)

    try:
        demo_basic_usage()
        demo_config_management()
        demo_performance_features()
        demo_error_handling()

        print("\n" + "=" * 80)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 80)

        print("\nğŸ“š æ›´å¤šä¿¡æ¯:")
        print("   - æ–‡æ¡£: qlib/contrib/data/tushare/README.md")
        print("   - ç¤ºä¾‹: qlib/contrib/data/tushare/example.py")
        print("   - æµ‹è¯•: qlib/contrib/data/tushare/tests/")

    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()