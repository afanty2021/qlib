#!/usr/bin/env python3
"""
è¡Œä¸šé£é™©ç®¡ç†ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è¡Œä¸šæ•°æ®è¿›è¡Œé£é™©æ§åˆ¶å’ŒæŠ•èµ„ç»„åˆç®¡ç†
"""

import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# æ·»åŠ qlibè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent.parent))


# ============================================================
# è¡Œä¸šé£é™©åˆ†æç±»
# ============================================================

class IndustryConcentrationRisk:
    """è¡Œä¸šé›†ä¸­åº¦é£é™©æ§åˆ¶"""

    def __init__(self, max_industry_weight: float = 0.3):
        """
        åˆå§‹åŒ–è¡Œä¸šé›†ä¸­åº¦é£é™©æ§åˆ¶

        Args:
            max_industry_weight: å•ä¸ªè¡Œä¸šæœ€å¤§æƒé‡
        """
        self.max_industry_weight = max_industry_weight

    def calculate_concentration(
        self,
        holdings: pd.DataFrame,
        industry_map: Dict[str, str]
    ) -> pd.DataFrame:
        """
        è®¡ç®—è¡Œä¸šé›†ä¸­åº¦

        Args:
            holdings: æŒä»“æ•°æ® (stock_code, weight)
            industry_map: è‚¡ç¥¨åˆ°è¡Œä¸šçš„æ˜ å°„

        Returns:
            è¡Œä¸šé›†ä¸­åº¦DataFrame
        """
        df = holdings.copy()
        df['industry'] = df['stock_code'].map(industry_map)

        # è®¡ç®—è¡Œä¸šæƒé‡
        industry_weights = df.groupby('industry')['weight'].sum().reset_index()
        industry_weights.columns = ['industry', 'weight']
        industry_weights = industry_weights.sort_values('weight', ascending=False)

        # è®¡ç®—é›†ä¸­åº¦æŒ‡æ ‡
        total_weight = industry_weights['weight'].sum()
        industry_weights['weight_pct'] = industry_weights['weight'] / total_weight

        # ç´¯è®¡æƒé‡ï¼ˆç”¨äºè®¡ç®—åŸºå°¼ç³»æ•°ï¼‰
        industry_weights['cumsum_weight'] = industry_weights['weight_pct'].cumsum()

        # è®¡ç®—HHI (Herfindahl-Hirschman Index)
        hhi = (industry_weights['weight_pct'] ** 2).sum()

        # è®¡ç®—å‰Nå¤§è¡Œä¸šæƒé‡
        top1_weight = industry_weights.iloc[0]['weight_pct'] if len(industry_weights) > 0 else 0
        top3_weight = industry_weights.head(3)['weight_pct'].sum()
        top5_weight = industry_weights.head(5)['weight_pct'].sum()

        metrics = {
            'hhi': hhi,
            'top1_weight': top1_weight,
            'top3_weight': top3_weight,
            'top5_weight': top5_weight
        }

        print(f"âœ… è®¡ç®—è¡Œä¸šé›†ä¸­åº¦:")
        print(f"   HHI: {hhi:.4f}")
        print(f"   å‰1å¤§è¡Œä¸šæƒé‡: {top1_weight:.2%}")
        print(f"   å‰3å¤§è¡Œä¸šæƒé‡: {top3_weight:.2%}")
        print(f"   å‰5å¤§è¡Œä¸šæƒé‡: {top5_weight:.2%}")

        return industry_weights, metrics

    def check_concentration(
        self,
        holdings: pd.DataFrame,
        industry_map: Dict[str, str]
    ) -> Tuple[bool, List[str]]:
        """
        æ£€æŸ¥è¡Œä¸šé›†ä¸­åº¦æ˜¯å¦è¶…é™

        Args:
            holdings: æŒä»“æ•°æ®
            industry_map: è‚¡ç¥¨åˆ°è¡Œä¸šçš„æ˜ å°„

        Returns:
            (æ˜¯å¦é€šè¿‡, è­¦å‘Šä¿¡æ¯åˆ—è¡¨)
        """
        industry_weights, metrics = self.calculate_concentration(holdings, industry_map)

        warnings = []

        # æ£€æŸ¥å•è¡Œä¸šæƒé‡
        overweight_industries = industry_weights[
            industry_weights['weight_pct'] > self.max_industry_weight
        ]

        if len(overweight_industries) > 0:
            passed = False
            for _, row in overweight_industries.iterrows():
                warnings.append(
                    f"âš ï¸ è¡Œä¸š {row['industry']} æƒé‡ {row['weight_pct']:.2%} "
                    f"è¶…è¿‡é™åˆ¶ {self.max_industry_weight:.2%}"
                )
        else:
            passed = True
            warnings.append("âœ… æ‰€æœ‰è¡Œä¸šæƒé‡åœ¨é™åˆ¶èŒƒå›´å†…")

        return passed, warnings

    def adjust_portfolio(
        self,
        holdings: pd.DataFrame,
        industry_map: Dict[str, str],
        method: str = "capping"
    ) -> pd.DataFrame:
        """
        è°ƒæ•´æŠ•èµ„ç»„åˆä»¥æ§åˆ¶è¡Œä¸šé›†ä¸­åº¦

        Args:
            holdings: åŸå§‹æŒä»“
            industry_map: è¡Œä¸šæ˜ å°„
            method: è°ƒæ•´æ–¹æ³• ("capping"å°é¡¶, "equal_weight"ç­‰æƒé‡)

        Returns:
            è°ƒæ•´åçš„æŒä»“
        """
        df = holdings.copy()
        df['industry'] = df['stock_code'].map(industry_map)

        if method == "capping":
            # æ–¹æ³•1: æƒé‡å°é¡¶
            while True:
                industry_weights, _ = self.calculate_concentration(df, industry_map)
                overweight = industry_weights[
                    industry_weights['weight_pct'] > self.max_industry_weight
                ]

                if len(overweight) == 0:
                    break

                # å¯¹è¶…é™è¡Œä¸šæŒ‰æ¯”ä¾‹ç¼©å‡
                for _, row in overweight.iterrows():
                    industry = row['industry']
                    current_weight = row['weight_pct']
                    scale_factor = self.max_industry_weight / current_weight

                    # ç¼©å‡è¯¥è¡Œä¸šæ‰€æœ‰è‚¡ç¥¨æƒé‡
                    mask = df['industry'] == industry
                    df.loc[mask, 'weight'] *= scale_factor

            # é‡æ–°å½’ä¸€åŒ–
            df['weight'] = df['weight'] / df['weight'].sum()

        elif method == "equal_weight":
            # æ–¹æ³•2: è¡Œä¸šå†…ç­‰æƒé‡
            industry_weights = {}
            for industry in df['industry'].unique():
                industry_stocks = df[df['industry'] == industry]
                equal_weight = 1.0 / len(industry_stocks)
                df.loc[df['industry'] == industry, 'weight'] = equal_weight

        print(f"âœ… è°ƒæ•´æŠ•èµ„ç»„åˆï¼Œæ–¹æ³•: {method}")

        return df


class IndustryExposureAnalysis:
    """è¡Œä¸šæš´éœ²åˆ†æ"""

    def __init__(self):
        """åˆå§‹åŒ–è¡Œä¸šæš´éœ²åˆ†æ"""
        pass

    def calculate_exposure(
        self,
        portfolio: pd.DataFrame,
        benchmark: pd.DataFrame,
        industry_map: Dict[str, str]
    ) -> pd.DataFrame:
        """
        è®¡ç®—ç›¸å¯¹åŸºå‡†çš„è¡Œä¸šæš´éœ²

        Args:
            portfolio: æŠ•èµ„ç»„åˆæŒä»“
            benchmark: åŸºå‡†æŒä»“
            industry_map: è¡Œä¸šæ˜ å°„

        Returns:
            è¡Œä¸šæš´éœ²DataFrame
        """
        # è®¡ç®—ç»„åˆè¡Œä¸šæƒé‡
        portfolio_df = portfolio.copy()
        portfolio_df['industry'] = portfolio_df['stock_code'].map(industry_map)
        portfolio_weights = portfolio_df.groupby('industry')['weight'].sum().reset_index()
        portfolio_weights.columns = ['industry', 'portfolio_weight']

        # è®¡ç®—åŸºå‡†è¡Œä¸šæƒé‡
        benchmark_df = benchmark.copy()
        benchmark_df['industry'] = benchmark_df['stock_code'].map(industry_map)
        benchmark_weights = benchmark_df.groupby('industry')['weight'].sum().reset_index()
        benchmark_weights.columns = ['industry', 'benchmark_weight']

        # åˆå¹¶
        exposure = pd.merge(
            portfolio_weights,
            benchmark_weights,
            on='industry',
            how='outer'
        ).fillna(0)

        # è®¡ç®—è¶…ä½é…
        exposure['active_weight'] = exposure['portfolio_weight'] - exposure['benchmark_weight']

        # æŒ‰è¶…é…æ’åº
        exposure = exposure.sort_values('active_weight', ascending=False)

        print(f"âœ… è®¡ç®—è¡Œä¸šæš´éœ²: {len(exposure)} ä¸ªè¡Œä¸š")

        return exposure

    def analyze_risk_factors(
        self,
        exposure: pd.DataFrame
    ) -> Dict[str, float]:
        """
        åˆ†æé£é™©å› å­

        Args:
            exposure: è¡Œä¸šæš´éœ²æ•°æ®

        Returns:
            é£é™©æŒ‡æ ‡å­—å…¸
        """
        # ç»å¯¹åç¦»åº¦
        abs_deviation = exposure['active_weight'].abs().sum()

        # è·Ÿè¸ªè¯¯å·®ï¼ˆç®€åŒ–ç‰ˆï¼‰
        tracking_error = np.sqrt((exposure['active_weight'] ** 2).sum())

        # æœ€å¤§è¶…é…
        max_overweight = exposure['active_weight'].max()

        # æœ€å¤§ä½é…
        max_underweight = exposure['active_weight'].min()

        # è¶…é…è¡Œä¸šæ•°
        overweight_count = len(exposure[exposure['active_weight'] > 0])

        # ä½é…è¡Œä¸šæ•°
        underweight_count = len(exposure[exposure['active_weight'] < 0])

        risk_metrics = {
            'absolute_deviation': abs_deviation,
            'tracking_error': tracking_error,
            'max_overweight': max_overweight,
            'max_underweight': max_underweight,
            'overweight_count': overweight_count,
            'underweight_count': underweight_count
        }

        print(f"âœ… åˆ†æé£é™©å› å­:")
        for key, value in risk_metrics.items():
            print(f"   {key}: {value:.4f}")

        return risk_metrics


class IndustryStressTest:
    """è¡Œä¸šå‹åŠ›æµ‹è¯•"""

    def __init__(self):
        """åˆå§‹åŒ–å‹åŠ›æµ‹è¯•"""
        pass

    def scenario_analysis(
        self,
        holdings: pd.DataFrame,
        industry_map: Dict[str, str],
        scenarios: Dict[str, Dict[str, float]]
    ) -> pd.DataFrame:
        """
        æƒ…æ™¯åˆ†æ

        Args:
            holdings: æŒä»“æ•°æ®
            industry_map: è¡Œä¸šæ˜ å°„
            scenarios: æƒ…æ™¯å®šä¹‰
                ä¾‹å¦‚: {
                    "ç‰›å¸‚": {"é“¶è¡Œ": 0.10, "åœ°äº§": 0.15},
                    "ç†Šå¸‚": {"é“¶è¡Œ": -0.08, "åœ°äº§": -0.12}
                }

        Returns:
            æƒ…æ™¯åˆ†æç»“æœ
        """
        df = holdings.copy()
        df['industry'] = df['stock_code'].map(industry_map)

        results = []

        for scenario_name, scenario_shocks in scenarios.items():
            # è®¡ç®—ç»„åˆåœ¨æƒ…æ™¯ä¸‹çš„æ”¶ç›Š
            scenario_return = 0.0

            for industry, shock in scenario_shocks.items():
                industry_weight = df[df['industry'] == industry]['weight'].sum()
                scenario_return += industry_weight * shock

            results.append({
                'scenario': scenario_name,
                'return': scenario_return
            })

        result_df = pd.DataFrame(results)

        print(f"âœ… æƒ…æ™¯åˆ†æ: {len(scenarios)} ä¸ªæƒ…æ™¯")

        return result_df

    def calculate_var(
        self,
        holdings: pd.DataFrame,
        industry_returns: pd.DataFrame,
        confidence: float = 0.95
    ) -> float:
        """
        è®¡ç®—è¡Œä¸šVaR (Value at Risk)

        Args:
            holdings: æŒä»“æ•°æ®
            industry_returns: è¡Œä¸šæ”¶ç›Šç‡å†å²æ•°æ®
            confidence: ç½®ä¿¡æ°´å¹³

        Returns:
            VaRå€¼
        """
        df = holdings.copy()
        df['industry'] = df['stock_code'].map(industry_map)

        # è®¡ç®—ç»„åˆåœ¨å„è¡Œä¸šçš„æƒé‡
        industry_weights = df.groupby('industry')['weight'].sum().reset_index()
        industry_weights.columns = ['industry', 'weight']

        # è®¡ç®—å†å²æ”¶ç›Šç‡
        portfolio_returns = []

        for _, row in industry_returns.iterrows():
            daily_return = 0.0
            for _, industry_w in industry_weights.iterrows():
                industry = industry_w['industry']
                weight = industry_w['weight']
                if industry in row:
                    daily_return += weight * row[industry]
            portfolio_returns.append(daily_return)

        portfolio_returns = pd.Series(portfolio_returns)

        # è®¡ç®—VaR
        var = portfolio_returns.quantile(1 - confidence)

        print(f"âœ… è®¡ç®— VaR ({confidence*100:.0f}%): {var:.2%}")

        return var


# ============================================================
# ç¤ºä¾‹å‡½æ•°
# ============================================================

def generate_sample_portfolio() -> Tuple[pd.DataFrame, Dict[str, str]]:
    """ç”Ÿæˆç¤ºä¾‹æŠ•èµ„ç»„åˆ"""
    print("ğŸ“Š ç”Ÿæˆç¤ºä¾‹æŠ•èµ„ç»„åˆ...")

    # ç¤ºä¾‹è‚¡ç¥¨
    stock_list = [f"{i:06d}.SZ" for i in range(1, 51)]

    # ç”ŸæˆæŒä»“
    holdings = []
    remaining_weight = 1.0

    for i, stock in enumerate(stock_list):
        weight = remaining_weight * (0.5 ** (i + 1))  # é€’å‡æƒé‡
        holdings.append({
            'stock_code': stock,
            'weight': weight
        })
        remaining_weight -= weight
        if remaining_weight <= 0:
            break

    holdings_df = pd.DataFrame(holdings)

    # å½’ä¸€åŒ–
    holdings_df['weight'] = holdings_df['weight'] / holdings_df['weight'].sum()

    # è¡Œä¸šæ˜ å°„
    industries = ['é“¶è¡Œ', 'åœ°äº§', 'åŒ»è¯', 'ç§‘æŠ€', 'æ¶ˆè´¹', 'åˆ¶é€ ', 'é‡‘è', 'èƒ½æº']
    industry_map = {stock: np.random.choice(industries) for stock in stock_list}

    print(f"   ç”Ÿæˆ {len(holdings_df)} åªè‚¡ç¥¨çš„ç»„åˆ")

    return holdings_df, industry_map


def example_1_concentration_check():
    """ç¤ºä¾‹1: è¡Œä¸šé›†ä¸­åº¦æ£€æŸ¥"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹1: è¡Œä¸šé›†ä¸­åº¦æ£€æŸ¥")
    print("="*80)

    # ç”Ÿæˆç¤ºä¾‹ç»„åˆ
    holdings, industry_map = generate_sample_portfolio()

    # åˆ›å»ºé£é™©æ§åˆ¶å¯¹è±¡
    risk_control = IndustryConcentrationRisk(max_industry_weight=0.3)

    # æ£€æŸ¥é›†ä¸­åº¦
    print("\nğŸ“Š æ£€æŸ¥è¡Œä¸šé›†ä¸­åº¦...")
    passed, warnings = risk_control.check_concentration(holdings, industry_map)

    for warning in warnings:
        print(warning)

    # æ˜¾ç¤ºè¡Œä¸šæƒé‡
    industry_weights, metrics = risk_control.calculate_concentration(holdings, industry_map)
    print("\nè¡Œä¸šæƒé‡åˆ†å¸ƒ:")
    print(industry_weights.head(10).to_string(index=False))


def example_2_portfolio_adjustment():
    """ç¤ºä¾‹2: æŠ•èµ„ç»„åˆè°ƒæ•´"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹2: æŠ•èµ„ç»„åˆè°ƒæ•´")
    print("="*80)

    # ç”Ÿæˆç¤ºä¾‹ç»„åˆ
    holdings, industry_map = generate_sample_portfolio()

    # åˆ›å»ºé£é™©æ§åˆ¶å¯¹è±¡
    risk_control = IndustryConcentrationRisk(max_industry_weight=0.2)

    # è°ƒæ•´ç»„åˆ
    print("\nğŸ“Š è°ƒæ•´æŠ•èµ„ç»„åˆ...")
    adjusted_holdings = risk_control.adjust_portfolio(
        holdings,
        industry_map,
        method="capping"
    )

    # å†æ¬¡æ£€æŸ¥
    print("\nğŸ“Š è°ƒæ•´åæ£€æŸ¥...")
    passed, warnings = risk_control.check_concentration(adjusted_holdings, industry_map)

    for warning in warnings:
        print(warning)


def example_3_exposure_analysis():
    """ç¤ºä¾‹3: è¡Œä¸šæš´éœ²åˆ†æ"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹3: è¡Œä¸šæš´éœ²åˆ†æ")
    print("="*80)

    # ç”Ÿæˆç»„åˆå’ŒåŸºå‡†
    portfolio, industry_map = generate_sample_portfolio()
    benchmark, _ = generate_sample_portfolio()

    # åˆ›å»ºæš´éœ²åˆ†æå¯¹è±¡
    exposure_analysis = IndustryExposureAnalysis()

    # è®¡ç®—æš´éœ²
    print("\nğŸ“Š è®¡ç®—ç›¸å¯¹åŸºå‡†çš„è¡Œä¸šæš´éœ²...")
    exposure = exposure_analysis.calculate_exposure(portfolio, benchmark, industry_map)

    print("\nè¡Œä¸šæš´éœ² (å‰10ä¸ª):")
    print(exposure.head(10).to_string(index=False))

    # åˆ†æé£é™©å› å­
    print("\nğŸ“Š åˆ†æé£é™©å› å­...")
    risk_metrics = exposure_analysis.analyze_risk_factors(exposure)


def example_4_stress_test():
    """ç¤ºä¾‹4: å‹åŠ›æµ‹è¯•"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹4: å‹åŠ›æµ‹è¯•")
    print("="*80)

    # ç”Ÿæˆç»„åˆ
    holdings, industry_map = generate_sample_portfolio()

    # åˆ›å»ºå‹åŠ›æµ‹è¯•å¯¹è±¡
    stress_test = IndustryStressTest()

    # å®šä¹‰æƒ…æ™¯
    scenarios = {
        "ç‰›å¸‚": {
            "é“¶è¡Œ": 0.10, "åœ°äº§": 0.15, "ç§‘æŠ€": 0.20,
            "åŒ»è¯": 0.08, "æ¶ˆè´¹": 0.12, "åˆ¶é€ ": 0.10
        },
        "ç†Šå¸‚": {
            "é“¶è¡Œ": -0.08, "åœ°äº§": -0.12, "ç§‘æŠ€": -0.15,
            "åŒ»è¯": -0.05, "æ¶ˆè´¹": -0.07, "åˆ¶é€ ": -0.08
        },
        "è¡Œä¸šè½®åŠ¨(ç§‘æŠ€å¼º)": {
            "ç§‘æŠ€": 0.25, "é“¶è¡Œ": -0.05, "åœ°äº§": -0.05,
            "åŒ»è¯": 0.10, "æ¶ˆè´¹": 0.05
        }
    }

    # æ‰§è¡Œæƒ…æ™¯åˆ†æ
    print("\nğŸ“Š æ‰§è¡Œæƒ…æ™¯åˆ†æ...")
    results = stress_test.scenario_analysis(holdings, industry_map, scenarios)

    print("\næƒ…æ™¯åˆ†æç»“æœ:")
    print(results.to_string(index=False))


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\nğŸ¯ è¡Œä¸šé£é™©ç®¡ç†ç¤ºä¾‹")
    print("="*80)
    print("æœ¬ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è¡Œä¸šæ•°æ®è¿›è¡Œé£é™©æ§åˆ¶")
    print("="*80)

    try:
        # ç¤ºä¾‹1: è¡Œä¸šé›†ä¸­åº¦æ£€æŸ¥
        example_1_concentration_check()

        # ç¤ºä¾‹2: æŠ•èµ„ç»„åˆè°ƒæ•´
        example_2_portfolio_adjustment()

        # ç¤ºä¾‹3: è¡Œä¸šæš´éœ²åˆ†æ
        example_3_exposure_analysis()

        # ç¤ºä¾‹4: å‹åŠ›æµ‹è¯•
        example_4_stress_test()

        print("\n" + "="*80)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("="*80)

        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("   1. æ ¹æ®å®é™…é£é™©åå¥½è®¾ç½®é›†ä¸­åº¦é™åˆ¶")
        print("   2. å®šæœŸç›‘æ§è¡Œä¸šæš´éœ²åº¦")
        print("   3. è®¾è®¡å¤šç§å‹åŠ›æƒ…æ™¯è¿›è¡Œæµ‹è¯•")
        print("   4. ç»“åˆå¸‚åœºç¯å¢ƒè°ƒæ•´é£é™©æ§åˆ¶å‚æ•°")

        print("\nğŸ“ é£é™©ç®¡ç†æœ€ä½³å®è·µ:")
        print("   1. è®¾ç½®å•è¡Œä¸šæƒé‡ä¸Šé™ (å¦‚30%)")
        print("   2. æ§åˆ¶å‰Nå¤§è¡Œä¸šæ€»æƒé‡")
        print("   3. å®šæœŸè¿›è¡Œå‹åŠ›æµ‹è¯•")
        print("   4. ç›‘æ§ç›¸å¯¹åŸºå‡†çš„åç¦»åº¦")
        print("   5. å»ºç«‹é£é™©é¢„è­¦æœºåˆ¶")

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
