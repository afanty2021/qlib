#!/usr/bin/env python3
"""
ä¸ªè‚¡-ç”³ä¸‡äºŒçº§è¡Œä¸šå®Œæ•´æ˜ å°„ä¸‹è½½å·¥å…· V2

ä½¿ç”¨index_member APIåå‘æŸ¥è¯¢ï¼Œè·å–å®Œæ•´çš„ç”³ä¸‡äºŒçº§è¡Œä¸šåˆ†ç±»æ˜ å°„

ä½¿ç”¨æ–¹æ³•ï¼š
    export TUSHARE_TOKEN="your_token"
    python download_stock_industry_mapping_v2.py
"""

import os
import sys
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
import time

def download_stock_industry_mapping():
    """ä¸‹è½½å®Œæ•´çš„ä¸ªè‚¡-ç”³ä¸‡äºŒçº§è¡Œä¸šæ˜ å°„"""

    token = os.getenv("TUSHARE_TOKEN")
    if not token:
        print("âŒ è¯·è®¾ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
        return

    print("ğŸ¯ ä¸ªè‚¡-ç”³ä¸‡äºŒçº§è¡Œä¸šå®Œæ•´æ˜ å°„ä¸‹è½½å·¥å…· V2")
    print("="*80)

    # åˆå§‹åŒ–TuShare
    import tushare as ts
    pro = ts.pro_api(token)

    # è¾“å‡ºç›®å½•
    output_dir = Path("~/.qlib/qlib_data/cn_data/industry_data").expanduser()
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. åŠ è½½ç”³ä¸‡äºŒçº§è¡Œä¸šåˆ—è¡¨
    print("\nğŸ“¥ åŠ è½½ç”³ä¸‡äºŒçº§è¡Œä¸šåˆ—è¡¨...")
    # å°è¯•å¤šä¸ªå¯èƒ½çš„æ–‡ä»¶å
    industry_l2_file = None
    for filename in [
        "industry_SW2021_L2__latest.csv",
        "industry_SW2021_L2_20251229_112014.csv",
        "industry__latest.csv"
    ]:
        candidate = output_dir / filename
        if candidate.exists():
            industry_l2_file = candidate
            break

    if not industry_l2_file:
        print(f"âŒ è¡Œä¸šåˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨")
        print("å¯ç”¨çš„æ–‡ä»¶:")
        for f in output_dir.glob("industry_SW*L2*"):
            print(f"  - {f.name}")
        return

    industry_l2 = pd.read_csv(industry_l2_file)
    # ç­›é€‰L2çº§åˆ«çš„è¡Œä¸š
    if 'level' in industry_l2.columns:
        industry_l2 = industry_l2[industry_l2['level'] == 'L2'].copy()
    # ç¡®ä¿æœ‰industry_codeåˆ—
    if 'industry_code' not in industry_l2.columns:
        industry_l2['industry_code'] = ''
    print(f"âœ… åŠ è½½ {len(industry_l2)} ä¸ªç”³ä¸‡äºŒçº§è¡Œä¸š")

    # 2. è·å–æ¯ä¸ªè¡Œä¸šçš„æˆåˆ†è‚¡
    print("\nğŸ“¥ å¼€å§‹è·å–è¡Œä¸šæˆåˆ†è‚¡...")
    print("="*80)

    all_mappings = []
    total = len(industry_l2)

    for idx, row in industry_l2.iterrows():
        index_code = row['index_code']
        industry_name = row['industry_name']
        industry_code = row.get('industry_code', '')

        print(f"\n[{idx+1}/{total}] {industry_name} ({index_code})...", end=" ", flush=True)

        try:
            # è·å–è¯¥è¡Œä¸šæŒ‡æ•°çš„æˆåˆ†è‚¡
            members = pro.index_member(index_code=index_code)

            if members is not None and not members.empty:
                # åªä¿ç•™å½“å‰æœ‰æ•ˆçš„æˆåˆ†è‚¡
                valid_members = members[
                    (members['is_new'] == 'Y') |
                    (members['out_date'].isna())
                ]

                for _, member in valid_members.iterrows():
                    all_mappings.append({
                        'ts_code': member['con_code'],
                        'index_code': index_code,
                        'industry_code': industry_code,
                        'industry_name': industry_name,
                        'in_date': member.get('in_date', ''),
                        'is_new': member.get('is_new', '')
                    })

                print(f"âœ… {len(valid_members)}åª")
            else:
                print("âš ï¸ æ— æ•°æ®")

            # é¿å…APIé¢‘ç‡é™åˆ¶
            time.sleep(0.21)

        except Exception as e:
            print(f"âŒ {str(e)}")
            continue

    if not all_mappings:
        print("\nâŒ æœªè·å–åˆ°ä»»ä½•æ˜ å°„æ•°æ®")
        return

    # 3. æ„å»ºæ˜ å°„è¡¨
    print("\nğŸ“Š æ„å»ºæ˜ å°„è¡¨...")
    mapping_df = pd.DataFrame(all_mappings)

    print(f"âœ… æ€»æ˜ å°„è®°å½•: {len(mapping_df)}")
    print(f"   è¦†ç›–è‚¡ç¥¨: {mapping_df['ts_code'].nunique()} åª")
    print(f"   è¦†ç›–è¡Œä¸š: {mapping_df['industry_name'].nunique()} ä¸ª")

    # 4. æ·»åŠ è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    print("\nğŸ“Š æ·»åŠ è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
    stock_basic = pro.stock_basic(
        exchange='',
        list_status='L',
        fields='ts_code,symbol,name,area,market,list_date'
    )

    # åˆå¹¶åŸºæœ¬ä¿¡æ¯
    mapping_df = mapping_df.merge(
        stock_basic[['ts_code', 'symbol', 'name']],
        on='ts_code',
        how='left'
    )

    # æ·»åŠ æ›´æ–°æ—¶é—´
    mapping_df['update_date'] = datetime.now().strftime('%Y-%m-%d')

    # é‡æ–°æ’åºåˆ—
    mapping_df = mapping_df[[
        'ts_code', 'symbol', 'name', 'industry_code', 'industry_name',
        'index_code', 'in_date', 'is_new', 'update_date'
    ]]

    # 5. ä¿å­˜æ•°æ®
    print("\nğŸ’¾ ä¿å­˜æ•°æ®...")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # CSVæ ¼å¼
    csv_file = output_dir / f"stock_industry_mapping_SW2021_complete_{timestamp}.csv"
    mapping_df.to_csv(csv_file, index=False, encoding='utf-8-sig')
    print(f"   âœ… {csv_file.name}")

    # æ›´æ–°latesté“¾æ¥
    latest_csv = output_dir / "stock_industry_mapping_SW2021__latest.csv"
    import shutil
    shutil.copy2(csv_file, latest_csv)
    print(f"   âœ… æ›´æ–°latesté“¾æ¥")

    # JSONå­—å…¸æ ¼å¼
    json_dict_file = output_dir / f"stock_industry_dict_SW2021_complete_{timestamp}.json"
    stock_to_industry = {}
    for _, row in mapping_df.iterrows():
        stock_to_industry[row['ts_code']] = {
            'industry_code': row['industry_code'],
            'industry_name': row['industry_name'],
            'symbol': row['symbol'],
            'name': row['name']
        }

    with open(json_dict_file, 'w', encoding='utf-8') as f:
        json.dump(stock_to_industry, f, ensure_ascii=False, indent=2)
    print(f"   âœ… {Path(json_dict_file).name} ({len(stock_to_industry)}æ¡)")

    # 6. ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“Š ç”ŸæˆæŠ¥å‘Š...")
    report_lines = []
    report_lines.append("# ä¸ªè‚¡-ç”³ä¸‡äºŒçº§è¡Œä¸šå®Œæ•´æ˜ å°„æŠ¥å‘Š")
    report_lines.append(f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"\n## æ•°æ®ç»Ÿè®¡")
    report_lines.append(f"- æ€»æ˜ å°„è®°å½•: {len(mapping_df)}")
    report_lines.append(f"- è¦†ç›–è‚¡ç¥¨: {mapping_df['ts_code'].nunique()} åª")
    report_lines.append(f"- è¦†ç›–è¡Œä¸š: {mapping_df['industry_name'].nunique()} ä¸ª")

    report_lines.append(f"\n## è¡Œä¸šåˆ†å¸ƒï¼ˆTop 20ï¼‰")
    industry_dist = mapping_df['industry_name'].value_counts().head(20)
    for industry, count in industry_dist.items():
        pct = count / len(mapping_df) * 100
        report_lines.append(f"{industry_dist.index.get(industry, '')+1}. {industry}: {count}åª ({pct:.2f}%)")

    report_file = output_dir / "stock_industry_mapping_complete_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))
    print(f"   âœ… {Path(report_file).name}")

    print("\n" + "="*80)
    print("âœ… ä¸‹è½½å®Œæˆï¼")
    print("="*80)

    print(f"\næ•°æ®æ–‡ä»¶ä½ç½®: {output_dir}")
    print("\nä¸»è¦æ–‡ä»¶:")
    print(f"  - {csv_file.name}")
    print(f"  - {Path(json_dict_file).name}")
    print(f"  - {Path(report_file).name}")

    return mapping_df

if __name__ == "__main__":
    download_stock_industry_mapping()
