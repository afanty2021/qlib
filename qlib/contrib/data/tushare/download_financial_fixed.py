#!/usr/bin/env python3
"""
ä¸‹è½½Aè‚¡è´¢åŠ¡æ•°æ®ï¼ˆå·²ä¿®å¤ç‰ˆæœ¬ï¼‰

ä¿®å¤é—®é¢˜ï¼š
1. ç§»é™¤äº†é”™è¯¯çš„"è·³è¿‡æœªä¸Šå¸‚è‚¡ç¥¨"é€»è¾‘
2. TuShare APIä¼šè‡ªåŠ¨è¿”å›è¯¥è‚¡ç¥¨ä¸Šå¸‚åçš„æ•°æ®
3. ç¡®ä¿æ‰€æœ‰5466åªè‚¡ç¥¨éƒ½èƒ½æ­£ç¡®ä¸‹è½½

ä½¿ç”¨æ–¹æ³•ï¼š
    export TUSHARE_TOKEN="your_token"
    python3 download_financial_fixed.py
"""

import os
import sys
import time
import json
import pandas as pd
from pathlib import Path
from datetime import datetime

def download_financial_data_fixed():
    """ä¿®å¤åçš„è´¢åŠ¡æ•°æ®ä¸‹è½½å™¨"""

    print("\nğŸš€ Aè‚¡è´¢åŠ¡æ•°æ®ä¸‹è½½å™¨ï¼ˆä¿®å¤ç‰ˆï¼‰")
    print("="*80)

    # æ£€æŸ¥Token
    token = os.getenv("TUSHARE_TOKEN")
    if not token:
        print("âŒ è¯·è®¾ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
        sys.exit(1)

    # è¾“å‡ºç›®å½•
    output_dir = Path.home() / ".qlib/qlib_data/cn_data/financial_data"
    output_dir.mkdir(parents=True, exist_ok=True)

    # åˆå§‹åŒ–TuShare
    import tushare as ts
    pro = ts.pro_api(token)
    print(f"âœ… TuShareåˆå§‹åŒ–æˆåŠŸ")

    # è·å–è‚¡ç¥¨åˆ—è¡¨
    print("\nğŸ“Š è·å–Aè‚¡åˆ—è¡¨...")
    stock_list = pro.stock_basic(
        exchange='',
        list_status='L',
        fields='ts_code,name,list_date'
    ).sort_values('ts_code')

    total_stocks = len(stock_list)
    print(f"âœ… Aè‚¡æ€»æ•°: {total_stocks} åª")

    # é…ç½®ä¸‹è½½å‚æ•°
    START_DATE = "20000101"  # ä»2000å¹´å¼€å§‹
    END_DATE = datetime.now().strftime("%Y%m%d")
    BATCH_SIZE = 100
    DELAY = 0.3

    print(f"\nâš™ï¸  ä¸‹è½½é…ç½®:")
    print(f"   æ—¶é—´èŒƒå›´: {START_DATE} - {END_DATE}")
    print(f"   æ‰¹å¤„ç†å¤§å°: {BATCH_SIZE}")
    print(f"   è¯·æ±‚é—´éš”: {DELAY}ç§’")
    print(f"   é¢„è®¡è€—æ—¶: {total_stocks * DELAY / 60:.1f} åˆ†é’Ÿ")
    print("="*80)

    # çŠ¶æ€æ–‡ä»¶ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
    state_file = output_dir / "download_fixed_state.json"

    # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„ä¸‹è½½
    downloaded_codes = set()
    start_index = 0

    if state_file.exists():
        with open(state_file, 'r') as f:
            state = json.load(f)
            downloaded_codes = set(state.get('downloaded_codes', []))
            start_index = state.get('current_index', 0)

        print(f"ğŸ“¥ æ£€æµ‹åˆ°æœªå®Œæˆä¸‹è½½: å·²ä¸‹è½½ {len(downloaded_codes)} åª")
        print(f"   å°†ä»ç¬¬ {start_index + 1} åªè‚¡ç¥¨ç»§ç»­")

    # å¼€å§‹ä¸‹è½½
    print(f"\nğŸš€ å¼€å§‹ä¸‹è½½...")
    print("="*80)

    all_data = []
    batch_data = []
    batch_num = start_index // BATCH_SIZE + 1
    success_count = len(downloaded_codes)

    for idx in range(start_index, total_stocks):
        row = stock_list.iloc[idx]
        ts_code = row['ts_code']
        name = row['name']

        # è·³è¿‡å·²ä¸‹è½½
        if ts_code in downloaded_codes:
            continue

        # è¿›åº¦æ˜¾ç¤º
        progress = (idx + 1) / total_stocks * 100
        print(f"[{idx+1}/{total_stocks}] ({progress:.1f}%) {ts_code} {name}...", end=" ", flush=True)

        try:
            # âš ï¸ å…³é”®ä¿®å¤ï¼šç§»é™¤äº†"è·³è¿‡æœªä¸Šå¸‚è‚¡ç¥¨"çš„é”™è¯¯é€»è¾‘
            # TuShare APIä¼šè‡ªåŠ¨è¿”å›è¯¥è‚¡ç¥¨ä¸Šå¸‚åçš„æ•°æ®
            df = pro.fina_indicator(
                ts_code=ts_code,
                start_date=START_DATE,
                end_date=END_DATE
            )

            if df is not None and not df.empty:
                batch_data.append(df)
                success_count += 1
                downloaded_codes.add(ts_code)
                print(f"âœ… {len(df)} æ¡")
            else:
                print("âš ï¸ æ— æ•°æ®")

        except Exception as e:
            print(f"âŒ {str(e)[:40]}")

        # æ¯æ‰¹æ¬¡ä¿å­˜ä¸€æ¬¡
        if (idx + 1) % BATCH_SIZE == 0 or (idx + 1) == total_stocks:
            # ä¿å­˜æ‰¹æ¬¡æ•°æ®
            if batch_data:
                batch_df = pd.concat(batch_data, ignore_index=True)

                batch_file = output_dir / f"fixed_batch_{batch_num:04d}.csv"
                batch_df.to_csv(batch_file, index=False, encoding='utf-8-sig')
                print(f"  ğŸ’¾ æ‰¹æ¬¡ {batch_num} å·²ä¿å­˜ ({len(batch_df)} æ¡)")

                all_data.append(batch_df)
                batch_data = []

                # æ›´æ–°çŠ¶æ€
                state = {
                    'current_index': idx + 1,
                    'downloaded_codes': list(downloaded_codes),
                    'last_update': datetime.now().isoformat()
                }
                with open(state_file, 'w') as f:
                    json.dump(state, f)

                batch_num += 1

        # APIé™æµ
        time.sleep(DELAY)

    # åˆå¹¶æ‰€æœ‰æ•°æ®
    print("\n" + "="*80)
    print("ğŸ“Š åˆå¹¶æ‰€æœ‰æ•°æ®...")

    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)

        # å»é‡ï¼ˆä¿ç•™æœ€æ–°ï¼‰
        combined_df = combined_df.sort_values(['ts_code', 'end_date', 'ann_date'])
        combined_df = combined_df.drop_duplicates(
            subset=['ts_code', 'end_date'],
            keep='last'
        )

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜å®Œæ•´æ•°æ®
        final_file = output_dir / f"a_share_financial_fixed_{timestamp}.csv"
        combined_df.to_csv(final_file, index=False, encoding='utf-8-sig')
        print(f"âœ… å®Œæ•´æ•°æ®: {final_file}")

        # ä¿å­˜æœ€æ–°ç‰ˆæœ¬
        latest_file = output_dir / "a_share_financial_latest.csv"
        combined_df.to_csv(latest_file, index=False, encoding='utf-8-sig')
        print(f"âœ… æœ€æ–°ç‰ˆæœ¬: {latest_file}")

        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡:")
        print(f"   æˆåŠŸ: {success_count}/{total_stocks} åªè‚¡ç¥¨")
        print(f"   æ€»è®°å½•: {len(combined_df):,} æ¡")
        print(f"   å­—æ®µæ•°: {len(combined_df.columns)} ä¸ª")
        print(f"   è‚¡ç¥¨æ•°: {combined_df['ts_code'].nunique()} åª")
        print(f"   æ—¶é—´èŒƒå›´: {combined_df['end_date'].min()} - {combined_df['end_date'].max()}")

        # æŒ‰å¹´ä»½ç»Ÿè®¡
        combined_df['year'] = combined_df['end_date'].astype(str).str[:4]
        yearly_stats = combined_df.groupby('year')['ts_code'].nunique()
        print(f"\nğŸ“Š æ¯å¹´è‚¡ç¥¨æ•°:")
        for year, count in yearly_stats.items():
            print(f"   {year}: {count}åª")

        # åˆ é™¤çŠ¶æ€æ–‡ä»¶
        if state_file.exists():
            state_file.unlink()
            print(f"\n   å·²æ¸…ç†çŠ¶æ€æ–‡ä»¶")

    else:
        print("âš ï¸ æ²¡æœ‰ä¸‹è½½åˆ°æ–°æ•°æ®")

    print("\nâœ… å…¨éƒ¨å®Œæˆ!")


if __name__ == "__main__":
    try:
        download_financial_data_fixed()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        print("ğŸ’¡ çŠ¶æ€å·²ä¿å­˜ï¼Œå¯ä»¥é‡æ–°è¿è¡Œè„šæœ¬ç»§ç»­ä¸‹è½½")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
