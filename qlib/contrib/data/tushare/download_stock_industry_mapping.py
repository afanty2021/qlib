#!/usr/bin/env python3
"""
ä¸ªè‚¡-ç”³ä¸‡äºŒçº§è¡Œä¸šæ˜ å°„ä¸‹è½½å·¥å…·

åŠŸèƒ½ï¼š
1. ä¸‹è½½æ‰€æœ‰Aè‚¡è‚¡ç¥¨çš„ç”³ä¸‡äºŒçº§è¡Œä¸šåˆ†ç±»
2. ç”Ÿæˆè‚¡ç¥¨ä»£ç åˆ°è¡Œä¸šä»£ç çš„æ˜ å°„è¡¨
3. ä¿å­˜ä¸ºå¤šç§æ ¼å¼ä¾¿äºä½¿ç”¨

ä½¿ç”¨æ–¹æ³•ï¼š
    python download_stock_industry_mapping.py

æˆ–ä½¿ç”¨TuShare Tokenï¼š
    export TUSHARE_TOKEN="your_token"
    python download_stock_industry_mapping.py
"""

import os
import sys
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import time

# æ·»åŠ qlibè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent.parent))

try:
    from qlib.contrib.data.tushare.config import TuShareConfig
    from qlib.contrib.data.tushare.api_client import TuShareAPIClient
    QLIB_AVAILABLE = True
except ImportError:
    QLIB_AVAILABLE = False
    print("âš ï¸ Qlibæœªå®‰è£…ï¼Œä½¿ç”¨åŸç”Ÿtushare")
    import tushare as ts


class StockIndustryMappingDownloader:
    """ä¸ªè‚¡-è¡Œä¸šæ˜ å°„ä¸‹è½½å™¨"""

    def __init__(self, token: str = None, output_dir: str = None):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨

        Args:
            token: TuShare Token
            output_dir: è¾“å‡ºç›®å½•
        """
        self.token = token or os.getenv("TUSHARE_TOKEN")
        if not self.token:
            raise ValueError("è¯·è®¾ç½®TUSHARE_TOKENç¯å¢ƒå˜é‡æˆ–ä¼ å…¥tokenå‚æ•°")

        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            # é»˜è®¤è¾“å‡ºåˆ°Qlibæ•°æ®ç›®å½•
            output_dir = Path("~/.qlib/qlib_data/cn_data/industry_data").expanduser()
        else:
            output_dir = Path(output_dir)

        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ç›´æ¥ä½¿ç”¨åŸç”ŸTuShare APIï¼ˆé¿å…ç¼“å­˜ç›®å½•é—®é¢˜ï¼‰
        import tushare as ts
        self.client = ts.pro_api(self.token)
        self.use_proxied_api = False

        print(f"âœ… åˆå§‹åŒ–å®Œæˆ")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"   APIæ¨¡å¼: åŸç”ŸTuShare")

    def download_stock_basic(self) -> pd.DataFrame:
        """
        ä¸‹è½½è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯

        Returns:
            è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯DataFrame
        """
        print("\n" + "="*80)
        print("ğŸ“¥ å¼€å§‹ä¸‹è½½è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
        print("="*80)

        try:
            # ä½¿ç”¨åŸç”ŸTuShare API
            import tushare as ts
            ts_client = ts.pro_api(self.token)

            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            print("\nğŸ“Š è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆåŒ…å«è¡Œä¸šå­—æ®µï¼‰...")
            df = ts_client.stock_basic(
                exchange='',
                list_status='L',  # Lä¸Šå¸‚ Dé€€å¸‚ Pæš‚åœä¸Šå¸‚
                fields='ts_code,symbol,name,area,industry,market,list_date'
            )

            if df is not None and not df.empty:
                print(f"âœ… æˆåŠŸè·å– {len(df)} åªè‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯")
                print(f"   - åŒ…å«å­—æ®µ: {list(df.columns)}")

                # æ˜¾ç¤ºè¡Œä¸šåˆ†å¸ƒï¼ˆä½¿ç”¨industryå­—æ®µï¼‰
                if 'industry' in df.columns:
                    print(f"\nğŸ“ˆ è¡Œä¸šåˆ†å¸ƒï¼ˆåŸºäºstock_basicï¼‰:")
                    industry_dist = df['industry'].value_counts().head(10)
                    for industry, count in industry_dist.items():
                        print(f"   - {industry}: {count}åª")

                return df
            else:
                print("âš ï¸ æœªè·å–åˆ°æ•°æ®")
                return pd.DataFrame()

        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()

    def download_sw2021_industry_classify(self) -> pd.DataFrame:
        """
        ä¸‹è½½ç”³ä¸‡2021è¡Œä¸šåˆ†ç±»

        Returns:
            ç”³ä¸‡è¡Œä¸šåˆ†ç±»DataFrame
        """
        print("\n" + "="*80)
        print("ğŸ“¥ å¼€å§‹ä¸‹è½½ç”³ä¸‡2021è¡Œä¸šåˆ†ç±»")
        print("="*80)

        all_classify = pd.DataFrame()

        try:
            import tushare as ts
            ts_client = ts.pro_api(self.token)

            # è·å–L1å’ŒL2çº§åˆ«çš„è¡Œä¸šåˆ†ç±»
            levels = ['L1', 'L2']
            source = 'SW2021'

            for level in levels:
                print(f"\nğŸ“Š è·å–ç”³ä¸‡2021 {level} çº§è¡Œä¸šåˆ†ç±»...")

                try:
                    df = ts_client.index_classify(
                        level=level,
                        source=source
                    )

                    if df is not None and not df.empty:
                        df['level'] = level
                        all_classify = pd.concat([all_classify, df], ignore_index=True)
                        print(f"   âœ… {len(df)} æ¡è®°å½•")

                        # é¿å…APIé¢‘ç‡é™åˆ¶
                        time.sleep(0.2)
                    else:
                        print(f"   âš ï¸ æ— æ•°æ®")

                except Exception as e:
                    print(f"   âŒ å¤±è´¥: {str(e)}")

            if not all_classify.empty:
                print(f"\nâœ… ç”³ä¸‡è¡Œä¸šåˆ†ç±»ä¸‹è½½å®Œæˆï¼Œå…± {len(all_classify)} æ¡")

            return all_classify

        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
            return pd.DataFrame()

    def download_stock_industry_detail(self) -> pd.DataFrame:
        """
        ä¸‹è½½ä¸ªè‚¡è¯¦ç»†çš„è¡Œä¸šåˆ†ç±»ä¿¡æ¯

        ä½¿ç”¨get_unionè·å–ä¸ªè‚¡çš„è¡Œä¸šæˆåˆ†

        Returns:
            ä¸ªè‚¡è¡Œä¸šåˆ†ç±»DataFrame
        """
        print("\n" + "="*80)
        print("ğŸ“¥ å¼€å§‹ä¸‹è½½ä¸ªè‚¡è¯¦ç»†è¡Œä¸šåˆ†ç±»")
        print("="*80)

        try:
            import tushare as ts
            ts_client = ts.pro_api(self.token)

            # å…ˆè·å–è‚¡ç¥¨åˆ—è¡¨
            stock_list = ts_client.stock_basic(
                exchange='',
                list_status='L',
                fields='ts_code,symbol,name'
            )

            if stock_list is None or stock_list.empty:
                print("âš ï¸ æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
                return pd.DataFrame()

            print(f"\nğŸ“Š å…± {len(stock_list)} åªè‚¡ç¥¨ï¼Œå¼€å§‹è·å–è¡Œä¸šåˆ†ç±»...")

            # å­˜å‚¨ä¸ªè‚¡è¡Œä¸šä¿¡æ¯
            stock_industry_list = []
            total = len(stock_list)

            # æ‰¹é‡è·å–ï¼Œé¿å…APIé™åˆ¶
            batch_size = 100
            for i in range(0, total, batch_size):
                batch = stock_list.iloc[i:i+batch_size]
                print(f"\n   å¤„ç†è¿›åº¦: {i+1}-{min(i+batch_size, total)}/{total}")

                for idx, row in batch.iterrows():
                    ts_code = row['ts_code']
                    symbol = row['symbol']
                    name = row['name']

                    try:
                        # ä½¿ç”¨get_unionè·å–æˆåˆ†è‚¡ä¿¡æ¯
                        # è¿™ä¸ªæ¥å£å¯ä»¥è·å–æŒ‡æ•°çš„æˆåˆ†è‚¡ï¼Œä¹Ÿå¯ä»¥åè¿‡æ¥æŸ¥è¯¢è‚¡ç¥¨æ‰€å±çš„æŒ‡æ•°
                        # ä½†TuShareæ²¡æœ‰ç›´æ¥çš„"è‚¡ç¥¨â†’è¡Œä¸š"æŸ¥è¯¢æ¥å£

                        # æ–¹æ³•ï¼šä½¿ç”¨daily_basicè·å–è‚¡ç¥¨çš„è¡Œä¸šä¿¡æ¯
                        basic_data = ts_client.daily_basic(
                            ts_code=ts_code,
                            fields='ts_code,trade_date,turnover_rate,volume_ratio,pe,pe_ttm,pb,ps,ps_ttm,dv_ratio,dv_ttm,total_share,float_share,free_share,total_mv,circ_mv'
                        )

                        # daily_basicæ²¡æœ‰ç›´æ¥çš„è¡Œä¸šä¿¡æ¯
                        # æˆ‘ä»¬éœ€è¦ä½¿ç”¨stock_basicçš„industryå­—æ®µ

                        time.sleep(0.1)  # é¿å…é¢‘ç‡é™åˆ¶

                    except Exception as e:
                        print(f"      âš ï¸ {ts_code} è·å–å¤±è´¥: {str(e)}")
                        continue

            print(f"\nâœ… ä¸ªè‚¡è¡Œä¸šåˆ†ç±»ä¸‹è½½å®Œæˆ")
            return pd.DataFrame(stock_industry_list)

        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()

    def create_industry_mapping(
        self,
        stock_basic: pd.DataFrame,
        industry_classify: pd.DataFrame = None
    ) -> pd.DataFrame:
        """
        åˆ›å»ºè‚¡ç¥¨-è¡Œä¸šæ˜ å°„è¡¨

        Args:
            stock_basic: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            industry_classify: è¡Œä¸šåˆ†ç±»ä¿¡æ¯

        Returns:
            è‚¡ç¥¨-è¡Œä¸šæ˜ å°„DataFrame
        """
        print("\n" + "="*80)
        print("ğŸ”— åˆ›å»ºè‚¡ç¥¨-è¡Œä¸šæ˜ å°„è¡¨")
        print("="*80)

        if stock_basic.empty:
            print("âš ï¸ è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ä¸ºç©º")
            return pd.DataFrame()

        # ä½¿ç”¨stock_basicä¸­çš„industryå­—æ®µ
        # è¿™ä¸ªå­—æ®µåŒ…å«äº†ç”³ä¸‡è¡Œä¸šåˆ†ç±»ä¿¡æ¯
        mapping_df = stock_basic[['ts_code', 'symbol', 'name', 'industry']].copy()
        mapping_df.columns = ['ts_code', 'symbol', 'name', 'industry_name']

        # å¦‚æœæœ‰è¡Œä¸šåˆ†ç±»è¡¨ï¼Œå°è¯•åŒ¹é…è¡Œä¸šä»£ç 
        if industry_classify is not None and not industry_classify.empty:
            print("\nğŸ“Š åŒ¹é…è¡Œä¸šä»£ç ...")

            # åˆ›å»ºè¡Œä¸šåç§°åˆ°ä»£ç çš„æ˜ å°„
            industry_map = dict(zip(
                industry_classify['industry_name'],
                industry_classify['industry_code']
            ))

            # æ·»åŠ è¡Œä¸šä»£ç åˆ—
            mapping_df['industry_code'] = mapping_df['industry_name'].map(industry_map)

            # ç»Ÿè®¡åŒ¹é…æƒ…å†µ
            matched = mapping_df['industry_code'].notna().sum()
            print(f"   âœ… æˆåŠŸåŒ¹é…è¡Œä¸šä»£ç : {matched}/{len(mapping_df)}")

        # æ·»åŠ æ—¶é—´æˆ³
        mapping_df['update_date'] = datetime.now().strftime('%Y-%m-%d')

        print(f"\nâœ… æ˜ å°„è¡¨åˆ›å»ºå®Œæˆ")
        print(f"   æ€»è‚¡ç¥¨æ•°: {len(mapping_df)}")

        # æ˜¾ç¤ºè¡Œä¸šåˆ†å¸ƒ
        print(f"\nğŸ“ˆ ç”³ä¸‡è¡Œä¸šåˆ†å¸ƒ:")
        industry_dist = mapping_df['industry_name'].value_counts().head(15)
        for industry, count in industry_dist.items():
            print(f"   - {industry}: {count}åª")

        return mapping_df

    def save_mapping_data(
        self,
        mapping_df: pd.DataFrame,
        stock_basic: pd.DataFrame = None,
        industry_classify: pd.DataFrame = None
    ):
        """
        ä¿å­˜æ˜ å°„æ•°æ®

        Args:
            mapping_df: æ˜ å°„è¡¨
            stock_basic: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            industry_classify: è¡Œä¸šåˆ†ç±»
        """
        print("\n" + "="*80)
        print("ğŸ’¾ ä¿å­˜æ•°æ®")
        print("="*80)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜æ˜ å°„è¡¨
        if not mapping_df.empty:
            print(f"\nğŸ“ ä¿å­˜æ˜ å°„è¡¨...")

            # CSVæ ¼å¼
            mapping_file = self.output_dir / f"stock_industry_mapping_SW2021_{timestamp}.csv"
            mapping_df.to_csv(mapping_file, index=False, encoding='utf-8-sig')
            print(f"   âœ… {mapping_file.name}")

            # JSONæ ¼å¼
            json_file = self.output_dir / f"stock_industry_mapping_SW2021_{timestamp}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(mapping_df.to_dict('records'), f, ensure_ascii=False, indent=2)
            print(f"   âœ… {json_file.name}")

            # åˆ›å»ºå­—å…¸æ ¼å¼ä¾¿äºæŸ¥è¯¢
            dict_file = self.output_dir / f"stock_industry_dict_SW2021_{timestamp}.json"
            stock_to_industry = dict(zip(
                mapping_df['ts_code'],
                mapping_df[['industry_code', 'industry_name']].to_dict('records')
            ))
            # ç§»é™¤Noneå€¼
            stock_to_industry = {k: v for k, v in stock_to_industry.items() if v.get('industry_code')}
            with open(dict_file, 'w', encoding='utf-8') as f:
                json.dump(stock_to_industry, f, ensure_ascii=False, indent=2)
            print(f"   âœ… {dict_file.name} ({len(stock_to_industry)}æ¡æ˜ å°„)")

            # åˆ›å»ºæœ€æ–°ç‰ˆæœ¬é“¾æ¥
            latest_mapping = self.output_dir / "stock_industry_mapping__latest.csv"
            import shutil
            shutil.copy2(mapping_file, latest_mapping)
            print(f"   âœ… æ›´æ–°æœ€æ–°ç‰ˆæœ¬é“¾æ¥")

        # ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        if stock_basic is not None and not stock_basic.empty:
            print(f"\nğŸ“ ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
            basic_file = self.output_dir / f"stock_basic_{timestamp}.csv"
            stock_basic.to_csv(basic_file, index=False, encoding='utf-8-sig')
            print(f"   âœ… {basic_file.name} ({len(stock_basic)}æ¡)")

        # ä¿å­˜è¡Œä¸šåˆ†ç±»
        if industry_classify is not None and not industry_classify.empty:
            print(f"\nğŸ“ ä¿å­˜è¡Œä¸šåˆ†ç±»...")
            classify_file = self.output_dir / f"industry_classify_SW2021_{timestamp}.csv"
            industry_classify.to_csv(classify_file, index=False, encoding='utf-8-sig')
            print(f"   âœ… {classify_file.name} ({len(industry_classify)}æ¡)")

        print(f"\nâœ… æ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ°: {self.output_dir}")

    def generate_summary_report(
        self,
        mapping_df: pd.DataFrame,
        stock_basic: pd.DataFrame = None
    ) -> str:
        """
        ç”Ÿæˆæ•°æ®æ‘˜è¦æŠ¥å‘Š

        Args:
            mapping_df: æ˜ å°„è¡¨
            stock_basic: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯

        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        print("\n" + "="*80)
        print("ğŸ“Š ç”Ÿæˆæ•°æ®æ‘˜è¦æŠ¥å‘Š")
        print("="*80)

        report_lines = []
        report_lines.append("# ä¸ªè‚¡-ç”³ä¸‡è¡Œä¸šæ˜ å°„æ•°æ®æ‘˜è¦æŠ¥å‘Š")
        report_lines.append(f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"\næ•°æ®ç›®å½•: {self.output_dir}")

        # åŸºæœ¬ç»Ÿè®¡
        if not mapping_df.empty:
            report_lines.append(f"\n## æ˜ å°„è¡¨ç»Ÿè®¡")
            report_lines.append(f"- æ€»è‚¡ç¥¨æ•°: {len(mapping_df)}")

            # è¡Œä¸šåˆ†å¸ƒ
            if 'industry_name' in mapping_df.columns:
                industry_dist = mapping_df['industry_name'].value_counts()
                report_lines.append(f"- è¡Œä¸šæ•°é‡: {len(industry_dist)}")
                report_lines.append(f"\n## è¡Œä¸šåˆ†å¸ƒï¼ˆæŒ‰è‚¡ç¥¨æ•°é‡æ’åºï¼‰")

                for idx, (industry, count) in enumerate(industry_dist.items(), 1):
                    pct = count / len(mapping_df) * 100
                    report_lines.append(f"{idx}. {industry}: {count}åª ({pct:.2f}%)")

            # äº¤æ˜“æ‰€åˆ†å¸ƒ
            if 'ts_code' in mapping_df.columns:
                report_lines.append(f"\n## äº¤æ˜“æ‰€åˆ†å¸ƒ")
                mapping_df['exchange'] = mapping_df['ts_code'].str[-2:]
                exchange_dist = mapping_df['exchange'].value_counts()
                for exchange, count in exchange_dist.items():
                    exchange_name = 'ä¸Šæµ·' if exchange == 'SH' else 'æ·±åœ³' if exchange == 'SZ' else exchange
                    report_lines.append(f"- {exchange_name}({exchange}): {count}åª")

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.output_dir / "stock_industry_mapping_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file.name}")

        return '\n'.join(report_lines)

    def run_full_download(self):
        """æ‰§è¡Œå®Œæ•´ä¸‹è½½æµç¨‹"""
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹å®Œæ•´ä¸‹è½½æµç¨‹")
        print("="*80)

        # 1. ä¸‹è½½è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆåŒ…å«è¡Œä¸šï¼‰
        stock_basic = self.download_stock_basic()

        if stock_basic.empty:
            print("\nâŒ ä¸‹è½½è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
            return None

        # 2. ä¸‹è½½ç”³ä¸‡è¡Œä¸šåˆ†ç±»
        industry_classify = self.download_sw2021_industry_classify()

        # 3. åˆ›å»ºæ˜ å°„è¡¨
        mapping_df = self.create_industry_mapping(stock_basic, industry_classify)

        # 4. ä¿å­˜æ•°æ®
        self.save_mapping_data(mapping_df, stock_basic, industry_classify)

        # 5. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_summary_report(mapping_df, stock_basic)

        print("\n" + "="*80)
        print("âœ… å®Œæ•´ä¸‹è½½æµç¨‹å®Œæˆï¼")
        print("="*80)

        # æ˜¾ç¤ºæ‘˜è¦
        print(f"\nğŸ“Š æ•°æ®æ‘˜è¦:")
        print(f"  - è‚¡ç¥¨æ€»æ•°: {len(stock_basic) if not stock_basic.empty else 0}")
        print(f"  - æ˜ å°„è®°å½•: {len(mapping_df) if not mapping_df.empty else 0}")
        print(f"  - è¡Œä¸šåˆ†ç±»: {len(industry_classify) if not industry_classify.empty else 0}")

        return {
            'stock_basic': stock_basic,
            'industry_classify': industry_classify,
            'mapping': mapping_df,
            'report': report
        }


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥Token
    token = os.getenv("TUSHARE_TOKEN")
    if not token:
        print("âŒ è¯·è®¾ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
        print("   export TUSHARE_TOKEN='your_token_here'")
        sys.exit(1)

    print("ğŸ¯ ä¸ªè‚¡-ç”³ä¸‡äºŒçº§è¡Œä¸šæ˜ å°„ä¸‹è½½å·¥å…·")
    print("="*80)

    # åˆ›å»ºä¸‹è½½å™¨
    downloader = StockIndustryMappingDownloader(token=token)

    # æ‰§è¡Œä¸‹è½½
    try:
        result = downloader.run_full_download()

        if result and result['mapping'] is not None and not result['mapping'].empty:
            print("\nâœ… ä¸‹è½½æˆåŠŸï¼")
            print(f"\næ•°æ®æ–‡ä»¶ä½ç½®: {downloader.output_dir}")
            print("\nä¸»è¦æ–‡ä»¶:")
            print("  - stock_industry_mapping__latest.csv  # æœ€æ–°æ˜ å°„è¡¨")
            print("  - stock_industry_dict__latest.json    # å­—å…¸æ ¼å¼æ˜ å°„")
            print("  - stock_industry_mapping_report.md   # è¯¦ç»†æŠ¥å‘Š")
        else:
            print("\nâš ï¸ ä¸‹è½½æœªå®Œæˆï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

    except Exception as e:
        print(f"\nâŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
