#!/usr/bin/env python3
"""
ETFæ•°æ®è‡ªåŠ¨ä¸‹è½½è„šæœ¬

åŠŸèƒ½ï¼š
- ä»TuShareè·å–ETFæ—¥çº¿è¡Œæƒ…æ•°æ®
- æ”¯æŒå¢é‡æ›´æ–°ï¼ˆæ£€æµ‹æœ¬åœ°æœ€æ–°æ—¥æœŸï¼‰
- æ”¯æŒå…¨é‡å†å²æ•°æ®ä¸‹è½½
- è‡ªåŠ¨è½¬æ¢ä¸ºQlibæ ¼å¼

ä½¿ç”¨æ–¹å¼ï¼š
    # ä¸‹è½½æŒ‡å®šETFæ•°æ®
    python scripts/etf_auto_download.py --etf-codes 510300.SH,510500.SH

    # ä¸‹è½½ä¸»æµETFæ•°æ®
    python scripts/etf_auto_download.py --main-etf

    # ä¸‹è½½æ•°æ®å¹¶è½¬æ¢ä¸ºQlibæ ¼å¼
    python scripts/etf_auto_download.py --convert-qlib

ç¯å¢ƒå˜é‡ï¼š
    TUSHARE_TOKEN: TuShare API Tokenï¼ˆå¿…éœ€ï¼‰

é…ç½®æ–‡ä»¶ï¼š
    scripts/etf_config.yaml: ETFåˆ—è¡¨å’Œé…ç½®
"""

import os
import sys
import logging
import time
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import pandas as pd
import numpy as np
import yaml

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å°è¯•å¯¼å…¥TuShareå®¢æˆ·ç«¯
try:
    from qlib.contrib.data.tushare.api_client import TuShareAPIClient
    from qlib.contrib.data.tushare.config import TuShareConfig
    TUSHARE_AVAILABLE = True
except ImportError:
    TUSHARE_AVAILABLE = False


def load_config(config_file: str = None) -> dict:
    """
    åŠ è½½é…ç½®æ–‡ä»¶

    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        é…ç½®å­—å…¸
    """
    if config_file is None:
        # é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„
        config_file = Path(__file__).parent / "etf_config.yaml"

    config_path = Path(config_file)

    if not config_path.exists():
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        print("ä½¿ç”¨ç©ºé…ç½®ï¼ˆéœ€è¦é€šè¿‡ --etf-codes æŒ‡å®šETFåˆ—è¡¨ï¼‰")
        return {"etf_list": []}

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            return config or {}
    except Exception as e:
        print(f"âš ï¸  é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return {"etf_list": []}


class ETFDataDownloader:
    """ETFæ•°æ®ä¸‹è½½å™¨"""

    def __init__(
        self,
        token: str = None,
        data_dir: str = "~/.qlib/qlib_data/cn_data/etf_raw",
        max_retries: int = 3,
        retry_delay: float = 1.0
    ):
        """
        åˆå§‹åŒ–ETFæ•°æ®ä¸‹è½½å™¨

        Args:
            token: TuShare API Token
            data_dir: åŸå§‹æ•°æ®å­˜å‚¨ç›®å½•
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        self.data_dir = Path(data_dir).expanduser()
        self.data_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()

        # åˆå§‹åŒ–TuShareå®¢æˆ·ç«¯
        if TUSHARE_AVAILABLE:
            config = TuShareConfig(
                token=token,
                max_retries=max_retries,
                retry_delay=retry_delay,
                rate_limit=200
            )
            self.client = TuShareAPIClient(config)
        else:
            import tushare as ts
            ts.set_token(token)
            self.client = ts.pro_api()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_etfs": 0,
            "success_count": 0,
            "failed_count": 0,
            "total_records": 0,
            "errors": []
        }

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        logger = logging.getLogger("ETFDownloader")
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            # æ—¥å¿—æ ¼å¼
            log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            date_format = "%Y-%m-%d %H:%M:%S"
            formatter = logging.Formatter(log_format, date_format)

            # æ–‡ä»¶å¤„ç†å™¨
            log_file = self.data_dir / "etf_download.log"
            file_handler = logging.FileHandler(log_file, encoding="utf-8")
            file_handler.setLevel(logging.DEBUG)
            file_handler.setFormatter(formatter)

            # æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            console_handler.setFormatter(formatter)

            logger.addHandler(file_handler)
            logger.addHandler(console_handler)

        return logger

    def get_latest_date(self, etf_code: str) -> Optional[str]:
        """
        è·å–æŒ‡å®šETFçš„æœ€æ–°æ•°æ®æ—¥æœŸ

        Args:
            etf_code: ETFä»£ç 

        Returns:
            æœ€æ–°æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)ï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å› None
        """
        csv_file = self.data_dir / f"{etf_code}.csv"

        if not csv_file.exists():
            return None

        try:
            # è¯»å–æ–‡ä»¶çš„æœ€åä¸€è¡Œ
            df = pd.read_csv(csv_file, nrows=1)
            if not df.empty and 'trade_date' in df.columns:
                latest_date = df['trade_date'].iloc[0]
                # å¤„ç†ä¸åŒçš„æ—¥æœŸæ ¼å¼
                if pd.isna(latest_date):
                    return None
                # å¦‚æœæ˜¯æ•´æ•°ç±»å‹ï¼ˆnumpy.int64æˆ–intï¼‰ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if isinstance(latest_date, (int, np.integer)):
                    latest_date = str(latest_date)
                    # è½¬æ¢ä¸º YYYY-MM-DD æ ¼å¼
                    if len(latest_date) == 8:
                        latest_date = f"{latest_date[:4]}-{latest_date[4:6]}-{latest_date[6:8]}"
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
                elif isinstance(latest_date, str):
                    if len(latest_date) == 8 and latest_date.isdigit():
                        # YYYYMMDD æ ¼å¼è½¬ä¸º YYYY-MM-DD
                        latest_date = f"{latest_date[:4]}-{latest_date[4:6]}-{latest_date[6:8]}"
                return latest_date
            return None
        except Exception as e:
            self.logger.warning(f"æ— æ³•è¯»å– {etf_code} çš„æœ€æ–°æ—¥æœŸ: {e}")
            return None

    def download_etf_data(
        self,
        etf_code: str,
        start_date: str = None,
        end_date: str = None
    ) -> Optional[pd.DataFrame]:
        """
        ä¸‹è½½å•ä¸ªETFçš„å†å²æ•°æ®

        Args:
            etf_code: ETFä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDD)
            end_date: ç»“æŸæ—¥æœŸ (YYYYMMDD)

        Returns:
            ETFæ•°æ®DataFrameï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        # é»˜è®¤æ—¥æœŸèŒƒå›´
        if end_date is None:
            end_date = datetime.now().strftime("%Y%m%d")
        if start_date is None:
            # é»˜è®¤ä»2010å¹´å¼€å§‹
            start_date = "20100101"

        try:
            self.logger.info(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ {etf_code} æ•°æ®...")

            if TUSHARE_AVAILABLE:
                # ä½¿ç”¨Qlibçš„TuShareå®¢æˆ·ç«¯
                data = self.client._make_request("fund_daily", {
                    "ts_code": etf_code,
                    "start_date": start_date,
                    "end_date": end_date
                })

                if data and "items" in data and len(data["items"]) > 0:
                    df = pd.DataFrame(data["items"], columns=data["fields"])
                else:
                    self.logger.warning(f"  âš ï¸  {etf_code} æ— æ•°æ®")
                    return None
            else:
                # ä½¿ç”¨åŸç”Ÿtushare
                data = self.client.fund_daily(
                    ts_code=etf_code,
                    start_date=start_date,
                    end_date=end_date
                )
                df = pd.DataFrame(data)

            if df.empty:
                self.logger.warning(f"  âš ï¸  {etf_code} è¿”å›ç©ºæ•°æ®")
                return None

            self.logger.info(f"  âœ… {etf_code} è·å–åˆ° {len(df)} æ¡è®°å½•")
            return df

        except Exception as e:
            self.logger.error(f"  âŒ {etf_code} ä¸‹è½½å¤±è´¥: {e}")
            self.stats["errors"].append(f"{etf_code}: {str(e)}")
            return None

    def save_to_csv(self, df: pd.DataFrame, etf_code: str):
        """
        ä¿å­˜ETFæ•°æ®åˆ°CSVæ–‡ä»¶

        Args:
            df: ETFæ•°æ®DataFrame
            etf_code: ETFä»£ç 
        """
        csv_file = self.data_dir / f"{etf_code}.csv"

        try:
            # ç¡®ä¿ trade_date åˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
            if 'trade_date' in df.columns:
                # å¤„ç†æ•´æ•°ç±»å‹çš„æ—¥æœŸ
                df['trade_date'] = df['trade_date'].apply(
                    lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, np.integer)) else x
                )

            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¿½åŠ æ•°æ®
            if csv_file.exists():
                existing_df = pd.read_csv(csv_file)
                # åŒæ ·å¤„ç†ç°æœ‰æ•°æ®çš„æ—¥æœŸåˆ—
                if 'trade_date' in existing_df.columns:
                    existing_df['trade_date'] = existing_df['trade_date'].apply(
                        lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, np.integer)) else x
                    )

                # åˆå¹¶æ•°æ®ï¼Œå»é‡
                df = pd.concat([existing_df, df], ignore_index=True)
                df = df.drop_duplicates(subset=['trade_date'], keep='last')

                # æŒ‰æ—¥æœŸé™åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                df = df.sort_values('trade_date', ascending=False)

            # ä¿å­˜åˆ°CSV
            df.to_csv(csv_file, index=False)
            self.logger.info(f"  ğŸ’¾ å·²ä¿å­˜åˆ° {csv_file.name} ({len(df)} æ¡è®°å½•)")
            self.stats["total_records"] += len(df)

        except Exception as e:
            self.logger.error(f"  âŒ ä¿å­˜å¤±è´¥: {e}")
            raise

    def download_incremental(self, etf_codes: List[str]) -> bool:
        """
        å¢é‡ä¸‹è½½ETFæ•°æ®

        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨

        Returns:
            æ˜¯å¦å…¨éƒ¨æˆåŠŸ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸš€ å¼€å§‹å¢é‡ä¸‹è½½ETFæ•°æ®")
        self.logger.info("=" * 60)

        self.stats["total_etfs"] = len(etf_codes)

        for etf_code in etf_codes:
            try:
                # è·å–æœ¬åœ°æœ€æ–°æ—¥æœŸ
                latest_date = self.get_latest_date(etf_code)

                if latest_date:
                    # è½¬æ¢ä¸ºTuShareæ—¥æœŸæ ¼å¼
                    latest_date_ts = latest_date.replace("-", "")
                    # ä»æœ€æ–°æ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹ä¸‹è½½
                    next_date = (pd.Timestamp(latest_date) + timedelta(days=1)).strftime("%Y%m%d")
                    self.logger.info(f"ğŸ“Š {etf_code} æœ¬åœ°æœ€æ–°æ—¥æœŸ: {latest_date}")
                    start_date = next_date
                else:
                    self.logger.info(f"ğŸ“Š {etf_code} é¦–æ¬¡ä¸‹è½½")
                    start_date = None  # ä½¿ç”¨é»˜è®¤èµ·å§‹æ—¥æœŸ

                # ä¸‹è½½ä»Šæ—¥æ•°æ®
                end_date = datetime.now().strftime("%Y%m%d")

                # å¦‚æœstart_dateåœ¨end_dateä¹‹åï¼Œè¯´æ˜æ•°æ®å·²æ˜¯æœ€æ–°
                if start_date and start_date > end_date:
                    self.logger.info(f"  âœ… {etf_code} æ•°æ®å·²æ˜¯æœ€æ–°")
                    self.stats["success_count"] += 1
                    continue

                # ä¸‹è½½æ•°æ®
                df = self.download_etf_data(etf_code, start_date, end_date)

                if df is not None:
                    self.save_to_csv(df, etf_code)
                    self.stats["success_count"] += 1
                else:
                    self.stats["failed_count"] += 1

                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.2)

            except Exception as e:
                self.logger.error(f"âŒ {etf_code} å¤„ç†å¤±è´¥: {e}")
                self.stats["errors"].append(f"{etf_code}: {str(e)}")
                self.stats["failed_count"] += 1

        return self.stats["failed_count"] == 0

    def download_all(self, etf_codes: List[str]) -> bool:
        """
        å…¨é‡ä¸‹è½½ETFå†å²æ•°æ®

        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨

        Returns:
            æ˜¯å¦å…¨éƒ¨æˆåŠŸ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸš€ å¼€å§‹å…¨é‡ä¸‹è½½ETFæ•°æ®")
        self.logger.info("=" * 60)

        self.stats["total_etfs"] = len(etf_codes)

        for etf_code in etf_codes:
            try:
                # ä¸‹è½½å…¨éƒ¨å†å²æ•°æ®
                df = self.download_etf_data(etf_code)

                if df is not None:
                    self.save_to_csv(df, etf_code)
                    self.stats["success_count"] += 1
                else:
                    self.stats["failed_count"] += 1

                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.2)

            except Exception as e:
                self.logger.error(f"âŒ {etf_code} å¤„ç†å¤±è´¥: {e}")
                self.stats["errors"].append(f"{etf_code}: {str(e)}")
                self.stats["failed_count"] += 1

        return self.stats["failed_count"] == 0

    def print_summary(self):
        """æ‰“å°ä¸‹è½½æ‘˜è¦"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ“Š ä¸‹è½½æ‘˜è¦")
        self.logger.info("=" * 60)
        self.logger.info(f"æ€»ETFæ•°é‡: {self.stats['total_etfs']}")
        self.logger.info(f"æˆåŠŸ: {self.stats['success_count']}")
        self.logger.info(f"å¤±è´¥: {self.stats['failed_count']}")
        self.logger.info(f"æ€»è®°å½•æ•°: {self.stats['total_records']}")

        if self.stats["errors"]:
            self.logger.info("\nâŒ å¤±è´¥åˆ—è¡¨:")
            for error in self.stats["errors"][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                self.logger.info(f"  - {error}")

        self.logger.info("=" * 60)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="ETFæ•°æ®è‡ªåŠ¨ä¸‹è½½è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:

  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸‹è½½ETFæ•°æ®ï¼ˆå¢é‡æ›´æ–°ï¼‰
  python scripts/etf_auto_download.py

  # ä½¿ç”¨æŒ‡å®šé…ç½®æ–‡ä»¶
  python scripts/etf_auto_download.py --config custom_etf_config.yaml

  # ä¸‹è½½æŒ‡å®šETFæ•°æ®
  python scripts/etf_auto_download.py --etf-codes 510300.SH,510500.SH

  # å…¨é‡ä¸‹è½½å†å²æ•°æ®
  python scripts/etf_auto_download.py --full-download

  # ä¸‹è½½å¹¶è½¬æ¢ä¸ºQlibæ ¼å¼
  python scripts/etf_auto_download.py --convert-qlib
        """
    )

    parser.add_argument(
        "--config",
        type=str,
        default=None,
        help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: scripts/etf_config.yamlï¼‰"
    )

    parser.add_argument(
        "--etf-codes",
        type=str,
        help="ETFä»£ç åˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œä¾‹å¦‚: 510300.SH,510500.SHï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰"
    )

    parser.add_argument(
        "--full-download",
        action="store_true",
        help="å…¨é‡ä¸‹è½½å†å²æ•°æ®ï¼ˆé»˜è®¤å¢é‡æ›´æ–°ï¼‰"
    )

    parser.add_argument(
        "--convert-qlib",
        action="store_true",
        help="è½¬æ¢ä¸ºQlibæ ¼å¼"
    )

    parser.add_argument(
        "--data-dir",
        type=str,
        default="~/.qlib/qlib_data/cn_data/etf_raw",
        help="åŸå§‹æ•°æ®å­˜å‚¨ç›®å½•"
    )

    parser.add_argument(
        "--qlib-dir",
        type=str,
        default="~/.qlib/qlib_data/cn_data/etf",
        help="Qlibæ ¼å¼æ•°æ®å­˜å‚¨ç›®å½•"
    )

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # æ£€æŸ¥Token
    token = os.getenv("TUSHARE_TOKEN")
    if not token:
        print("âŒ æœªè®¾ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®: export TUSHARE_TOKEN='your_token_here'")
        sys.exit(1)

    # ç¡®å®šETFåˆ—è¡¨
    if args.etf_codes:
        # å‘½ä»¤è¡ŒæŒ‡å®šçš„ETFåˆ—è¡¨ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        etf_codes = [code.strip() for code in args.etf_codes.split(",")]
        print(f"ğŸ“‹ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„ETFåˆ—è¡¨ ({len(etf_codes)} ä¸ª)")
    else:
        # ä»é…ç½®æ–‡ä»¶è¯»å–
        config = load_config(args.config)
        etf_codes = config.get("etf_list", [])

        if not etf_codes:
            print("âŒ é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ETFåˆ—è¡¨")
            print("è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€æŒ‡å®šETFï¼š")
            print("  1. åœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½® etf_list")
            print("  2. ä½¿ç”¨ --etf-codes å‚æ•°æŒ‡å®š")
            sys.exit(1)

        print(f"ğŸ“‹ ä½¿ç”¨é…ç½®æ–‡ä»¶çš„ETFåˆ—è¡¨ ({len(etf_codes)} ä¸ª)")

    # æ‰“å°ETFåˆ—è¡¨æ‘˜è¦
    if len(etf_codes) <= 10:
        print(f"   {', '.join(etf_codes)}")
    else:
        print(f"   {', '.join(etf_codes[:5])}... ç­‰å…± {len(etf_codes)} ä¸ª")

    # åˆ›å»ºä¸‹è½½å™¨
    downloader = ETFDataDownloader(
        token=token,
        data_dir=args.data_dir
    )

    # ä¸‹è½½æ•°æ®
    if args.full_download:
        success = downloader.download_all(etf_codes)
    else:
        success = downloader.download_incremental(etf_codes)

    # æ‰“å°æ‘˜è¦
    downloader.print_summary()

    # è½¬æ¢ä¸ºQlibæ ¼å¼
    if args.convert_qlib and success:
        print("\n" + "=" * 60)
        print("ğŸ”„ å¼€å§‹è½¬æ¢ä¸ºQlibæ ¼å¼...")
        print("=" * 60)

        convert_script = Path(__file__).parent / "etf_convert_qlib.py"
        if convert_script.exists():
            import subprocess
            cmd = [
                sys.executable,
                str(convert_script),
                "--source-dir", args.data_dir,
                "--qlib-dir", args.qlib_dir
            ]
            subprocess.run(cmd)
        else:
            print(f"âŒ è½¬æ¢è„šæœ¬ä¸å­˜åœ¨: {convert_script}")

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
