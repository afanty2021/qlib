#!/usr/bin/env python3
"""
TuShare å‚è€ƒæ•°æ®è·å–å™¨

ä½¿ç”¨ TuShare API è·å–å‚è€ƒæ•°æ®ï¼Œæ›¿ä»£ Dolt æ•°æ®åº“è¿›è¡Œæ•°æ®è´¨é‡æ¯”å¯¹ã€‚

ä¼˜åŠ¿ï¼š
- æ— éœ€ä¸‹è½½å¤§å‹ Dolt æ•°æ®åº“ï¼ˆæ•°GBï¼‰
- ç›´æ¥è·å–æœ€æ–°æ•°æ®
- é€Ÿåº¦å¿«ï¼Œå¯é æ€§é«˜

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/tushare_reference_fetcher.py --symbols 000001.SZ,000002.SZ --start-date 20240101 --end-date 20241231
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import warnings
import argparse

import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from qlib.contrib.data.tushare.api_client import TuShareAPIClient
from qlib.contrib.data.tushare.config import TuShareConfig

warnings.filterwarnings('ignore')


class TuShareReferenceFetcher:
    """
    TuShare å‚è€ƒæ•°æ®è·å–å™¨

    ä½¿ç”¨ TuShare API è·å–å‚è€ƒæ•°æ®ç”¨äºæ•°æ®è´¨é‡æ¯”å¯¹ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ– TuShare å®¢æˆ·ç«¯"""
        self.logger = self._setup_logger()

        # æ£€æŸ¥ Token
        token = os.getenv("TUSHARE_TOKEN")
        if not token:
            raise ValueError(
                "âŒ æœªè®¾ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡\n"
                "è¯·è®¾ç½®: export TUSHARE_TOKEN='your_token_here'"
            )

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        config = TuShareConfig(token=token)
        self.client = TuShareAPIClient(config)

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger("TuShareReferenceFetcher")
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger

    def get_reference_data(
        self,
        symbols: List[str],
        start_date: str,
        end_date: str,
        chunk_size: int = 100
    ) -> pd.DataFrame:
        """
        è·å–å‚è€ƒæ•°æ®

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDD)
            end_date: ç»“æŸæ—¥æœŸ (YYYYMMDD)
            chunk_size: æ¯æ¬¡è¯·æ±‚çš„è‚¡ç¥¨æ•°é‡

        Returns:
            å‚è€ƒæ•°æ® DataFrame
        """
        self.logger.info(f"ğŸ“¡ ä» TuShare è·å–å‚è€ƒæ•°æ®...")
        self.logger.info(f"   è‚¡ç¥¨æ•°é‡: {len(symbols)}")
        self.logger.info(f"   æ—¥æœŸèŒƒå›´: {start_date} -> {end_date}")

        all_data = []

        # åˆ†æ‰¹è·å–æ•°æ®
        for i in range(0, len(symbols), chunk_size):
            chunk_symbols = symbols[i:i + chunk_size]
            self.logger.info(f"   æ­£åœ¨è·å–ç¬¬ {i//chunk_size + 1} æ‰¹ ({len(chunk_symbols)} åªè‚¡ç¥¨)...")

            for symbol in chunk_symbols:
                try:
                    # è°ƒç”¨ TuShare API
                    data = self.client._make_request("daily", {
                        "ts_code": symbol,
                        "start_date": start_date,
                        "end_date": end_date
                    })

                    if data and "items" in data and len(data["items"]) > 0:
                        df = pd.DataFrame(data["items"], columns=data["fields"])

                        # å­—æ®µæ˜ å°„åˆ°ç»Ÿä¸€æ ¼å¼
                        df = df.rename(columns={
                            "ts_code": "symbol",
                            "trade_date": "tradedate"
                        })

                        # é€‰æ‹©éœ€è¦çš„å­—æ®µ
                        df = df[["tradedate", "symbol", "open", "high", "low", "close", "vol", "amount"]]
                        df = df.rename(columns={"vol": "volume"})

                        all_data.append(df)

                except Exception as e:
                    self.logger.warning(f"   âš ï¸  {symbol} è·å–å¤±è´¥: {e}")
                    continue

        if all_data:
            result_df = pd.concat(all_data, ignore_index=True)
            result_df = result_df.sort_values(["tradedate", "symbol"])
            self.logger.info(f"âœ… è·å–åˆ° {len(result_df):,} æ¡å‚è€ƒæ•°æ®")
            return result_df
        else:
            self.logger.error("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return pd.DataFrame()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="TuShare å‚è€ƒæ•°æ®è·å–å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è·å–å•åªè‚¡ç¥¨æ•°æ®
  python scripts/tushare_reference_fetcher.py \\
      --symbols 000001.SZ \\
      --start-date 20240101 \\
      --end-date 20241231 \\
      --output reference_data.csv

  # è·å–å¤šåªè‚¡ç¥¨æ•°æ®
  python scripts/tushare_reference_fetcher.py \\
      --symbols 000001.SZ,000002.SZ,600000.SH \\
      --start-date 20240101 \\
      --end-date 20241231 \\
      --output reference_data.csv

  # ä½¿ç”¨æ²ªæ·±300æˆåˆ†è‚¡
  python scripts/tushare_reference_fetcher.py \\
      --use-csi300 \\
      --start-date 20240101 \\
      --end-date 20241231 \\
      --output csi300_reference.csv
        """
    )

    parser.add_argument(
        "--symbols",
        type=str,
        help="è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œä¾‹å¦‚: 000001.SZ,000002.SZ"
    )

    parser.add_argument(
        "--use-csi300",
        action="store_true",
        help="ä½¿ç”¨æ²ªæ·±300æˆåˆ†è‚¡"
    )

    parser.add_argument(
        "--use-csi500",
        action="store_true",
        help="ä½¿ç”¨ä¸­è¯500æˆåˆ†è‚¡"
    )

    parser.add_argument(
        "--start-date",
        type=str,
        required=True,
        help="å¼€å§‹æ—¥æœŸ (YYYYMMDD)"
    )

    parser.add_argument(
        "--end-date",
        type=str,
        default=None,
        help="ç»“æŸæ—¥æœŸ (YYYYMMDD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©"
    )

    parser.add_argument(
        "--output",
        type=str,
        default="reference_data.csv",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: reference_data.csv)"
    )

    parser.add_argument(
        "--chunk-size",
        type=int,
        default=100,
        help="æ¯æ‰¹è¯·æ±‚çš„è‚¡ç¥¨æ•°é‡ (é»˜è®¤: 100)"
    )

    args = parser.parse_args()

    # æ£€æŸ¥å‚æ•°
    if not args.symbols and not args.use_csi300 and not args.use_csi500:
        parser.error("å¿…é¡»æŒ‡å®š --symbols, --use-csi300 æˆ– --use-csi500")

    # è®¾ç½®ç»“æŸæ—¥æœŸ
    if args.end_date is None:
        args.end_date = datetime.now().strftime("%Y%m%d")

    print("\n" + "=" * 60)
    print("TuShare å‚è€ƒæ•°æ®è·å–å™¨")
    print("=" * 60)

    try:
        # åˆ›å»ºè·å–å™¨
        fetcher = TuShareReferenceFetcher()

        # ç¡®å®šè‚¡ç¥¨åˆ—è¡¨
        symbols = []
        if args.symbols:
            symbols = [s.strip() for s in args.symbols.split(",")]

        elif args.use_csi300 or args.use_csi500:
            # è·å–æŒ‡æ•°æˆåˆ†è‚¡
            index_code = "000300.SH" if args.use_csi300 else "000905.SH"
            index_name = "æ²ªæ·±300" if args.use_csi300 else "ä¸­è¯500"

            print(f"\nğŸ“Š è·å– {index_name} æˆåˆ†è‚¡...")

            data = fetcher.client._make_request("index_weight", {
                "index_code": index_code,
                "start_date": args.end_date,
                "end_date": args.end_date
            })

            if data and "items" in data:
                df = pd.DataFrame(data["items"], columns=data["fields"])
                symbols = df["con_code"].unique().tolist()

                # è½¬æ¢ä¸º TuShare æ ¼å¼
                formatted_symbols = []
                for s in symbols:
                    if s.endswith(".SH") or s.endswith(".SZ"):
                        formatted_symbols.append(s)
                    elif s.startswith("6"):
                        formatted_symbols.append(f"{s}.SH")
                    else:
                        formatted_symbols.append(f"{s}.SZ")

                symbols = formatted_symbols

                print(f"âœ… è·å–åˆ° {len(symbols)} åªæˆåˆ†è‚¡")
            else:
                print(f"âŒ è·å– {index_name} æˆåˆ†è‚¡å¤±è´¥")
                return 1

        # è·å–å‚è€ƒæ•°æ®
        reference_df = fetcher.get_reference_data(
            symbols=symbols,
            start_date=args.start_date,
            end_date=args.end_date,
            chunk_size=args.chunk_size
        )

        if reference_df.empty:
            print("\nâŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return 1

        # ä¿å­˜æ•°æ®
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        reference_df.to_csv(output_path, index=False)

        print(f"\nâœ… å‚è€ƒæ•°æ®å·²ä¿å­˜: {output_path}")
        print(f"   æ€»è®°å½•æ•°: {len(reference_df):,}")
        print(f"   æ—¥æœŸèŒƒå›´: {reference_df['tradedate'].min()} -> {reference_df['tradedate'].max()}")
        print(f"   è‚¡ç¥¨æ•°é‡: {reference_df['symbol'].nunique()}")

        return 0

    except ValueError as e:
        print(f"\nâŒ {e}")
        return 1
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
