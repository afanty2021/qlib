#!/usr/bin/env python3
"""
æ•°æ®èåˆæœºåˆ¶æ¼”ç¤ºè„šæœ¬

æ¼”ç¤ºå¢é‡æ›´æ–°å¦‚ä½•ä¸æœ¬åœ°å†å²æ•°æ®èåˆ

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/data_merge_demo.py
"""

import pandas as pd
from pathlib import Path
from datetime import datetime


def create_sample_old_data():
    """åˆ›å»ºç¤ºä¾‹æ—§æ•°æ®ï¼ˆæ¨¡æ‹Ÿæœ¬åœ°å†å²æ•°æ®ï¼‰"""
    print("=" * 60)
    print("æ­¥éª¤ 1: åˆ›å»ºç¤ºä¾‹æ—§æ•°æ®")
    print("=" * 60)

    # åˆ›å»º 2024-12-15 åˆ° 2024-12-20 çš„æ•°æ®
    dates = ["20241215", "20241216", "20241217", "20241218", "20241219", "20241220"]
    symbols = ["000001.SZ", "000002.SZ", "000003.SZ"]

    data = []
    for date in dates:
        for symbol in symbols:
            data.append({
                "tradedate": date,
                "symbol": symbol,
                "open": 10.0,
                "high": 10.5,
                "low": 9.5,
                "close": 10.25,
                "volume": 1000000,
                "amount": 10250000
            })

    df = pd.DataFrame(data)
    df = df.sort_values(["tradedate", "symbol"], ascending=[False, True])

    print(f"âœ… æ—§æ•°æ®åˆ›å»ºæˆåŠŸ")
    print(f"   è¡Œæ•°: {len(df)}")
    print(f"   æ—¥æœŸèŒƒå›´: {df['tradedate'].min()} -> {df['tradedate'].max()}")
    print(f"   è‚¡ç¥¨æ•°é‡: {df['symbol'].nunique()}")
    print()

    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_file = Path("/tmp/stock_data_old.csv")
    df.to_csv(temp_file, index=False)
    print(f"ğŸ’¾ æ—§æ•°æ®å·²ä¿å­˜åˆ°: {temp_file}")
    print()

    return temp_file


def create_sample_new_data():
    """åˆ›å»ºç¤ºä¾‹æ–°æ•°æ®ï¼ˆæ¨¡æ‹Ÿå¢é‡ä¸‹è½½çš„æ•°æ®ï¼‰"""
    print("=" * 60)
    print("æ­¥éª¤ 2: åˆ›å»ºç¤ºä¾‹æ–°æ•°æ®ï¼ˆå¢é‡ä¸‹è½½ï¼‰")
    print("=" * 60)

    # åˆ›å»º 2024-12-23 åˆ° 2024-12-25 çš„æ•°æ®ï¼ˆå‡è®¾å‘¨æœ«ä¼‘å¸‚ï¼‰
    dates = ["20241223", "20241224", "20241225"]
    symbols = ["000001.SZ", "000002.SZ", "000003.SZ", "000004.SZ"]  # æ–°å¢ä¸€åªè‚¡ç¥¨

    data = []
    for date in dates:
        for symbol in symbols:
            data.append({
                "tradedate": date,
                "symbol": symbol,
                "open": 11.0,  # ä»·æ ¼ç•¥æœ‰ä¸Šæ¶¨
                "high": 11.5,
                "low": 10.5,
                "close": 11.25,
                "volume": 1100000,
                "amount": 11250000
            })

    df = pd.DataFrame(data)

    print(f"âœ… æ–°æ•°æ®åˆ›å»ºæˆåŠŸ")
    print(f"   è¡Œæ•°: {len(df)}")
    print(f"   æ—¥æœŸèŒƒå›´: {df['tradedate'].min()} -> {df['tradedate'].max()}")
    print(f"   è‚¡ç¥¨æ•°é‡: {df['symbol'].nunique()}")
    print()

    return df


def demonstrate_merge_mechanism(old_file, new_df):
    """æ¼”ç¤ºæ•°æ®èåˆæœºåˆ¶"""
    print("=" * 60)
    print("æ­¥éª¤ 3: æ¼”ç¤ºæ•°æ®èåˆæœºåˆ¶")
    print("=" * 60)

    # 1. è¯»å–æ—§æ•°æ®
    print("1ï¸âƒ£  è¯»å–æ—§æ•°æ®")
    old_df = pd.read_csv(old_file)
    print(f"   æ—§æ•°æ®è¡Œæ•°: {len(old_df):,}")
    print(f"   æ—§æ•°æ®åˆ—: {list(old_df.columns)}")
    print()

    # 2. å±•ç¤ºæ–°æ—§æ•°æ®
    print("2ï¸âƒ£  æ•°æ®æ¦‚è§ˆ")
    print("   æ—§æ•°æ®æœ€æ–°æ—¥æœŸ:")
    print(f"   {old_df['tradedate'].iloc[0]} (å‡è®¾æ•°æ®æŒ‰æ—¥æœŸé™åºæ’åˆ—)")
    print()
    print("   æ–°æ•°æ®æ—¥æœŸèŒƒå›´:")
    print(f"   {new_df['tradedate'].min()} -> {new_df['tradedate'].max()}")
    print()

    # 3. æ‹¼æ¥æ•°æ®
    print("3ï¸âƒ£  æ‹¼æ¥æ–°æ—§æ•°æ®")
    combined_df = pd.concat([old_df, new_df], ignore_index=True)
    print(f"   åˆå¹¶å‰è¡Œæ•°: {len(old_df):,} + {len(new_df):,} = {len(old_df) + len(new_df):,}")
    print(f"   åˆå¹¶åè¡Œæ•°: {len(combined_df):,}")
    print()

    # 4. å»é‡
    print("4ï¸âƒ£  å»é‡å¤„ç†")
    before_dedup = len(combined_df)
    combined_df = combined_df.drop_duplicates(
        subset=["tradedate", "symbol"],
        keep="last"
    )
    after_dedup = len(combined_df)
    duplicates_removed = before_dedup - after_dedup

    print(f"   å»é‡å‰: {before_dedup:,} è¡Œ")
    print(f"   å»é‡å: {after_dedup:,} è¡Œ")
    print(f"   ç§»é™¤é‡å¤: {duplicates_removed} è¡Œ")
    print()
    print("   ğŸ“ å»é‡é”®: ['tradedate', 'symbol']")
    print("   ğŸ“ ç­–ç•¥: keep='last' (ä¿ç•™æœ€åå‡ºç°çš„è®°å½•)")
    print()

    # 5. æ’åº
    print("5ï¸âƒ£  æ’åº")
    combined_df = combined_df.sort_values(["tradedate", "symbol"])
    print(f"   æ’åºé”®: ['tradedate', 'symbol']")
    print(f"   é¡ºåº: å‡åº (æ—§->æ–°)")
    print()

    # 6. ä¿å­˜
    print("6ï¸âƒ£  ä¿å­˜èåˆåçš„æ•°æ®")
    output_file = Path("/tmp/stock_data_merged.csv")
    combined_df.to_csv(output_file, index=False)
    print(f"   ä¿å­˜è·¯å¾„: {output_file}")
    print()

    return output_file, combined_df


def verify_merge_result(merged_file, merged_df):
    """éªŒè¯èåˆç»“æœ"""
    print("=" * 60)
    print("æ­¥éª¤ 4: éªŒè¯èåˆç»“æœ")
    print("=" * 60)

    # ç¡®ä¿ tradedate æ˜¯å­—ç¬¦ä¸²ç±»å‹
    merged_df['tradedate'] = merged_df['tradedate'].astype(str)

    # æ•°æ®å®Œæ•´æ€§
    print("âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥")
    print(f"   æ€»è¡Œæ•°: {len(merged_df):,}")
    print(f"   æ—¥æœŸèŒƒå›´: {merged_df['tradedate'].min()} -> {merged_df['tradedate'].max()}")
    print(f"   è‚¡ç¥¨æ•°é‡: {merged_df['symbol'].nunique()}")
    print()

    # å»é‡éªŒè¯
    print("âœ… å»é‡éªŒè¯")
    duplicate_count = merged_df.duplicated(subset=["tradedate", "symbol"]).sum()
    print(f"   é‡å¤è®°å½•æ•°: {duplicate_count}")
    if duplicate_count == 0:
        print("   âœ… æ²¡æœ‰é‡å¤è®°å½•ï¼Œå»é‡æˆåŠŸï¼")
    print()

    # æ’åºéªŒè¯
    print("âœ… æ’åºéªŒè¯")
    is_sorted = merged_df['tradedate'].is_monotonic_increasing
    print(f"   æ—¥æœŸæ˜¯å¦å‡åº: {is_sorted}")
    if is_sorted:
        print("   âœ… æ•°æ®å·²æ­£ç¡®æ’åºï¼")
    print()

    # å±•ç¤ºéƒ¨åˆ†æ•°æ®
    print("âœ… æ•°æ®é¢„è§ˆ")
    print("   æœ€æ—©çš„æ•°æ®:")
    print(merged_df.head(3).to_string(index=False))
    print()
    print("   æœ€æ–°çš„æ•°æ®:")
    print(merged_df.tail(3).to_string(index=False))
    print()

    # ç»Ÿè®¡ä¿¡æ¯
    print("âœ… ç»Ÿè®¡ä¿¡æ¯")
    print(f"   æ–‡ä»¶å¤§å°: {merged_file.stat().st_size / 1024:.2f} KB")
    print(f"   å¹³å‡æ¯äº¤æ˜“æ—¥è®°å½•æ•°: {len(merged_df) / merged_df['tradedate'].nunique():.0f}")
    print()


def demonstrate_edge_cases():
    """æ¼”ç¤ºè¾¹ç•Œæƒ…å†µå¤„ç†"""
    print("=" * 60)
    print("æ­¥éª¤ 5: è¾¹ç•Œæƒ…å†µæ¼”ç¤º")
    print("=" * 60)

    # æƒ…å†µ 1: æ•°æ®ä¿®æ­£
    print("1ï¸âƒ£  æƒ…å†µ 1: æ•°æ®ä¿®æ­£")
    print("   å‡è®¾ 2024-12-20 çš„æ•°æ®æœ‰è¯¯ï¼Œéœ€è¦ä¿®æ­£")
    data_old = pd.DataFrame([{
        "tradedate": "20241220",
        "symbol": "000001.SZ",
        "close": 10.25,  # æ—§ä»·æ ¼
        "volume": 1000000
    }])
    data_new = pd.DataFrame([{
        "tradedate": "20241220",
        "symbol": "000001.SZ",
        "close": 10.30,  # ä¿®æ­£åçš„ä»·æ ¼
        "volume": 1000000
    }])

    combined = pd.concat([data_old, data_new])
    combined = combined.drop_duplicates(subset=["tradedate", "symbol"], keep="last")

    print(f"   æ—§ä»·æ ¼: {data_old['close'].iloc[0]}")
    print(f"   æ–°ä»·æ ¼: {data_new['close'].iloc[0]}")
    print(f"   æœ€ç»ˆä»·æ ¼: {combined['close'].iloc[0]}")
    print(f"   âœ… keep='last' ä¿ç•™äº†æ–°æ•°æ®ï¼ˆä¿®æ­£åçš„ä»·æ ¼ï¼‰")
    print()

    # æƒ…å†µ 2: æ–°å¢è‚¡ç¥¨
    print("2ï¸âƒ£  æƒ…å†µ 2: æ–°å¢è‚¡ç¥¨")
    print("   å‡è®¾ 000004.SZ æ˜¯æ–°ä¸Šå¸‚çš„è‚¡ç¥¨")
    data_has_stock = pd.DataFrame([{
        "tradedate": "20241223",
        "symbol": "000004.SZ",
        "close": 11.25
    }])
    print(f"   æ–°è‚¡ç¥¨: {data_has_stock['symbol'].iloc[0]}")
    print(f"   ä¸Šå¸‚æ—¥æœŸ: {data_has_stock['tradedate'].iloc[0]}")
    print(f"   âœ… æ–°è‚¡ç¥¨å¯ä»¥ç›´æ¥æ·»åŠ ï¼Œä¸ä¼šå†²çª")
    print()


def main():
    """ä¸»å‡½æ•°"""
    print("\n")
    print("ğŸ¯" * 30)
    print("æ•°æ®èåˆæœºåˆ¶æ¼”ç¤º")
    print("ğŸ¯" * 30)
    print("\n")

    try:
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        old_file = create_sample_old_data()
        new_df = create_sample_new_data()

        # æ¼”ç¤ºèåˆæœºåˆ¶
        merged_file, merged_df = demonstrate_merge_mechanism(old_file, new_df)

        # éªŒè¯ç»“æœ
        verify_merge_result(merged_file, merged_df)

        # è¾¹ç•Œæƒ…å†µ
        demonstrate_edge_cases()

        print("=" * 60)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 60)
        print()
        print("ğŸ“Š èåˆåçš„æ•°æ®æ–‡ä»¶:")
        print(f"   {merged_file}")
        print()
        print("ğŸ’¡ æ ¸å¿ƒè¦ç‚¹:")
        print("   1. å¢é‡æ£€æµ‹: ä»…è¯»å–æ–‡ä»¶ç¬¬ä¸€è¡Œè·å–æœ€æ–°æ—¥æœŸ")
        print("   2. æ•°æ®æ‹¼æ¥: pd.concat() åˆå¹¶æ–°æ—§æ•°æ®")
        print("   3. å»é‡ç­–ç•¥: drop_duplicates(subset=[...], keep='last')")
        print("   4. æ’åºä¿è¯: sort_values() ç¡®ä¿æ•°æ®ä¸€è‡´æ€§")
        print()

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
