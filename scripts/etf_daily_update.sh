#!/usr/bin/env python3
"""
ETFæ•°æ®æ¯æ—¥è‡ªåŠ¨æ›´æ–°å®Œæ•´è„šæœ¬

åŠŸèƒ½ï¼š
- è‡ªåŠ¨ä»TuShareè·å–ETFå½“æ—¥æ•°æ®
- å¦‚æœå†å²æ•°æ®ä¸å­˜åœ¨åˆ™è‡ªåŠ¨è¡¥å……
- è‡ªåŠ¨è½¬æ¢ä¸ºQlibæ ¼å¼
- å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
- å¯é€‰çš„é€šçŸ¥åŠŸèƒ½

ä½¿ç”¨æ–¹å¼ï¼š
    # ç›´æ¥è¿è¡Œï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
    python scripts/etf_daily_update.py

    # æŒ‡å®šé…ç½®æ–‡ä»¶
    python scripts/etf_daily_update.py --config etf_config.yaml

    # å…¨é‡ä¸‹è½½å†å²æ•°æ®
    python scripts/etf_daily_update.py --full-download

ç¯å¢ƒå˜é‡ï¼š
    TUSHARE_TOKEN: TuShare API Tokenï¼ˆå¿…éœ€ï¼‰
"""

import os
import sys
import logging
import time
import json
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import pandas as pd
import yaml

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class ETFDailyUpdater:
    """ETFæ•°æ®æ¯æ—¥æ›´æ–°å™¨ï¼ˆå®Œæ•´ç‰ˆï¼‰"""

    def __init__(
        self,
        token: str = None,
        data_dir: str = "~/.qlib/qlib_data/cn_data/etf_raw",
        qlib_dir: str = "~/.qlib/qlib_data/cn_data/etf",
        config_file: str = None
    ):
        """
        åˆå§‹åŒ–æ›´æ–°å™¨

        Args:
            token: TuShare API Token
            data_dir: åŸå§‹æ•°æ®å­˜å‚¨ç›®å½•
            qlib_dir: Qlibæ ¼å¼æ•°æ®ç›®å½•
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.data_dir = Path(data_dir).expanduser()
        self.qlib_dir = Path(qlib_dir).expanduser()

        # åˆ›å»ºç›®å½•
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.qlib_dir.mkdir(parents=True, exist_ok=True)

        # åŠ è½½é…ç½®
        self.config = self._load_config(config_file)

        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()

        # åˆå§‹åŒ–TuShareå®¢æˆ·ç«¯
        self._init_tushare_client(token)

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "start_time": datetime.now(),
            "etf_list": [],
            "downloaded": [],
            "failed": [],
            "converted": [],
            "errors": []
        }

    def _load_config(self, config_file: str = None) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            "etf_list": [],  # ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œä¸å†ä½¿ç”¨ç¡¬ç¼–ç 
            "download_interval": 0.2,  # ä¸‹è½½é—´éš”ï¼ˆç§’ï¼‰
            "max_retries": 3,
            "convert_to_qlib": True,
            "enable_notification": False,
            "log_level": "INFO"
        }

        # é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„
        if config_file is None:
            config_file = Path(__file__).parent / "etf_config.yaml"

        config_path = Path(config_file)

        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = yaml.safe_load(f)
                    if user_config:
                        default_config.update(user_config)
            except Exception as e:
                self.logger = logging.getLogger("ETFDailyUpdater")
                self.logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®°å½•è­¦å‘Š
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            print("è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½® etf_list")

        return default_config

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        logger = logging.getLogger("ETFDailyUpdater")
        logger.setLevel(getattr(logging, self.config.get("log_level", "INFO")))

        if not logger.handlers:
            # æ—¥å¿—æ ¼å¼
            log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            date_format = "%Y-%m-%d %H:%M:%S"
            formatter = logging.Formatter(log_format, date_format)

            # æ–‡ä»¶å¤„ç†å™¨ï¼ˆæŒ‰æ—¥æœŸåˆ†å‰²ï¼‰
            log_file = self.data_dir / f"update_{datetime.now().strftime('%Y%m%d')}.log"
            file_handler = logging.FileHandler(log_file, encoding="utf-8")
            file_handler.setLevel(logging.DEBUG)
            file_handler.setFormatter(formatter)

            # æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            console_handler.setFormatter(formatter)

            logger.addHandler(file_handler)
            logger.addHandler(console_handler)

        return logger

    def _init_tushare_client(self, token: str):
        """åˆå§‹åŒ–TuShareå®¢æˆ·ç«¯"""
        if token is None:
            token = os.getenv("TUSHARE_TOKEN")

        if not token:
            raise ValueError("æœªè®¾ç½®TUSHARE_TOKENç¯å¢ƒå˜é‡æˆ–å‚æ•°")

        try:
            from qlib.contrib.data.tushare.api_client import TuShareAPIClient
            from qlib.contrib.data.tushare.config import TuShareConfig

            config = TuShareConfig(
                token=token,
                max_retries=self.config.get("max_retries", 3),
                retry_delay=1.0,
                rate_limit=200
            )
            self.client = TuShareAPIClient(config)
            self.tushare_available = True

        except ImportError:
            import tushare as ts
            ts.set_token(token)
            self.client = ts.pro_api()
            self.tushare_available = False

    def get_latest_date(self, etf_code: str) -> Optional[str]:
        """è·å–æœ¬åœ°æœ€æ–°æ•°æ®æ—¥æœŸ"""
        csv_file = self.data_dir / f"{etf_code}.csv"

        if not csv_file.exists():
            return None

        try:
            df = pd.read_csv(csv_file, nrows=1)
            if not df.empty and 'trade_date' in df.columns:
                latest_date = df['trade_date'].iloc[0]
                # å¤„ç†ä¸åŒçš„æ—¥æœŸæ ¼å¼
                if pd.isna(latest_date):
                    return None
                # å¦‚æœæ˜¯æ•´æ•°ç±»å‹ï¼ˆnumpy.int64æˆ–intï¼‰ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if isinstance(latest_date, (int, np.integer)):
                    latest_date = str(latest_date)
                    # è½¬æ¢ä¸º YYYY-MM-DD æ ¼å¼
                    if len(latest_date) == 8:
                        latest_date = f"{latest_date[:4]}-{latest_date[4:6]}-{latest_date[6:8]}"
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
                elif isinstance(latest_date, str):
                    if len(latest_date) == 8 and latest_date.isdigit():
                        # YYYYMMDD æ ¼å¼è½¬ä¸º YYYY-MM-DD
                        latest_date = f"{latest_date[:4]}-{latest_date[4:6]}-{latest_date[6:8]}"
                return latest_date
            return None
        except Exception:
            return None

    def download_etf_data(
        self,
        etf_code: str,
        start_date: str = None,
        end_date: str = None
    ) -> Optional[pd.DataFrame]:
        """ä¸‹è½½ETFæ•°æ®"""
        if end_date is None:
            end_date = datetime.now().strftime("%Y%m%d")

        try:
            if self.tushare_available:
                data = self.client._make_request("fund_daily", {
                    "ts_code": etf_code,
                    "start_date": start_date or "20100101",
                    "end_date": end_date
                })

                if data and "items" in data and len(data["items"]) > 0:
                    return pd.DataFrame(data["items"], columns=data["fields"])
            else:
                df = self.client.fund_daily(
                    ts_code=etf_code,
                    start_date=start_date or "20100101",
                    end_date=end_date
                )
                return pd.DataFrame(df)

        except Exception as e:
            self.logger.error(f"âŒ {etf_code} ä¸‹è½½å¤±è´¥: {e}")
            self.stats["errors"].append(f"{etf_code}: {str(e)}")

        return None

    def save_to_csv(self, df: pd.DataFrame, etf_code: str):
        """ä¿å­˜æ•°æ®åˆ°CSV"""
        csv_file = self.data_dir / f"{etf_code}.csv"

        try:
            # ç¡®ä¿ trade_date åˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
            if 'trade_date' in df.columns:
                # å¤„ç†æ•´æ•°ç±»å‹çš„æ—¥æœŸ
                df['trade_date'] = df['trade_date'].apply(
                    lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, np.integer)) else x
                )

            if csv_file.exists():
                existing_df = pd.read_csv(csv_file)
                # åŒæ ·å¤„ç†ç°æœ‰æ•°æ®çš„æ—¥æœŸåˆ—
                if 'trade_date' in existing_df.columns:
                    existing_df['trade_date'] = existing_df['trade_date'].apply(
                        lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, np.integer)) else x
                    )

                df = pd.concat([existing_df, df], ignore_index=True)
                df = df.drop_duplicates(subset=['trade_date'], keep='last')
                df = df.sort_values('trade_date', ascending=False)

            df.to_csv(csv_file, index=False)

        except Exception as e:
            self.logger.error(f"âŒ {etf_code} ä¿å­˜å¤±è´¥: {e}")
            raise

    def convert_to_qlib(self):
        """è½¬æ¢ä¸ºQlibæ ¼å¼"""
        self.logger.info("ğŸ”„ å¼€å§‹è½¬æ¢ä¸ºQlibæ ¼å¼...")

        # è°ƒç”¨è½¬æ¢è„šæœ¬
        convert_script = Path(__file__).parent / "etf_convert_qlib.py"

        if convert_script.exists():
            import subprocess
            cmd = [
                sys.executable,
                str(convert_script),
                "--source-dir", str(self.data_dir),
                "--qlib-dir", str(self.qlib_dir)
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)

            if result.returncode == 0:
                self.logger.info("âœ… Qlibæ ¼å¼è½¬æ¢å®Œæˆ")
                return True
            else:
                self.logger.error(f"âŒ è½¬æ¢å¤±è´¥: {result.stderr}")
                return False
        else:
            self.logger.warning(f"âš ï¸  è½¬æ¢è„šæœ¬ä¸å­˜åœ¨: {convert_script}")
            return False

    def run(self, full_download: bool = False):
        """æ‰§è¡Œæ›´æ–°"""
        self.logger.info("=" * 60)
        self.logger.info("ğŸš€ ETFæ•°æ®æ¯æ—¥æ›´æ–°å¼€å§‹")
        self.logger.info("=" * 60)

        etf_list = self.config.get("etf_list", [])

        if not etf_list:
            self.logger.error("âŒ é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ETFåˆ—è¡¨")
            self.logger.error("è¯·åœ¨ etf_config.yaml ä¸­é…ç½® etf_list")
            return

        self.stats["etf_list"] = etf_list
        self.logger.info(f"ğŸ“‹ å…± {len(etf_list)} ä¸ªETFå¾…æ›´æ–°")

        for etf_code in etf_list:
            try:
                # ç¡®å®šä¸‹è½½æ—¥æœŸèŒƒå›´
                if full_download:
                    start_date = None
                    self.logger.info(f"ğŸ“¥ {etf_code} å…¨é‡ä¸‹è½½...")
                else:
                    latest_date = self.get_latest_date(etf_code)
                    if latest_date:
                        next_date = (pd.Timestamp(latest_date) + timedelta(days=1)).strftime("%Y%m%d")
                        if next_date > datetime.now().strftime("%Y%m%d"):
                            self.logger.info(f"âœ… {etf_code} æ•°æ®å·²æ˜¯æœ€æ–°")
                            continue
                        start_date = next_date
                        self.logger.info(f"ğŸ“¥ {etf_code} å¢é‡æ›´æ–° (ä»{latest_date})...")
                    else:
                        start_date = None
                        self.logger.info(f"ğŸ“¥ {etf_code} é¦–æ¬¡ä¸‹è½½...")

                # ä¸‹è½½æ•°æ®
                df = self.download_etf_data(etf_code, start_date)

                if df is not None and not df.empty:
                    self.save_to_csv(df, etf_code)
                    self.stats["downloaded"].append(etf_code)
                    self.logger.info(f"âœ… {etf_code} ä¸‹è½½æˆåŠŸ ({len(df)} æ¡)")
                else:
                    self.stats["failed"].append(etf_code)
                    self.logger.warning(f"âš ï¸  {etf_code} æ— æ•°æ®æˆ–ä¸‹è½½å¤±è´¥")

                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(self.config.get("download_interval", 0.2))

            except Exception as e:
                self.logger.error(f"âŒ {etf_code} å¤„ç†å¤±è´¥: {e}")
                self.stats["failed"].append(etf_code)
                self.stats["errors"].append(f"{etf_code}: {str(e)}")

        # è½¬æ¢ä¸ºQlibæ ¼å¼
        if self.config.get("convert_to_qlib", True) and self.stats["downloaded"]:
            self.convert_to_qlib()

        # æ‰“å°æ‘˜è¦
        self.print_summary()

    def print_summary(self):
        """æ‰“å°æ›´æ–°æ‘˜è¦"""
        duration = (datetime.now() - self.stats["start_time"]).total_seconds()

        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ“Š æ›´æ–°æ‘˜è¦")
        self.logger.info("=" * 60)
        self.logger.info(f"æ€»ETFæ•°é‡: {len(self.stats['etf_list'])}")
        self.logger.info(f"æˆåŠŸæ›´æ–°: {len(self.stats['downloaded'])}")
        self.logger.info(f"å¤±è´¥: {len(self.stats['failed'])}")
        self.logger.info(f"è€—æ—¶: {duration:.2f} ç§’")

        if self.stats["failed"]:
            self.logger.info("\nâŒ å¤±è´¥åˆ—è¡¨:")
            for etf in self.stats["failed"][:10]:
                self.logger.info(f"  - {etf}")

        self.logger.info("=" * 60)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="ETFæ•°æ®æ¯æ—¥è‡ªåŠ¨æ›´æ–°",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        "--config",
        type=str,
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )

    parser.add_argument(
        "--full-download",
        action="store_true",
        help="å…¨é‡ä¸‹è½½å†å²æ•°æ®"
    )

    parser.add_argument(
        "--data-dir",
        type=str,
        default="~/.qlib/qlib_data/cn_data/etf_raw",
        help="åŸå§‹æ•°æ®ç›®å½•"
    )

    parser.add_argument(
        "--qlib-dir",
        type=str,
        default="~/.qlib/qlib_data/cn_data/etf",
        help="Qlibæ ¼å¼æ•°æ®ç›®å½•"
    )

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    try:
        updater = ETFDailyUpdater(
            data_dir=args.data_dir,
            qlib_dir=args.qlib_dir,
            config_file=args.config
        )

        updater.run(full_download=args.full_download)

        sys.exit(0 if not updater.stats["failed"] else 1)

    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
