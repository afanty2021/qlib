#!/usr/bin/env python3
"""
ETFæ•°æ®è½¬æ¢ä¸ºQlibæ ¼å¼è„šæœ¬

åŠŸèƒ½ï¼š
- å°†TuShareä¸‹è½½çš„ETF CSVæ•°æ®è½¬æ¢ä¸ºQlibæ ¼å¼
- ä½¿ç”¨Qlibçš„dump_binå·¥å…·è¿›è¡Œè½¬æ¢
- æ”¯æŒå¢é‡æ›´æ–°å’Œå…¨é‡è½¬æ¢

ä½¿ç”¨æ–¹å¼ï¼š
    python scripts/etf_convert_qlib.py --source-dir ~/.qlib/qlib_data/cn_data/etf_raw --qlib-dir ~/.qlib/qlib_data/cn_data/etf
"""

import os
import sys
import logging
import argparse
from pathlib import Path
from typing import List

import pandas as pd
import numpy as np
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from qlib.utils import fname_to_code, code_to_fname


class ETFDataConverter:
    """ETFæ•°æ®è½¬æ¢ä¸ºQlibæ ¼å¼"""

    def __init__(
        self,
        source_dir: str = "~/.qlib/qlib_data/cn_data/etf_raw",
        qlib_dir: str = "~/.qlib/qlib_data/cn_data/etf"
    ):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨

        Args:
            source_dir: åŸå§‹CSVæ•°æ®ç›®å½•
            qlib_dir: Qlibæ ¼å¼æ•°æ®è¾“å‡ºç›®å½•
        """
        self.source_dir = Path(source_dir).expanduser()
        self.qlib_dir = Path(qlib_dir).expanduser()

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.qlib_dir.mkdir(parents=True, exist_ok=True)

        # å­ç›®å½•
        self.calendars_dir = self.qlib_dir / "calendars"
        self.features_dir = self.qlib_dir / "features"
        self.instruments_dir = self.qlib_dir / "instruments"

        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_files": 0,
            "converted": 0,
            "failed": 0
        }

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        logger = logging.getLogger("ETFConverter")
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            # æ—¥å¿—æ ¼å¼
            log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            date_format = "%Y-%m-%d %H:%M:%S"
            formatter = logging.Formatter(log_format, date_format)

            # æ–‡ä»¶å¤„ç†å™¨
            log_file = self.qlib_dir / "convert.log"
            file_handler = logging.FileHandler(log_file, encoding="utf-8")
            file_handler.setLevel(logging.DEBUG)
            file_handler.setFormatter(formatter)

            # æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            console_handler.setFormatter(formatter)

            logger.addHandler(file_handler)
            logger.addHandler(console_handler)

        return logger

    def normalize_csv_data(self, csv_path: Path) -> pd.DataFrame:
        """
        æ ‡å‡†åŒ–CSVæ•°æ®ä¸ºQlibæ ¼å¼

        Args:
            csv_path: CSVæ–‡ä»¶è·¯å¾„

        Returns:
            æ ‡å‡†åŒ–åçš„DataFrame
        """
        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(csv_path)

            # æ£€æŸ¥å¿…è¦çš„åˆ—
            required_columns = ['trade_date', 'ts_code']
            missing_cols = [col for col in required_columns if col not in df.columns]
            if missing_cols:
                self.logger.warning(f"  âš ï¸  {csv_path.name} ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                return None

            # é‡å‘½ååˆ—ä»¥åŒ¹é…Qlibæ ¼å¼
            column_mapping = {
                'ts_code': 'symbol',
                'trade_date': 'date',
                'open': 'open',
                'high': 'high',
                'low': 'low',
                'close': 'close',
                'vol': 'volume',
                'amount': 'amount'
            }

            # åº”ç”¨åˆ—æ˜ å°„
            df = df.rename(columns=column_mapping)

            # ç¡®ä¿æœ‰volumeåˆ—
            if 'volume' not in df.columns and 'vol' in df.columns:
                df['volume'] = df['vol']

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')

            # æŒ‰æ—¥æœŸæ’åº
            df = df.sort_values('date')

            # æ·»åŠ factoråˆ—ï¼ˆè°ƒæ•´å› å­ï¼ŒETFè®¾ä¸º1.0ï¼‰
            if 'factor' not in df.columns:
                df['factor'] = 1.0

            # é€‰æ‹©éœ€è¦çš„åˆ—
            columns_order = ['date', 'symbol', 'open', 'high', 'low', 'close', 'volume', 'factor']
            available_columns = [col for col in columns_order if col in df.columns]
            df = df[available_columns]

            return df

        except Exception as e:
            self.logger.error(f"  âŒ æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return None

    def save_to_qlib_format(
        self,
        df: pd.DataFrame,
        etf_code: str,
        calendar_list: List[pd.Timestamp]
    ):
        """
        ä¿å­˜ä¸ºQlibäºŒè¿›åˆ¶æ ¼å¼

        Args:
            df: æ ‡å‡†åŒ–åçš„DataFrame
            etf_code: ETFä»£ç 
            calendar_list: äº¤æ˜“æ—¥å†åˆ—è¡¨
        """
        if df.empty:
            self.logger.warning(f"  âš ï¸  {etf_code} æ•°æ®ä¸ºç©º")
            return

        try:
            # åˆ›å»ºETFç‰¹å¾ç›®å½•
            etf_dir = self.features_dir / code_to_fname(etf_code).lower()
            etf_dir.mkdir(parents=True, exist_ok=True)

            # æŒ‰æ—¥æœŸå¯¹é½äº¤æ˜“æ—¥å†
            df.set_index('date', inplace=True)
            df_indexed = df.reindex(calendar_list)

            # ä¿å­˜å„å­—æ®µä¸ºäºŒè¿›åˆ¶æ ¼å¼
            fields = ['open', 'high', 'low', 'close', 'volume', 'factor']

            for field in fields:
                if field not in df_indexed.columns:
                    continue

                bin_file = etf_dir / f"{field}.day.bin"

                # è·å–å­—æ®µæ•°æ®
                data = df_indexed[field].values

                # å¤„ç†NaNå€¼
                data = np.nan_to_num(data, nan=0.0)

                # è½¬æ¢ä¸ºäºŒè¿›åˆ¶å¹¶ä¿å­˜
                data.astype('<f').tofile(str(bin_file))

            self.logger.info(f"  âœ… {etf_code} å·²è½¬æ¢ä¸ºQlibæ ¼å¼")

        except Exception as e:
            self.logger.error(f"  âŒ è½¬æ¢å¤±è´¥: {e}")
            raise

    def get_all_calendars(self, csv_files: List[Path]) -> List[pd.Timestamp]:
        """
        ä»æ‰€æœ‰CSVæ–‡ä»¶ä¸­è·å–äº¤æ˜“æ—¥å†

        Args:
            csv_files: CSVæ–‡ä»¶åˆ—è¡¨

        Returns:
            æ’åºåçš„äº¤æ˜“æ—¥å†åˆ—è¡¨
        """
        all_dates = set()

        for csv_file in tqdm(csv_files, desc="è¯»å–äº¤æ˜“æ—¥å†"):
            try:
                df = pd.read_csv(csv_file)
                if 'trade_date' in df.columns:
                    dates = pd.to_datetime(df['trade_date'], format='%Y%m%d')
                    all_dates.update(dates)
            except Exception as e:
                self.logger.warning(f"  âš ï¸  è¯»å– {csv_file.name} æ—¥æœŸå¤±è´¥: {e}")

        return sorted(all_dates)

    def save_calendars(self, calendar_list: List[pd.Timestamp]):
        """
        ä¿å­˜äº¤æ˜“æ—¥å†

        Args:
            calendar_list: äº¤æ˜“æ—¥å†åˆ—è¡¨
        """
        self.calendars_dir.mkdir(parents=True, exist_ok=True)
        calendar_file = self.calendars_dir / "day.txt"

        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        date_strings = [d.strftime('%Y-%m-%d') for d in calendar_list]

        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(calendar_file, 'w') as f:
            for date_str in date_strings:
                f.write(f"{date_str}\n")

        self.logger.info(f"âœ… äº¤æ˜“æ—¥å†å·²ä¿å­˜ ({len(calendar_list)} ä¸ªäº¤æ˜“æ—¥)")

    def save_instruments(self, etf_codes: List[str], calendar_list: List[pd.Timestamp]):
        """
        ä¿å­˜ETFåˆ—è¡¨æ–‡ä»¶

        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            calendar_list: äº¤æ˜“æ—¥å†åˆ—è¡¨
        """
        self.instruments_dir.mkdir(parents=True, exist_ok=True)
        instruments_file = self.instruments_dir / "all.txt"

        # è·å–æ¯ä¸ªETFçš„èµ·æ­¢æ—¥æœŸ
        instrument_info = []

        for etf_code in etf_codes:
            csv_file = self.source_dir / f"{etf_code}.csv"
            if not csv_file.exists():
                continue

            try:
                df = pd.read_csv(csv_file)
                if 'trade_date' in df.columns and len(df) > 0:
                    dates = pd.to_datetime(df['trade_date'], format='%Y%m%d')
                    start_date = dates.min().strftime('%Y-%m-%d')
                    end_date = dates.max().strftime('%Y-%m-%d')

                    instrument_info.append(f"{etf_code}\t{start_date}\t{end_date}\n")

            except Exception as e:
                self.logger.warning(f"  âš ï¸  è·å– {etf_code} ä¿¡æ¯å¤±è´¥: {e}")

        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(instruments_file, 'w') as f:
            f.writelines(instrument_info)

        self.logger.info(f"âœ… ETFåˆ—è¡¨å·²ä¿å­˜ ({len(instrument_info)} ä¸ªETF)")

    def convert_all(self):
        """è½¬æ¢æ‰€æœ‰ETFæ•°æ®"""
        self.logger.info("=" * 60)
        self.logger.info("ğŸ”„ å¼€å§‹è½¬æ¢ä¸ºQlibæ ¼å¼")
        self.logger.info("=" * 60)

        # è·å–æ‰€æœ‰CSVæ–‡ä»¶
        csv_files = sorted(self.source_dir.glob("*.csv"))
        self.stats["total_files"] = len(csv_files)

        if not csv_files:
            self.logger.warning(f"âŒ åœ¨ {self.source_dir} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
            return False

        self.logger.info(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")

        # è·å–äº¤æ˜“æ—¥å†
        self.logger.info("\nğŸ“… æ„å»ºäº¤æ˜“æ—¥å†...")
        calendar_list = self.get_all_calendars(csv_files)
        self.save_calendars(calendar_list)

        # æå–ETFä»£ç åˆ—è¡¨
        etf_codes = [csv.stem for csv in csv_files]

        # ä¿å­˜ETFåˆ—è¡¨
        self.logger.info("\nğŸ“ ä¿å­˜ETFåˆ—è¡¨...")
        self.save_instruments(etf_codes, calendar_list)

        # è½¬æ¢æ¯ä¸ªETFæ•°æ®
        self.logger.info("\nğŸ”„ è½¬æ¢ETFæ•°æ®...")
        for csv_file in tqdm(csv_files, desc="è½¬æ¢è¿›åº¦"):
            etf_code = csv_file.stem

            try:
                # æ ‡å‡†åŒ–æ•°æ®
                df = self.normalize_csv_data(csv_file)

                if df is not None:
                    # è½¬æ¢ä¸ºQlibæ ¼å¼
                    self.save_to_qlib_format(df, etf_code, calendar_list)
                    self.stats["converted"] += 1
                else:
                    self.stats["failed"] += 1

            except Exception as e:
                self.logger.error(f"âŒ {etf_code} è½¬æ¢å¤±è´¥: {e}")
                self.stats["failed"] += 1

        return True

    def print_summary(self):
        """æ‰“å°è½¬æ¢æ‘˜è¦"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ“Š è½¬æ¢æ‘˜è¦")
        self.logger.info("=" * 60)
        self.logger.info(f"æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        self.logger.info(f"æˆåŠŸ: {self.stats['converted']}")
        self.logger.info(f"å¤±è´¥: {self.stats['failed']}")
        self.logger.info("=" * 60)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="ETFæ•°æ®è½¬æ¢ä¸ºQlibæ ¼å¼",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        "--source-dir",
        type=str,
        default="~/.qlib/qlib_data/cn_data/etf_raw",
        help="åŸå§‹CSVæ•°æ®ç›®å½•"
    )

    parser.add_argument(
        "--qlib-dir",
        type=str,
        default="~/.qlib/qlib_data/cn_data/etf",
        help="Qlibæ ¼å¼æ•°æ®è¾“å‡ºç›®å½•"
    )

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # åˆ›å»ºè½¬æ¢å™¨
    converter = ETFDataConverter(
        source_dir=args.source_dir,
        qlib_dir=args.qlib_dir
    )

    # æ‰§è¡Œè½¬æ¢
    success = converter.convert_all()

    # æ‰“å°æ‘˜è¦
    converter.print_summary()

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
