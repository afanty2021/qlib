#!/usr/bin/env python3
"""
æ¼”ç¤ºå¦‚ä½•åœ¨qlibä¸­ä½¿ç”¨ä¸‹è½½çš„ä¸Šè¯æŒ‡æ•°å’Œæ²ªæ·±300æ•°æ®

ä¸‹è½½çš„æ•°æ®åŒ…æ‹¬ï¼š
1. ä¸Šè¯æŒ‡æ•°(000001.SH)è¿‘5å¹´æ—¥çº¿æ•°æ®
2. æ²ªæ·±300æˆåˆ†è‚¡è¿‘5å¹´æ—¥çº¿æ•°æ®
3. å·²è½¬æ¢ä¸ºqlibæ ‡å‡†æ ¼å¼çš„æ•°æ®
"""

import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ Qlibè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

def load_and_inspect_data():
    """åŠ è½½å¹¶æ£€æŸ¥ä¸‹è½½çš„æ•°æ®"""
    print("=" * 80)
    print("ğŸ“Š åŠ è½½å¹¶æ£€æŸ¥ä¸‹è½½çš„æ•°æ®")
    print("=" * 80)

    # æ–‡ä»¶åˆ—è¡¨
    files = {
        "ä¸Šè¯æŒ‡æ•°åŸå§‹æ•°æ®": "shanghai_index_5years.csv",
        "ä¸Šè¯æŒ‡æ•°Qlibæ ¼å¼": "shanghai_index_5years_qlib_format.csv",
        "æ²ªæ·±300åŸå§‹æ•°æ®": "csi300_stocks_5years.csv",
        "æ²ªæ·±300Qlibæ ¼å¼": "csi300_stocks_5years_qlib_format.csv"
    }

    loaded_data = {}

    for name, filename in files.items():
        if os.path.exists(filename):
            print(f"\nğŸ“ åŠ è½½ {name}: {filename}")
            try:
                df = pd.read_csv(filename)
                loaded_data[name] = df
                print(f"   âœ… æ•°æ®å½¢çŠ¶: {df.shape}")
                print(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {df.iloc[0]['date'] if 'date' in df.columns else df.index[0]} è‡³ {df.iloc[-1]['date'] if 'date' in df.columns else df.index[-1]}")
                print(f"   ğŸ“Š åˆ—å: {list(df.columns)}")

                # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
                if len(df) > 0:
                    print(f"   ğŸ“‹ æ•°æ®ç¤ºä¾‹:")
                    print(f"      {df.head(2).to_string()}")
            except Exception as e:
                print(f"   âŒ åŠ è½½å¤±è´¥: {e}")
        else:
            print(f"\nâš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")

    return loaded_data

def analyze_shanghai_index(data):
    """åˆ†æä¸Šè¯æŒ‡æ•°æ•°æ®"""
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ä¸Šè¯æŒ‡æ•°æ•°æ®åˆ†æ")
    print("=" * 80)

    if "ä¸Šè¯æŒ‡æ•°Qlibæ ¼å¼" not in data:
        print("âŒ æœªæ‰¾åˆ°ä¸Šè¯æŒ‡æ•°æ•°æ®")
        return

    df = data["ä¸Šè¯æŒ‡æ•°Qlibæ ¼å¼"].copy()

    # è½¬æ¢æ—¥æœŸåˆ—
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date')

    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {df['date'].min().strftime('%Y-%m-%d')} è‡³ {df['date'].max().strftime('%Y-%m-%d')}")
    print(f"   ğŸ“ˆ æ€»äº¤æ˜“æ—¥: {len(df)} å¤©")
    print(f"   ğŸ’° æœ€æ–°æ”¶ç›˜ä»·: {df['close'].iloc[-1]:.2f}")
    print(f"   ğŸ“Š æœŸé—´æœ€é«˜ä»·: {df['high'].max():.2f}")
    print(f"   ğŸ“Š æœŸé—´æœ€ä½ä»·: {df['low'].min():.2f}")
    print(f"   ğŸ“Š å¹³å‡æˆäº¤é‡: {df['volume'].mean():,.0f}")

    # è®¡ç®—æ”¶ç›Šç‡
    df['returns'] = df['close'].pct_change()
    df['cumulative_returns'] = (1 + df['returns']).cumprod()

    print(f"\nğŸ“ˆ æ”¶ç›Šç‡åˆ†æ:")
    total_return = (df['close'].iloc[-1]/df['close'].iloc[0] - 1) * 100
    annual_return = ((df['close'].iloc[-1]/df['close'].iloc[0])**(252/len(df)) - 1) * 100
    annual_volatility = df['returns'].std() * np.sqrt(252) * 100
    max_dd = calculate_max_drawdown(df['close'])

    print(f"   ğŸ“Š æœŸé—´æ€»æ”¶ç›Šç‡: {total_return:.2f}%")
    print(f"   ğŸ“Š å¹´åŒ–æ”¶ç›Šç‡: {annual_return:.2f}%")
    print(f"   ğŸ“Š å¹´åŒ–æ³¢åŠ¨ç‡: {annual_volatility:.2f}%")
    print(f"   ğŸ“Š æœ€å¤§å›æ’¤: {max_dd:.2f}%")

    # å°è¯•åˆ›å»ºç®€å•çš„å›¾è¡¨
    try:
        plt.figure(figsize=(12, 8))

        # ä»·æ ¼èµ°åŠ¿å›¾
        plt.subplot(2, 2, 1)
        plt.plot(df['date'], df['close'], linewidth=1)
        plt.title('ä¸Šè¯æŒ‡æ•°æ”¶ç›˜ä»·èµ°åŠ¿')
        plt.xlabel('æ—¥æœŸ')
        plt.ylabel('æ”¶ç›˜ä»·')
        plt.xticks(rotation=45)

        # æˆäº¤é‡å›¾
        plt.subplot(2, 2, 2)
        plt.plot(df['date'], df['volume']/1e8, linewidth=1, color='orange')
        plt.title('ä¸Šè¯æŒ‡æ•°æˆäº¤é‡')
        plt.xlabel('æ—¥æœŸ')
        plt.ylabel('æˆäº¤é‡(äº¿æ‰‹)')
        plt.xticks(rotation=45)

        # ç´¯ç§¯æ”¶ç›Šç‡å›¾
        plt.subplot(2, 2, 3)
        plt.plot(df['date'], (df['cumulative_returns'] - 1) * 100, linewidth=1, color='green')
        plt.title('ä¸Šè¯æŒ‡æ•°ç´¯ç§¯æ”¶ç›Šç‡')
        plt.xlabel('æ—¥æœŸ')
        plt.ylabel('ç´¯ç§¯æ”¶ç›Šç‡(%)')
        plt.xticks(rotation=45)

        # æ”¶ç›Šç‡åˆ†å¸ƒ
        plt.subplot(2, 2, 4)
        plt.hist(df['returns'].dropna() * 100, bins=50, alpha=0.7, color='red')
        plt.title('æ—¥æ”¶ç›Šç‡åˆ†å¸ƒ')
        plt.xlabel('æ—¥æ”¶ç›Šç‡(%)')
        plt.ylabel('é¢‘æ•°')

        plt.tight_layout()
        chart_file = "shanghai_index_analysis.png"
        plt.savefig(chart_file, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"\nğŸ“Š å›¾è¡¨å·²ä¿å­˜: {chart_file}")

    except Exception as e:
        print(f"\nâš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")

def analyze_csi300_stocks(data):
    """åˆ†ææ²ªæ·±300æˆåˆ†è‚¡æ•°æ®"""
    print("\n" + "=" * 80)
    print("ğŸ¢ æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®åˆ†æ")
    print("=" * 80)

    if "æ²ªæ·±300Qlibæ ¼å¼" not in data:
        print("âŒ æœªæ‰¾åˆ°æ²ªæ·±300æ•°æ®")
        return

    df = data["æ²ªæ·±300Qlibæ ¼å¼"].copy()

    # è½¬æ¢æ—¥æœŸåˆ—
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(['instrument', 'date'])

    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   ğŸ¢ è‚¡ç¥¨æ•°é‡: {df['instrument'].nunique()}")
    print(f"   ğŸ“… äº¤æ˜“æ—¥æœŸ: {df['date'].nunique()} å¤©")
    print(f"   ğŸ“ˆ æ€»æ•°æ®ç‚¹: {len(df):,}")

    # æŒ‰è‚¡ç¥¨åˆ†ç»„ç»Ÿè®¡
    stock_stats = df.groupby('instrument').agg({
        'close': ['first', 'last', 'mean', 'std'],
        'volume': 'mean'
    }).round(2)

    stock_stats.columns = ['æœŸåˆä»·', 'æœŸæœ«ä»·', 'å¹³å‡ä»·', 'ä»·æ ¼æ ‡å‡†å·®', 'å¹³å‡æˆäº¤é‡']
    stock_stats['æœŸé—´æ”¶ç›Šç‡(%)'] = ((stock_stats['æœŸæœ«ä»·'] / stock_stats['æœŸåˆä»·'] - 1) * 100).round(2)

    print(f"\nğŸ“ˆ è‚¡ç¥¨è¡¨ç°æ’å (å‰10):")
    top_performers = stock_stats.sort_values('æœŸé—´æ”¶ç›Šç‡(%)', ascending=False).head(10)
    print(top_performers.to_string())

    print(f"\nğŸ“‰ è‚¡ç¥¨è¡¨ç°æ’å (å10):")
    bottom_performers = stock_stats.sort_values('æœŸé—´æ”¶ç›Šç‡(%)', ascending=True).head(10)
    print(bottom_performers.to_string())

    # è®¡ç®—æ•´ä½“ç»Ÿè®¡
    print(f"\nğŸ“Š æ•´ä½“ç»Ÿè®¡:")
    print(f"   ğŸ“ˆ å¹³å‡æ”¶ç›Šç‡: {stock_stats['æœŸé—´æ”¶ç›Šç‡(%)'].mean():.2f}%")
    print(f"   ğŸ“Š æ”¶ç›Šç‡ä¸­ä½æ•°: {stock_stats['æœŸé—´æ”¶ç›Šç‡(%)'].median():.2f}%")
    positive_count = (stock_stats['æœŸé—´æ”¶ç›Šç‡(%)'] > 0).sum()
    negative_count = (stock_stats['æœŸé—´æ”¶ç›Šç‡(%)'] <= 0).sum()
    positive_pct = (stock_stats['æœŸé—´æ”¶ç›Šç‡(%)'] > 0).mean() * 100
    negative_pct = (stock_stats['æœŸé—´æ”¶ç›Šç‡(%)'] <= 0).mean() * 100

    print(f"   ğŸ“ˆ æ­£æ”¶ç›Šè‚¡ç¥¨æ•°: {positive_count} åª ({positive_pct:.1f}%)")
    print(f"   ğŸ“‰ è´Ÿæ”¶ç›Šè‚¡ç¥¨æ•°: {negative_count} åª ({negative_pct:.1f}%)")
    print(f"   ğŸ“Š æ”¶ç›Šç‡æ ‡å‡†å·®: {stock_stats['æœŸé—´æ”¶ç›Šç‡(%)'].std():.2f}%")

def calculate_max_drawdown(prices):
    """è®¡ç®—æœ€å¤§å›æ’¤"""
    peak = pd.Series(prices).expanding().max()
    drawdown = (pd.Series(prices) - peak) / peak
    return drawdown.min() * 100

def demonstrate_qlib_usage():
    """æ¼”ç¤ºå¦‚ä½•åœ¨qlibä¸­ä½¿ç”¨è¿™äº›æ•°æ®"""
    print("\n" + "=" * 80)
    print("ğŸ¯ Qlibæ•°æ®ä½¿ç”¨æ¼”ç¤º")
    print("=" * 80)

    print("""
ğŸ’¡ åœ¨Qlibä¸­ä½¿ç”¨ä¸‹è½½çš„æ•°æ®æœ‰å‡ ç§æ–¹å¼ï¼š

1. ğŸ“ ç›´æ¥åŠ è½½CSVæ–‡ä»¶
   ```python
   import pandas as pd

   # åŠ è½½ä¸Šè¯æŒ‡æ•°æ•°æ®
   index_data = pd.read_csv('shanghai_index_5years_qlib_format.csv')
   index_data['date'] = pd.to_datetime(index_data['date'])

   # åŠ è½½æ²ªæ·±300æ•°æ®
   stock_data = pd.read_csv('csi300_stocks_5years_qlib_format.csv')
   stock_data['date'] = pd.to_datetime(stock_data['date'])
   ```

2. ğŸ”„ è½¬æ¢ä¸ºQlibæ•°æ®æ ¼å¼
   ```python
   from qlib.data import D

   # å°†æ•°æ®è®¾ç½®ä¸ºQlibå¯ç”¨æ ¼å¼
   # éœ€è¦å°†æ•°æ®æ”¾åœ¨æ­£ç¡®çš„ç›®å½•ç»“æ„ä¸­
   # å¹¶æŒ‰Qlibè¦æ±‚çš„æ•°æ®æ ¼å¼ç»„ç»‡
   ```

3. ğŸ“Š æ•°æ®åˆ†æå’Œå¯è§†åŒ–
   ```python
   import matplotlib.pyplot as plt

   # åŸºæœ¬åˆ†æ
   stock_returns = stock_data.groupby('instrument').apply(
       lambda x: (x['close'].iloc[-1] / x['close'].iloc[0] - 1) * 100
   )

   # å¯è§†åŒ–
   plt.figure(figsize=(12, 6))
   plt.hist(stock_returns, bins=30, alpha=0.7)
   plt.title('æ²ªæ·±300æˆåˆ†è‚¡æœŸé—´æ”¶ç›Šç‡åˆ†å¸ƒ')
   plt.xlabel('æ”¶ç›Šç‡(%)')
   plt.ylabel('è‚¡ç¥¨æ•°é‡')
   plt.show()
   ```

4. ğŸ¤– æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ
   ```python
   from qlib.data.dataset import DatasetH
   from qlib.contrib.model.gbdt import LGBModel

   # åˆ›å»ºæ•°æ®é›†
   dataset = DatasetH(
       handler=data_handler,
       segments={'train': ('2020-11-27', '2023-11-27'),
                'test': ('2023-11-28', '2025-11-26')}
   )

   # è®­ç»ƒæ¨¡å‹
   model = LGBModel(loss='mse', learning_rate=0.1)
   model.fit(dataset)
   ```

ğŸ“‹ æ•°æ®æ ¼å¼è¯´æ˜ï¼š
- æ‰€æœ‰æ•°æ®å·²è½¬æ¢ä¸ºQlibæ ‡å‡†æ ¼å¼
- æ—¥æœŸæ ¼å¼ï¼šYYYY-MM-DD
- è‚¡ç¥¨ä»£ç ï¼šSZ000001, SH600000 ç­‰
- å­—æ®µï¼šopen, high, low, close, volume, amount
- æ•°æ®å·²æŒ‰æ—¥æœŸæ’åº

ğŸ”§ åç»­ä½¿ç”¨å»ºè®®ï¼š
1. å¯ä»¥æ ¹æ®éœ€è¦ç­›é€‰ç‰¹å®šæ—¶é—´èŒƒå›´
2. å¯ä»¥æ·»åŠ æ›´å¤šæŠ€æœ¯æŒ‡æ ‡
3. å¯ä»¥ä¸å…¶ä»–æ•°æ®æºè¿›è¡Œæ•´åˆ
4. å¯ä»¥ç›´æ¥ç”¨äºç­–ç•¥å›æµ‹å’Œæ¨¡å‹è®­ç»ƒ
    """)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¸Šè¯æŒ‡æ•°å’Œæ²ªæ·±300æ•°æ®åˆ†ææ¼”ç¤º")
    print("=" * 80)

    # åŠ è½½æ•°æ®
    loaded_data = load_and_inspect_data()

    # åˆ†æä¸Šè¯æŒ‡æ•°
    analyze_shanghai_index(loaded_data)

    # åˆ†ææ²ªæ·±300æˆåˆ†è‚¡
    analyze_csi300_stocks(loaded_data)

    # æ¼”ç¤ºQlibä½¿ç”¨æ–¹æ³•
    demonstrate_qlib_usage()

    print("\n" + "=" * 80)
    print("ğŸ‰ æ•°æ®åˆ†ææ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)
    print("\nğŸ’¡ æç¤º:")
    print("   ğŸ“Š æ•°æ®æ–‡ä»¶å·²ä¿å­˜åœ¨å½“å‰ç›®å½•")
    print("   ğŸ“ˆ å¯ä»¥ç›´æ¥ç”¨äºé‡åŒ–åˆ†æå’Œç­–ç•¥å¼€å‘")
    print("   ğŸ¤– å»ºè®®ç»“åˆQlibçš„æœºå™¨å­¦ä¹ æ¨¡å—è¿›è¡Œæ·±åº¦åˆ†æ")
    print("   ğŸ“š æ›´å¤šä½¿ç”¨æ–¹æ³•è¯·å‚è€ƒQlibå®˜æ–¹æ–‡æ¡£")

if __name__ == "__main__":
    main()