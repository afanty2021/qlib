
# 工作流管理

<cite>
**本文档中引用的文件**  
- [run_all_model.py](file://examples/run_all_model.py)
- [exp.py](file://qlib/workflow/exp.py)
- [recorder.py](file://qlib/workflow/recorder.py)
- [manager.py](file://qlib/workflow/online/manager.py)
- [strategy.py](file://qlib/workflow/online/strategy.py)
- [update.py](file://qlib/workflow/online/update.py)
- [rolling_online_management.py](file://examples/online_srv/rolling_online_management.py)
</cite>

## 目录
1. [引言](#引言)
2. [实验与记录器机制](#实验与记录器机制)
3. [MLflow集成与追踪系统](#mlflow集成与追踪系统)
4. [在线服务模块分析](#在线服务模块分析)
5. [批量模型工作流组织](#批量模型工作流组织)
6. [记录器生命周期与资产管理](#记录器生命周期与资产管理)
7. [分布式任务调度](#分布式任务调度)
8. [生产级部署最佳实践](#生产级部署最佳实践)
9. [监控方案](#监控方案)
10. [结论](#结论)

## 引言
本文档全面阐述了Qlib框架中的实验管理和工作流自动化系统的运作机制。重点解释了Experiment和Recorder如何与MLflow集成以实现完整的实验追踪、指标记录和模型版本管理。详细描述了在线服务模块（online/）如何支持模型的滚动更新、预测服务部署和实时推理。通过run_all_model.py示例说明了批量运行多个模型工作流的组织方式。涵盖了记录器生命周期、资产保存、元数据管理以及分布式任务调度等关键方面，并提供了生产级部署的最佳实践和监控方案。

## 实验与记录器机制

### Experiment类架构
`Experiment`类是每个实验运行的核心容器，其API设计类似于MLflow。该类负责管理实验的整个生命周期，包括创建、启动、结束和查询记录器。每个实验实例包含唯一的ID和名称，并维护一个活动记录器（active_recorder），确保同一时间只有一个记录器处于运行状态。

```mermaid
classDiagram
class Experiment {
+string id
+string name
+Recorder active_recorder
+dict info()
+start(recorder_id, recorder_name, resume)
+end(recorder_status)
+create_recorder(recorder_name)
+get_recorder(recorder_id, recorder_name, create, start)
+list_recorders(rtype, **flt_kwargs)
}
class MLflowExperiment {
+string _uri
+MlflowClient _client
+start(recorder_id, recorder_name, resume)
+end(recorder_status)
+create_recorder(recorder_name)
+_get_recorder(recorder_id, recorder_name)
+search_records(**kwargs)
+delete_recorder(recorder_id, recorder_name)
+list_recorders(rtype, max_results, status, filter_string)
}
Experiment <|-- MLflowExperiment : "继承"
```

**图源**
- [exp.py](file://qlib/workflow/exp.py#L14-L239)

### Recorder类架构
`Recorder`类用于记录实验过程中的各种信息，包括参数、指标、标签和工件。它是实验追踪的基本单元，支持多种状态（SCHEDULED, RUNNING, FINISHED, FAILED）。每个记录器关联到一个特定的实验，并通过唯一的ID进行标识。

```mermaid
classDiagram
class Recorder {
+string id
+string name
+string experiment_id
+datetime start_time
+datetime end_time
+string status
+dict info()
+save_objects(local_path, artifact_path, **kwargs)
+load_object(name)
+start_run()
+end_run()
+log_params(**kwargs)
+log_metrics(step, **kwargs)
+log_artifact(local_path, artifact_path)
+set_tags(**kwargs)
+delete_tags(*keys)
+list_artifacts(artifact_path)
+download_artifact(path, dst_path)
+list_metrics()
+list_params()
+list_tags()
}
class MLflowRecorder {
+string _uri
+string _artifact_uri
+MlflowClient client
+AsyncCaller async_log
+get_local_dir()
+start_run()
+_log_uncommitted_code()
+end_run(status)
+save_objects(local_path, artifact_path, **kwargs)
+load_object(name, unpickler)
+log_params(**kwargs)
+log_metrics(step, **kwargs)
+set_tags(**kwargs)
+delete_tags(*keys)
+get_artifact_uri()
+list_artifacts(artifact_path)
+download_artifact(path, dst_path)
+list_metrics()
+list_params()
+list_tags()
}
Recorder <|-- MLflowRecorder : "继承"
```

**图源**
- [recorder.py](file://qlib/workflow/recorder.py#L27-L243)

**本节来源**
- [exp.py](file://qlib/workflow/exp.py#L14-L239)
- [recorder.py](file://qlib/workflow/recorder.py#L27-L243)

## MLflow集成与追踪系统

### MLflow实验管理器
Qlib通过`MLflowExpManager`实现了与MLflow的深度集成。在初始化时，可以通过配置指定使用MLflow作为实验管理后端：

```python
qlib.init(
    exp_manager={
        "class": "MLflowExpManager",
        "module_path": "qlib.workflow.expm",
        "kwargs": {
            "uri": "file:" + str(Path(os.getcwd()).resolve() / exp_folder_name),
            "default_exp_name": "Experiment",
        },
    }
)
```

这种集成允许将所有实验数据存储在本地文件系统或远程服务器上，支持跨团队协作和结果复现。

### 指标与参数记录流程
当调用`log_metrics`或`log_params`方法时，MLflowRecorder会异步地将数据发送到MLflow服务器。这通过`AsyncCaller`装饰器实现，提高了系统的响应速度：

```mermaid
sequenceDiagram
participant User as "用户代码"
participant Recorder as "MLflowRecorder"
participant Client as "MlflowClient"
participant Backend as "MLflow后端"
User->>Recorder : log_metrics(step=1, loss=0.5)
Recorder->>Recorder : @AsyncCaller.async_dec
Recorder->>Client : log_metric(run_id, name, value, step)
Client->>Backend : 发送指标数据
Backend-->>Client : 确认接收
Client-->>Recorder : 返回结果
Recorder-->>User : 完成记录
Note over Recorder,Client : 异步执行避免阻塞主进程
```

**图源**
- [recorder.py](file://qlib/workflow/recorder.py#L132-L141)

### 工件存储与加载
`save_objects`方法支持将模型检查点、预测文件等重要资产保存到指定位置。系统支持两种模式：直接保存本地路径或通过关键字参数传递对象。

```mermaid
flowchart TD
Start([开始保存对象]) --> CheckPath["检查local_path是否存在"]
CheckPath --> |存在| SaveByPath["使用client.log_artifacts<br/>或client.log_artifact"]
CheckPath --> |不存在| CreateTemp["创建临时目录"]
CreateTemp --> DumpObjects["序列化kwargs中的对象"]
DumpObjects --> LogArtifacts["调用client.log_artifact"]
LogArtifacts --> Cleanup["清理临时目录"]
Cleanup --> End([完成])
SaveByPath --> End
```

**图源**
- [recorder.py](file://qlib/workflow/recorder.py#L73-L87)

**本节来源**
- [exp.py](file://qlib/workflow/exp.py#L43-L60)
- [recorder.py](file://qlib/workflow/recorder.py#L104-L113)
- [recorder.py](file://qlib/workflow/recorder.py#L115-L119)

## 在线服务模块分析

### OnlineManager核心功能
`OnlineManager`负责管理一组"在线策略"并动态执行它们。它支持四种不同的训练场景组合：

| 场景 | 描述 |
|------|------|
| 在线 + Trainer | 实时交易中，Trainer帮助训练模型，按任务和策略顺序进行 |
| 在线 + DelayTrainer | 延迟训练器会跳过具体训练直到所有任务准备完毕，适合并行训练 |
| 模拟 + Trainer | 与"在线 + Trainer"行为相同，但用于回测而非实盘交易 |
| 模拟 + DelayTrainer | 当模型没有时间依赖性时，可利用DelayTrainer实现多任务能力 |

```mermaid
classDiagram
class OnlineManager {
+List[OnlineStrategy] strategies
+Trainer trainer
+pd.Timestamp begin_time
+pd.Timestamp cur_time
+dict history
+STATUS_SIMULATING = "simulating"
+STATUS_ONLINE = "online"
+first_train(strategies, model_kwargs)
+routine(cur_time, task_kwargs, model_kwargs, signal_kwargs)
+get_collector(**kwargs)
+add_strategy(strategies)
+prepare_signals(prepare_func, over_write)
+get_signals()
+simulate(end_time, frequency, task_kwargs, model_kwargs, signal_kwargs)
+delay_prepare(model_kwargs, signal_kwargs)
}
class OnlineStrategy {
+string name_id
+prepare_tasks(cur_time, **kwargs)
+prepare_online_models(trained_models, cur_time)
+first_tasks()
+get_collector()
}
class RollingStrategy {
+string exp_name
+List[dict] task_template
+RollingGen rg
+TimeAdjuster ta
+get_collector(process_list, rec_key_func, rec_filter_func, artifacts_key)
+first_tasks()
+prepare_tasks(cur_time)
+_list_latest(rec_list)
}
OnlineManager --> OnlineStrategy : "管理"
OnlineStrategy <|-- RollingStrategy : "扩展"
```

**图源**
- [manager.py](file://qlib/workflow/online/manager.py#L145-L382)
- [strategy.py](file://qlib/workflow/online/strategy.py#L100-L208)

### 滚动策略实现
`RollingStrategy`是一个具体的在线策略实现，总是使用最新的滚动模型作为在线模型。它基于`RollingGen`生成器来创建不同时间段的任务。

```mermaid
sequenceDiagram
participant OM as "OnlineManager"
participant RS as "RollingStrategy"
participant RG as "RollingGen"
participant T as "task_generator"
OM->>RS : first_train()
RS->>T : task_generator(tasks, generators=RG)
T->>RG : gen_following_tasks(task, calendar_latest)
RG-->>T : 返回新任务列表
T-->>RS : 返回任务列表
RS-->>OM : 返回任务供训练
OM->>RS : routine(cur_time)
RS->>_list_latest : 获取最新记录器
_list_latest-->>RS : 返回最新记录器和测试结束时间
RS->>RG : gen_following_tasks(基于最新任务)
RG-->>RS : 返回后续任务
RS-->>OM : 返回新任务供训练
```

**图源**
- [strategy.py](file://qlib/workflow/online/strategy.py#L100-L208)

### 预测更新机制
`PredUpdater`类负责在股票数据更新时更新预测结果。它基于Qlib Dataset提供数据集级别的更新功能。

```mermaid
flowchart TD
Start([开始更新预测]) --> LoadOld["加载旧预测数据"]
LoadOld --> GetLastEnd["确定最后日期last_end"]
GetLastEnd --> CalcStart["计算start_time_buffer"]
CalcStart --> PrepareDS["prepare_data()"]
PrepareDS --> LoadModel["从记录器加载模型"]
LoadModel --> Predict["model.predict(dataset)"]
Predict --> Replace["_replace_range(old_data, new_pred)"]
Replace --> Save["save_objects(pred.pkl=updated_data)"]
Save --> End([完成更新])
```

**图源**
- [update.py](file://qlib/workflow/online/update.py#L200-L298)

**本节来源**
- [manager.py](file://qlib/workflow/online/manager.py#L145-L382)
- [strategy.py](file://qlib/workflow/online/strategy.py#L100-L208)
- [update.py](file://qlib/workflow/online/update.py#L200-L298)

## 批量模型工作流组织

### run_all_model.py整体架构
`run_all_model.py`脚本提供了一个完整的批量模型工作流组织框架，支持多种运行模式和参数配置。

```mermaid
classDiagram
class ModelRunner {
+_init_qlib(exp_folder_name)
+run(times, models, dataset, universe, exclude, qlib_uri, exp_folder_name, wait_before_rm_env, wait_when_err)
+_collect_results(exp_folder_name, dataset)
}
class HelperFunctions {
+only_allow_defined_args(function_to_decorate)
+handler(signum, frame)
+cal_mean_std(results)
+create_env()
+execute(cmd, wait_when_err, raise_err)
+get_all_folders(models, exclude)
+get_all_files(folder_path, dataset, universe)
+get_all_results(folders)
+gen_and_save_md_table(metrics, dataset)
+gen_yaml_file_without_seed_kwargs(yaml_path, temp_dir)
}
ModelRunner --> HelperFunctions : "使用"
```

**图源**
- [run_all_model.py](file://examples/run_all_model.py#L1-L403)

### 运行流程控制
脚本的运行流程遵循严格的环境隔离原则，为每个模型创建独立的conda环境以避免依赖冲突。

```mermaid
flowchart TD
Start([开始运行]) --> InitQLIB["初始化QLIB"]
InitQLIB --> GetFolders["获取所有模型文件夹"]
GetFolders --> LoopModels["遍历每个模型"]
LoopModels --> CreateEnv["创建临时conda环境"]
CreateEnv --> InstallReq["安装requirements.txt"]
InstallReq --> InstallQLIB["安装QLIB包"]
InstallQLIB --> RunWorkflow["执行qrun命令多次"]
RunWorkflow --> Cleanup["删除临时环境"]
Cleanup --> NextModel["下一个模型"]
NextModel --> CollectResults["收集所有结果"]
CollectResults --> GenTable["生成Markdown表格"]
GenTable --> MoveFiles["移动结果文件夹"]
MoveFiles --> End([完成])
```

**图源**
- [run_all_model.py](file://examples/run_all_model.py#L1-L403)

### 结果收集与展示
结果收集过程包括检索已完成的实验记录、计算统计指标和生成可视化报告。

```mermaid
sequenceDiagram
participant MR as "ModelRunner"
participant R as "R.get_exp"
participant Exp as "Experiment"
participant Rec as "Recorder"
MR->>R : get_all_results(folders)
loop 每个文件夹
R->>Exp : get_exp(experiment_name=fn, create=False)
Exp->>Rec : list_recorders()
loop 每个记录器
Rec->>Rec : status == "FINISHED"
Rec->>Rec : load_object("task")
Rec->>Rec : list_metrics()
Rec->>MR : 返回指标数据
end
end
MR->>MR : cal_mean_std(results)
MR->>MR : gen_and_save_md_table()
MR->>MR : 移动结果文件夹
```

**图源**
- [run_all_model.py](file://examples/run_all_model.py#L1-L403)

**本节来源**
- [run_all_model.py](file://examples/run_all_model.py#L1-L403)

## 记录器生命周期与资产管理

### 生命周期管理
记录器的完整生命周期包括创建、启动、记录、结束四个阶段，每个阶段都有明确的状态转换规则。

```mermaid
stateDiagram-v2
[*] --> SCHEDULED
SCHEDULED --> RUNNING : start_run()
RUNNING --> FINISHED : end_run(STATUS_FI)
RUNNING --> FAILED : end_run(STATUS_FA)
RUNNING --> SCHEDULED : 异常终止
FINISHED --> [*]
FAILED --> [*]
```

**图源**
- [recorder.py](file://qlib/workflow/recorder.py#L27-L243)

### 资产保存策略
系统采用分层的资产保存策略，区分不同类型的数据存储需求。

| 资产类型 | 存储方式 | 访问方式 | 备注 |
|---------|--------|--------|------|
| 模型参数 | pickle序列化 | load_object("params.pkl") | 包含完整模型状态 |
| 数据集配置 | 序列化存储 | load_object("dataset") | 可重新构建数据集 |
| 预测结果 | pandas DataFrame | load_object("pred.pkl") | 多级索引结构 |
| 任务配置 | 序列化存储 | load_object("task") | 完整的任务定义 |
| 自定义工件 | 直接保存 | log_artifact() | 支持任意文件 |

**本节来源**
- [recorder.py](file://qlib/workflow/recorder.py#L73-L87)

## 分布式任务调度

### 任务生成机制
系统通过`task_generator`和`RollingGen`协同工作来生成滚动任务序列。

```mermaid
flowchart TD
Start([开始生成任务]) --> CheckTemplate["检查task_template类型"]
CheckTemplate --> |单个模板| ConvertToList["转换为列表"]
CheckTemplate --> |列表| UseDirectly["直接使用"]
ConvertToList --> UseDirectly
UseDirectly --> LoopTemplate["遍历每个模板"]
LoopTemplate --> CreateGenerator["创建RollingGen实例"]
CreateGenerator --> GenerateTasks["调用gen_following_tasks"]
GenerateTasks --> AddToResult["添加到结果列表"]
AddToResult --> NextTemplate["下一个模板"]
NextTemplate --> CheckMore["是否有更多模板"]
CheckMore --> |是| LoopTemplate
CheckMore --> |否| ReturnResult["返回任务列表"]
ReturnResult --> End([完成])
```

**本节来源**
- [strategy.py](file://qlib/workflow/online/strategy.py#L100-L208)

### 并行训练支持
通过`DelayTrainer`机制实现延迟训练，支持大规模并行处理。

```mermaid
sequenceDiagram
participant OM as "OnlineManager"
participant DT as "DelayTrainer"
participant TM as "TaskManager"
OM->>DT : first_train()
DT->>TM : 注册所有任务
loop 每个策略
OM->>DT : prepare_tasks()
DT->>TM : 添加新任务
end
OM->>DT : delay_prepare()
DT->>TM : 批量训练所有待处理任务
TM-->>DT : 返回训练好的模型
DT-->>OM : 完成准备
```

**本节来源**
- [rolling_online_management.py](file://examples/online_srv/rolling_online_management.py#L1-L144)

## 生产级部署最佳实践

### 环境隔离
建议为每个模型创建独立的conda环境，避免依赖冲突：

```bash