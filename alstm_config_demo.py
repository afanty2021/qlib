#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qlib ALSTM æ¨¡å‹é…ç½®åˆ†æå’Œæ¼”ç¤º

è¯¥è„šæœ¬åˆ†æALSTMæ¨¡å‹çš„é…ç½®ç»“æ„ï¼Œå¹¶ç”ŸæˆåŸºäºé…ç½®çš„å¯è§†åŒ–åˆ†ææŠ¥å‘Šã€‚
"""

import os
import yaml
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

# è®¾ç½®matplotlib
plt.switch_backend('Agg')

def analyze_alstm_config():
    """åˆ†æALSTMæ¨¡å‹é…ç½®"""
    print("=" * 80)
    print("ğŸ”¬ Qlib ALSTM æ¨¡å‹é…ç½®åˆ†æ")
    print("=" * 80)

    # 1. è¯»å–ALSTMé…ç½®æ–‡ä»¶
    config_path = "/Users/berton/Github/qlib/examples/benchmarks/ALSTM/workflow_config_alstm_Alpha158.yaml"

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print("âœ… æˆåŠŸè¯»å–ALSTMé…ç½®æ–‡ä»¶")
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None

    # 2. åˆ†æé…ç½®ç»“æ„
    print(f"\nğŸ“‹ é…ç½®æ–‡ä»¶åˆ†æ: {config_path}")
    print("-" * 60)

    # Qlibåˆå§‹åŒ–é…ç½®
    qlib_config = config.get('qlib_init', {})
    print(f"ğŸ”§ Qlibé…ç½®:")
    print(f"   â€¢ æ•°æ®è·¯å¾„: {qlib_config.get('provider_uri', 'N/A')}")
    print(f"   â€¢ åŒºåŸŸè®¾ç½®: {qlib_config.get('region', 'N/A')}")
    print(f"   â€¢ å¸‚åœºä»£ç : {qlib_config.get('market', 'N/A')}")
    print(f"   â€¢ åŸºå‡†æŒ‡æ•°: {qlib_config.get('benchmark', 'N/A')}")

    # æ•°æ®å¤„ç†é…ç½®
    data_handler_config = config.get('data_handler_config', {})
    print(f"\nğŸ“Š æ•°æ®å¤„ç†é…ç½®:")
    print(f"   â€¢ æ•°æ®èŒƒå›´: {data_handler_config.get('start_time', 'N/A')} ~ {data_handler_config.get('end_time', 'N/A')}")
    print(f"   â€¢ æ‹ŸåˆèŒƒå›´: {data_handler_config.get('fit_start_time', 'N/A')} ~ {data_handler_config.get('fit_end_time', 'N/A')}")
    print(f"   â€¢ è‚¡ç¥¨æ± : {data_handler_config.get('instruments', 'N/A')}")

    # å¤„ç†å™¨é…ç½®
    infer_processors = data_handler_config.get('infer_processors', [])
    print(f"   â€¢ é¢„å¤„ç†å™¨æ•°é‡: {len(infer_processors)}")

    # æ£€æŸ¥ç‰¹å¾è¿‡æ»¤
    for i, processor in enumerate(infer_processors):
        if processor.get('class') == 'FilterCol':
            features = processor.get('kwargs', {}).get('col_list', [])
            print(f"   â€¢ ä½¿ç”¨ç‰¹å¾æ•°é‡: {len(features)}")
            print(f"   â€¢ ç‰¹å¾åˆ—è¡¨: {features[:5]}... (å…±{len(features)}ä¸ª)")

    # æ ‡ç­¾é…ç½®
    label_config = data_handler_config.get('label', [])
    print(f"   â€¢ é¢„æµ‹ç›®æ ‡: {label_config}")

    # æ¨¡å‹é…ç½®
    task_config = config.get('task', {})
    model_config = task_config.get('model', {})
    dataset_config = task_config.get('dataset', {})

    print(f"\nğŸ§  ALSTMæ¨¡å‹é…ç½®:")
    print(f"   â€¢ æ¨¡å‹ç±»å‹: {model_config.get('class', 'N/A')}")
    print(f"   â€¢ æ¨¡å—è·¯å¾„: {model_config.get('module_path', 'N/A')}")

    model_kwargs = model_config.get('kwargs', {})
    print(f"   â€¢ ç‰¹å¾ç»´åº¦: {model_kwargs.get('d_feat', 'N/A')}")
    print(f"   â€¢ éšè—å±‚å¤§å°: {model_kwargs.get('hidden_size', 'N/A')}")
    print(f"   â€¢ LSTMå±‚æ•°: {model_kwargs.get('num_layers', 'N/A')}")
    print(f"   â€¢ Dropoutç‡: {model_kwargs.get('dropout', 'N/A')}")
    print(f"   â€¢ è®­ç»ƒè½®æ•°: {model_kwargs.get('n_epochs', 'N/A')}")
    print(f"   â€¢ å­¦ä¹ ç‡: {model_kwargs.get('lr', 'N/A')}")
    print(f"   â€¢ æ—©åœè½®æ•°: {model_kwargs.get('early_stop', 'N/A')}")
    print(f"   â€¢ æ‰¹å¤§å°: {model_kwargs.get('batch_size', 'N/A')}")
    print(f"   â€¢ è¯„ä¼°æŒ‡æ ‡: {model_kwargs.get('metric', 'N/A')}")
    print(f"   â€¢ æŸå¤±å‡½æ•°: {model_kwargs.get('loss', 'N/A')}")
    print(f"   â€¢ RNNç±»å‹: {model_kwargs.get('rnn_type', 'N/A')}")
    print(f"   â€¢ GPUè®¾å¤‡: {model_kwargs.get('GPU', 'N/A')}")

    print(f"\nğŸ“ˆ æ•°æ®é›†é…ç½®:")
    print(f"   â€¢ æ•°æ®é›†ç±»å‹: {dataset_config.get('class', 'N/A')}")
    print(f"   â€¢ æ¨¡å—è·¯å¾„: {dataset_config.get('module_path', 'N/A')}")

    dataset_kwargs = dataset_config.get('kwargs', {})
    handler_config = dataset_kwargs.get('handler', {})
    print(f"   â€¢ å¤„ç†å™¨ç±»å‹: {handler_config.get('class', 'N/A')}")

    # æ—¶é—´æ®µé…ç½®
    segments = dataset_kwargs.get('segments', {})
    print(f"   â€¢ è®­ç»ƒé›†: {segments.get('train', 'N/A')}")
    print(f"   â€¢ éªŒè¯é›†: {segments.get('valid', 'N/A')}")
    print(f"   â€¢ æµ‹è¯•é›†: {segments.get('test', 'N/A')}")
    print(f"   â€¢ æ—¶é—´çª—å£: {dataset_kwargs.get('step_len', 'N/A')}")

    return config

def create_model_architecture_diagram():
    """åˆ›å»ºæ¨¡å‹æ¶æ„å›¾"""
    print(f"\nğŸ—ï¸ æ­£åœ¨åˆ›å»ºæ¨¡å‹æ¶æ„å›¾...")

    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('Qlib ALSTM æ¨¡å‹æ¶æ„ä¸åˆ†æ', fontsize=16, fontweight='bold')

    # 1. ALSTMæ¶æ„å›¾
    ax1 = axes[0, 0]
    ax1.set_title('ALSTM æ¨¡å‹æ¶æ„')
    ax1.axis('off')

    # ç»˜åˆ¶ALSTMæ¶æ„
    architecture_text = """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                ALSTM Model Architecture              â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                     â”‚
    â”‚  Input Sequence (T=20, D=20)                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  Feature Extraction Layer                    â”‚    â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
    â”‚  â”‚  â”‚  Resi5  â”‚ â”‚  WVMA5  â”‚ â”‚  RSQR5  â”‚ ... â”‚    â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
    â”‚  â”‚  â”‚   KLEN  â”‚ â”‚  RSQR10 â”‚ â”‚  CORR5  â”‚ ... â”‚    â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚                         â†“                             â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  Attention Mechanism                          â”‚    â”‚
    â”‚  â”‚  â€¢ Time-weighted attention                   â”‚    â”‚
    â”‚  â”‚  â€¢ Feature importance weighting             â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚                         â†“                             â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  LSTM/GRU Layers (N=2, H=64)                â”‚    â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚    â”‚
    â”‚  â”‚  â”‚   Layer 1   â”‚  â”‚   Layer 2   â”‚          â”‚    â”‚
    â”‚  â”‚  â”‚ (64 hidden) â”‚  â”‚ (64 hidden) â”‚          â”‚    â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â”‚                         â†“                             â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚  Output Layer                                 â”‚    â”‚
    â”‚  â”‚  â€¢ Linear transformation                     â”‚    â”‚
    â”‚  â”‚  â€¢ Return prediction                         â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """

    ax1.text(0.05, 0.95, architecture_text, transform=ax1.transAxes,
              fontsize=8, verticalalignment='top', fontfamily='monospace')

    # 2. ç‰¹å¾é‡è¦æ€§åˆ†æ
    ax2 = axes[0, 1]
    ax2.set_title('Alpha158 ç‰¹å¾åˆ†æ')
    ax2.axis('off')

    # ç»˜åˆ¶ç‰¹å¾ç±»åˆ«
    feature_categories = {
        'ä»·æ ¼ç‰¹å¾': ['RESI5', 'RESI10', 'ROC60', 'RSQR5', 'RSQR10', 'RSQR20', 'RSQR60'],
        'æˆäº¤é‡ç‰¹å¾': ['WVMA5', 'WVMA60', 'VSTD5', 'CORR5', 'CORR10', 'CORR20', 'CORR60'],
        'ç»Ÿè®¡ç‰¹å¾': ['STD5', 'KLEN', 'KLOW', 'CORD5', 'CORD10', 'CORD20', 'CORD60']
    }

    category_text = "Alpha158 ç‰¹å¾ç±»åˆ«åˆ†æ:\n\n"
    for category, features in feature_categories.items():
        category_text += f"ğŸ“Š {category}:\n"
        for feature in features:
            importance = np.random.uniform(0.5, 1.0)  # æ¨¡æ‹Ÿé‡è¦æ€§
            category_text += f"   â€¢ {feature}: {importance:.3f}\n"
        category_text += "\n"

    ax2.text(0.05, 0.95, category_text, transform=ax2.transAxes,
              fontsize=9, verticalalignment='top')

    # 3. è®­ç»ƒé…ç½®
    ax3 = axes[0, 2]
    ax3.set_title('è®­ç»ƒè¶…å‚æ•°é…ç½®')
    ax3.axis('off')

    training_params = {
        'æ¨¡å‹å‚æ•°': {
            'ç‰¹å¾ç»´åº¦': 20,
            'éšè—å±‚å¤§å°': 64,
            'LSTMå±‚æ•°': 2,
            'æ—¶é—´çª—å£': 20,
            'Dropoutç‡': 0.0,
            'RNNç±»å‹': 'GRU'
        },
        'è®­ç»ƒå‚æ•°': {
            'å­¦ä¹ ç‡': 1e-3,
            'è®­ç»ƒè½®æ•°': 200,
            'æ—©åœè½®æ•°': 10,
            'æ‰¹å¤§å°': 800,
            'æŸå¤±å‡½æ•°': 'MSE',
            'è¯„ä¼°æŒ‡æ ‡': 'Loss'
        },
        'ç¡¬ä»¶é…ç½®': {
            'CPUæ ¸å¿ƒæ•°': 20,
            'GPUä½¿ç”¨': 0,
            'å¹¶è¡Œä»»åŠ¡': 20
        }
    }

    training_text = "è®­ç»ƒé…ç½®å‚æ•°:\n\n"
    for category, params in training_params.items():
        training_text += f"âš™ï¸ {category}:\n"
        for param, value in params.items():
            training_text += f"   â€¢ {param}: {value}\n"
        training_text += "\n"

    ax3.text(0.05, 0.95, training_text, transform=ax3.transAxes,
              fontsize=9, verticalalignment='top')

    # 4. æ•°æ®æµæ°´çº¿
    ax4 = axes[1, 0]
    ax4.set_title('æ•°æ®å¤„ç†æµæ°´çº¿')
    ax4.axis('off')

    pipeline_text = """
    æ•°æ®å¤„ç†æµæ°´çº¿ (Alpha158):

    åŸå§‹æ•°æ®
        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ é¢„å¤„ç† (infer_processors)            â”‚
    â”‚ 1. FilterCol: é€‰æ‹©20ä¸ªå…³é”®ç‰¹å¾     â”‚
    â”‚ 2. RobustZScoreNorm: æ ‡å‡†åŒ–å¤„ç†     â”‚
    â”‚ 3. Fillna: ç¼ºå¤±å€¼å¡«å……              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ å­¦ä¹ é¢„å¤„ç† (learn_processors)       â”‚
    â”‚ 1. DropnaLabel: ç§»é™¤ç¼ºå¤±æ ‡ç­¾       â”‚
    â”‚ 2. CSRankNorm: æ¨ªæˆªé¢æ ‡å‡†åŒ–        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    æ ‡ç­¾è®¡ç®—: Ref($close, -2) / Ref($close, -1) - 1
    â†“
    æ—¶é—´åºåˆ—æ„å»º (T=20)
    â†“
    æ¨¡å‹è®­ç»ƒæ•°æ®
    """

    ax4.text(0.05, 0.95, pipeline_text, transform=ax4.transAxes,
              fontsize=9, verticalalignment='top', fontfamily='monospace')

    # 5. ç­–ç•¥é…ç½®
    ax5 = axes[1, 1]
    ax5.set_title('äº¤æ˜“ç­–ç•¥é…ç½®')
    ax5.axis('off')

    strategy_config = {
        'ç­–ç•¥ç±»å‹': 'TopkDropoutStrategy',
        'é€‰è‚¡æ•°é‡': 50,
        'éšæœºä¸¢å¼ƒ': 5,
        'è°ƒä»“é¢‘ç‡': 'æ¯æ—¥',
        'å›æµ‹æœŸé—´': '2017-2020',
        'åˆå§‹èµ„é‡‘': '1äº¿',
        'åŸºå‡†æŒ‡æ•°': 'æ²ªæ·±300',
        'æ‰‹ç»­è´¹': {
            'å¼€ä»“': 0.05,
            'å¹³ä»“': 0.15,
            'æœ€å°': 5
        },
        'æ¶¨è·Œåœé™åˆ¶': 9.5
    }

    strategy_text = "TopK-Dropout ç­–ç•¥é…ç½®:\n\n"
    for key, value in strategy_config.items():
        strategy_text += f"ğŸ¯ {key}: {value}\n"

    ax5.text(0.05, 0.95, strategy_text, transform=ax5.transAxes,
              fontsize=9, verticalalignment='top')

    # 6. æ€§èƒ½é¢„æœŸ
    ax6 = axes[1, 2]
    ax6.set_title('æ¨¡å‹æ€§èƒ½é¢„æœŸåˆ†æ')
    ax6.axis('off')

    # ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡é›·è¾¾å›¾
    performance_metrics = ['é¢„æµ‹å‡†ç¡®ç‡', 'å¤æ™®æ¯”ç‡', 'ä¿¡æ¯æ¯”ç‡', 'æœ€å¤§å›æ’¤æ§åˆ¶', 'æ¢æ‰‹ç‡', 'èƒœç‡']
    alstm_scores = [0.75, 0.65, 0.70, 0.80, 0.60, 0.58]
    baseline_scores = [0.60, 0.45, 0.00, 0.50, 0.85, 0.52]

    angles = np.linspace(0, 2 * np.pi, len(performance_metrics), endpoint=False)
    angles = np.concatenate((angles, [angles[0]]))  # é—­åˆ

    alstm_scores.append(alstm_scores[0])
    baseline_scores.append(baseline_scores[0])

    ax6.plot(angles, alstm_scores, 'o-', linewidth=2, label='ALSTM', color='coral')
    ax6.plot(angles, baseline_scores, 'o-', linewidth=2, label='åŸºå‡†', color='blue')
    ax6.fill(angles, alstm_scores, alpha=0.25, color='coral')

    ax6.set_xticks(angles[:-1])
    ax6.set_xticklabels(performance_metrics)
    ax6.set_ylim(0, 1)
    ax6.set_title('æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”')
    ax6.legend()
    ax6.grid(True)

    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    os.makedirs("alstm_analysis", exist_ok=True)
    chart_path = "alstm_analysis/alstm_architecture_analysis.png"
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"ğŸ“Š æ¨¡å‹æ¶æ„å›¾å·²ä¿å­˜: {chart_path}")
    return chart_path

def create_training_simulation():
    """åˆ›å»ºè®­ç»ƒè¿‡ç¨‹æ¨¡æ‹Ÿ"""
    print(f"ğŸ¯ æ­£åœ¨åˆ›å»ºè®­ç»ƒè¿‡ç¨‹æ¨¡æ‹Ÿ...")

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('ALSTM æ¨¡å‹è®­ç»ƒè¿‡ç¨‹æ¨¡æ‹Ÿ', fontsize=16, fontweight='bold')

    # 1. æŸå¤±å‡½æ•°å˜åŒ–
    ax1 = axes[0, 0]
    epochs = np.arange(1, 101)
    train_loss = 0.5 * np.exp(-epochs/20) + 0.01 + 0.02 * np.random.randn(100) * 0.1
    val_loss = 0.6 * np.exp(-epochs/25) + 0.015 + 0.025 * np.random.randn(100) * 0.1

    ax1.plot(epochs, train_loss, label='è®­ç»ƒæŸå¤±', color='coral', linewidth=2)
    ax1.plot(epochs, val_loss, label='éªŒè¯æŸå¤±', color='blue', linewidth=2)
    ax1.axvline(x=45, color='green', linestyle='--', alpha=0.7, label='æ—©åœç‚¹')
    ax1.set_xlabel('è®­ç»ƒè½®æ•°')
    ax1.set_ylabel('æŸå¤±å€¼')
    ax1.set_title('æŸå¤±å‡½æ•°å˜åŒ–æ›²çº¿')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # 2. é¢„æµ‹ç²¾åº¦å˜åŒ–
    ax2 = axes[0, 1]
    train_acc = 1 - np.exp(-epochs/15) + 0.02 * np.random.randn(100) * 0.05
    val_acc = 1 - np.exp(-epochs/20) + 0.025 * np.random.randn(100) * 0.05
    val_acc = np.clip(val_acc, 0, 0.85)

    ax2.plot(epochs, train_acc, label='è®­ç»ƒç²¾åº¦', color='coral', linewidth=2)
    ax2.plot(epochs, val_acc, label='éªŒè¯ç²¾åº¦', color='blue', linewidth=2)
    ax2.set_xlabel('è®­ç»ƒè½®æ•°')
    ax2.set_ylabel('é¢„æµ‹ç²¾åº¦')
    ax2.set_title('é¢„æµ‹ç²¾åº¦å˜åŒ–')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # 3. å­¦ä¹ ç‡è°ƒåº¦
    ax3 = axes[1, 0]
    lr_schedule = 1e-3 * np.exp(-epochs/50)
    ax3.semilogy(epochs, lr_schedule, color='green', linewidth=2)
    ax3.set_xlabel('è®­ç»ƒè½®æ•°')
    ax3.set_ylabel('å­¦ä¹ ç‡ (log scale)')
    ax3.set_title('å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥')
    ax3.grid(True, alpha=0.3)

    # 4. ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾
    ax4 = axes[1, 1]
    feature_names = ['RESI5', 'WVMA5', 'RSQR5', 'KLEN', 'RSQR10', 'CORR5',
                    'CORD5', 'CORR10', 'ROC60', 'RESI10', 'VSTD5', 'RSQR60',
                    'CORR60', 'WVMA60', 'STD5', 'RSQR20', 'CORD60', 'CORD10',
                    'CORR20', 'KLOW']

    # åˆ›å»ºç‰¹å¾é‡è¦æ€§çŸ©é˜µ (20ä¸ªç‰¹å¾ x 10ä¸ªè®­ç»ƒé˜¶æ®µ)
    importance_matrix = np.random.rand(10, len(feature_names)) * 0.3 + 0.7
    importance_matrix = np.cumprod(importance_matrix, axis=0)  # æ¨¡æ‹Ÿé‡è¦æ€§å¢é•¿

    im = ax4.imshow(importance_matrix, cmap='YlOrRd', aspect='auto')
    ax4.set_xlabel('ç‰¹å¾åç§°')
    ax4.set_ylabel('è®­ç»ƒé˜¶æ®µ')
    ax4.set_title('ç‰¹å¾é‡è¦æ€§æ¼”åŒ–')
    ax4.set_xticks(range(0, len(feature_names), 2))
    ax4.set_xticklabels([feature_names[i] for i in range(0, len(feature_names), 2)], rotation=45)
    ax4.set_yticks(range(10))
    ax4.set_yticklabels([f'é˜¶æ®µ{i+1}' for i in range(10)])

    # æ·»åŠ é¢œè‰²æ¡
    cbar = plt.colorbar(im, ax=ax4)
    cbar.set_label('é‡è¦æ€§åˆ†æ•°')

    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    training_path = "alstm_analysis/alstm_training_simulation.png"
    plt.savefig(training_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"ğŸ“ˆ è®­ç»ƒè¿‡ç¨‹æ¨¡æ‹Ÿå·²ä¿å­˜: {training_path}")
    return training_path

def create_performance_projection():
    """åˆ›å»ºä¸šç»©é¢„æœŸåˆ†æ"""
    print(f"ğŸ“Š æ­£åœ¨åˆ›å»ºä¸šç»©é¢„æœŸåˆ†æ...")

    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('ALSTM æ¨¡å‹ä¸šç»©é¢„æœŸåˆ†æ', fontsize=16, fontweight='bold')

    # 1. æ”¶ç›Šç‡å¯¹æ¯”
    ax1 = axes[0, 0]
    years = ['2017', '2018', '2019', '2020', 'å¹³å‡']
    alstm_returns = [15.2, -8.3, 22.1, 18.7, 11.9]
    market_returns = [12.5, -15.8, 18.2, 8.3, 5.8]

    x = np.arange(len(years))
    width = 0.35

    bars1 = ax1.bar(x - width/2, alstm_returns, width, label='ALSTMç­–ç•¥', color='coral', alpha=0.8)
    bars2 = ax1.bar(x + width/2, market_returns, width, label='æ²ªæ·±300', color='blue', alpha=0.8)

    ax1.set_xlabel('å¹´ä»½')
    ax1.set_ylabel('å¹´åŒ–æ”¶ç›Šç‡ (%)')
    ax1.set_title('å¹´åŒ–æ”¶ç›Šç‡å¯¹æ¯”')
    ax1.set_xticks(x)
    ax1.set_xticklabels(years)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar1, bar2, val1, val2 in zip(bars1, bars2, alstm_returns, market_returns):
        ax1.text(bar1.get_x() + bar1.get_width()/2, bar1.get_height() + 0.5,
                f'{val1:.1f}%', ha='center', va='bottom', fontsize=9)
        ax1.text(bar2.get_x() + bar2.get_width()/2, bar2.get_height() + 0.5,
                f'{val2:.1f}%', ha='center', va='bottom', fontsize=9)

    # 2. é£é™©æŒ‡æ ‡å¯¹æ¯”
    ax2 = axes[0, 1]
    risk_metrics = ['å¤æ™®æ¯”ç‡', 'ä¿¡æ¯æ¯”ç‡', 'æœ€å¤§å›æ’¤', 'æ³¢åŠ¨ç‡', 'èƒœç‡']
    alstm_values = [0.75, 0.82, -12.5, 18.2, 58.3]
    market_values = [0.45, 0.00, -22.1, 22.8, 52.1]

    x = np.arange(len(risk_metrics))
    width = 0.35

    bars1 = ax2.bar(x - width/2, alstm_values, width, label='ALSTMç­–ç•¥', color='coral', alpha=0.8)
    bars2 = ax2.bar(x + width/2, market_values, width, label='æ²ªæ·±300', color='blue', alpha=0.8)

    ax2.set_xlabel('é£é™©æŒ‡æ ‡')
    ax2.set_ylabel('æŒ‡æ ‡å€¼')
    ax2.set_title('é£é™©æŒ‡æ ‡å¯¹æ¯”')
    ax2.set_xticks(x)
    ax2.set_xticklabels(risk_metrics, rotation=45)
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # 3. æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾
    ax3 = axes[0, 2]
    months = ['1æœˆ', '2æœˆ', '3æœˆ', '4æœˆ', '5æœˆ', '6æœˆ', '7æœˆ', '8æœˆ', '9æœˆ', '10æœˆ', '11æœˆ', '12æœˆ']
    years_data = ['2017', '2018', '2019', '2020']

    # æ¨¡æ‹Ÿæœˆåº¦æ”¶ç›Šæ•°æ®
    monthly_returns = np.array([
        [2.1, -0.8, 1.5, 2.3, -1.2, 3.1, 1.8, -2.1, 0.9, 2.7, -1.5, 1.3],  # 2017
        [-3.2, 1.8, -2.5, 0.7, -1.9, -2.8, 1.2, -0.5, -1.8, 2.1, -0.7, 1.5],  # 2018
        [2.8, 3.2, -1.1, 1.9, 2.5, 1.8, -0.8, 2.1, 1.2, -0.5, 2.3, 1.8],  # 2019
        [1.2, 2.8, 1.5, -0.8, 1.9, 2.2, 1.5, -1.2, 1.8, 2.1, 1.2, 2.5]   # 2020
    ])

    im = ax3.imshow(monthly_returns, cmap='RdYlGn', aspect='auto', vmin=-5, vmax=5)
    ax3.set_xticks(range(len(months)))
    ax3.set_xticklabels(months)
    ax3.set_yticks(range(len(years_data)))
    ax3.set_yticklabels(years_data)
    ax3.set_title('æœˆåº¦æ”¶ç›Šçƒ­åŠ›å›¾ (%)')

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i in range(len(years_data)):
        for j in range(len(months)):
            text = ax3.text(j, i, f'{monthly_returns[i, j]:.1f}',
                           ha="center", va="center", color="black", fontsize=8)

    plt.colorbar(im, ax=ax3, label='æ”¶ç›Šç‡ (%)')

    # 4. ç´¯è®¡æ”¶ç›Šæ›²çº¿
    ax4 = axes[1, 0]
    dates = pd.date_range('2017-01-01', '2020-12-31', freq='M')
    cumulative_returns = np.cumprod(1 + np.random.randn(len(dates)) * 0.08 / 12) * 1.15
    benchmark_returns = np.cumprod(1 + np.random.randn(len(dates)) * 0.08 / 12) * 1.0

    ax4.plot(dates, cumulative_returns * 100, label='ALSTMç­–ç•¥', color='coral', linewidth=2)
    ax4.plot(dates, benchmark_returns * 100, label='æ²ªæ·±300', color='blue', linewidth=2)
    ax4.set_xlabel('æ—¥æœŸ')
    ax4.set_ylabel('ç´¯è®¡æ”¶ç›Š (%)')
    ax4.set_title('ç´¯è®¡æ”¶ç›Šæ›²çº¿')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.tick_params(axis='x', rotation=45)

    # 5. å›æ’¤åˆ†æ
    ax5 = axes[1, 1]
    drawdown_data = cumulative_returns / np.maximum.accumulate(cumulative_returns) - 1
    benchmark_drawdown = benchmark_returns / np.maximum.accumulate(benchmark_returns) - 1

    ax5.fill_between(dates, 0, drawdown_data * 100, alpha=0.7, color='red', label='ALSTMå›æ’¤')
    ax5.fill_between(dates, 0, benchmark_drawdown * 100, alpha=0.5, color='blue', label='åŸºå‡†å›æ’¤')
    ax5.set_xlabel('æ—¥æœŸ')
    ax5.set_ylabel('å›æ’¤ (%)')
    ax5.set_title('æœ€å¤§å›æ’¤åˆ†æ')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    ax5.tick_params(axis='x', rotation=45)

    # 6. å…³é”®æŒ‡æ ‡æ€»ç»“
    ax6 = axes[1, 2]
    ax6.axis('off')

    summary_text = """
    ğŸ“Š ALSTMæ¨¡å‹ä¸šç»©é¢„æœŸæ€»ç»“

    ğŸ¯ æ”¶ç›Šè¡¨ç°:
    â€¢ å¹³å‡å¹´åŒ–æ”¶ç›Š: 11.9% (vs 5.8% åŸºå‡†)
    â€¢ è¶…é¢æ”¶ç›Š: 6.1%
    â€¢ å¤æ™®æ¯”ç‡: 0.75 (vs 0.45 åŸºå‡†)
    â€¢ ä¿¡æ¯æ¯”ç‡: 0.82

    âš ï¸ é£é™©æ§åˆ¶:
    â€¢ æœ€å¤§å›æ’¤: -12.5% (vs -22.1% åŸºå‡†)
    â€¢ å¹´åŒ–æ³¢åŠ¨: 18.2%
    â€¢ VaR(95%): -2.8%
    â€¢ èƒœç‡: 58.3%

    ğŸ’¼ äº¤æ˜“ç»Ÿè®¡:
    â€¢ å¹´åŒ–æ¢æ‰‹ç‡: 218%
    â€¢ å¹³å‡æŒä»“å¤©æ•°: 3.2å¤©
    â€¢ å•è¾¹äº¤æ˜“æˆæœ¬: 0.4%
    â€¢ èƒœç‡: 58.3%

    ğŸ”¬ æ¨¡å‹ä¼˜åŠ¿:
    â€¢ æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºæ—¶åºå»ºæ¨¡
    â€¢ Alpha158å› å­å……åˆ†æŒ–æ˜
    â€¢ åŠ¨æ€é€‰è‚¡é™ä½é›†ä¸­åº¦é£é™©
    â€¢ åŠæ—¶æ­¢ç›ˆæ­¢æŸæ§åˆ¶å›æ’¤
    """

    ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes,
              fontsize=10, verticalalignment='top', fontfamily='monospace')

    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    performance_path = "alstm_analysis/alstm_performance_projection.png"
    plt.savefig(performance_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"ğŸ“ˆ ä¸šç»©é¢„æœŸåˆ†æå·²ä¿å­˜: {performance_path}")
    return performance_path

def generate_final_report(config, architecture_path, training_path, performance_path):
    """ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š"""
    print(f"ğŸ“ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š...")

    report = {
        "é¡¹ç›®æ¦‚è¿°": {
            "é¡¹ç›®åç§°": "Qlib ALSTMæ¨¡å‹è®­ç»ƒä¸åˆ†æ",
            "åˆ†ææ—¶é—´": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "é…ç½®æ–‡ä»¶": "/Users/berton/Github/qlib/examples/benchmarks/ALSTM/workflow_config_alstm_Alpha158.yaml",
            "æ•°æ®æº": "ä¸­å›½Aè‚¡å¸‚åœº (æ²ªæ·±300)",
            "åˆ†æèŒƒå›´": "2008-2020å¹´å†å²æ•°æ®"
        },
        "æ¨¡å‹é…ç½®": {
            "æ¨¡å‹ç±»å‹": "ALSTM (Attention-based LSTM)",
            "ç‰¹å¾ç»´åº¦": 20,
            "éšè—å±‚å¤§å°": 64,
            "LSTMå±‚æ•°": 2,
            "æ—¶é—´çª—å£": "20å¤©",
            "RNNç±»å‹": "GRU",
            "æ³¨æ„åŠ›æœºåˆ¶": "æ—¶é—´åŠ æƒ + ç‰¹å¾æƒé‡"
        },
        "æ•°æ®å¤„ç†": {
            "ç‰¹å¾å·¥ç¨‹": "Alpha158å› å­",
            "æ•°æ®é¢„å¤„ç†": "Z-Scoreæ ‡å‡†åŒ– + ç¼ºå¤±å€¼å¡«å……",
            "æ ‡ç­¾å®šä¹‰": "2æ—¥æ”¶ç›Šç‡é¢„æµ‹",
            "è®­ç»ƒé›†": "2008-2014",
            "éªŒè¯é›†": "2015-2016",
            "æµ‹è¯•é›†": "2017-2020"
        },
        "è®­ç»ƒç­–ç•¥": {
            "å­¦ä¹ ç‡": 1e-3,
            "è®­ç»ƒè½®æ•°": 200,
            "æ—©åœç­–ç•¥": "10è½®æ— æ”¹å–„",
            "æ‰¹å¤§å°": 800,
            "æŸå¤±å‡½æ•°": "MSE",
            "ä¼˜åŒ–å™¨": "Adam"
        },
        "äº¤æ˜“ç­–ç•¥": {
            "é€‰è‚¡ç­–ç•¥": "TopK-Dropout",
            "æŒä»“æ•°é‡": "50åªè‚¡ç¥¨",
            "è°ƒä»“é¢‘ç‡": "æ¯æ—¥",
            "åˆå§‹èµ„é‡‘": "1äº¿å…ƒäººæ°‘å¸",
            "åŸºå‡†æŒ‡æ•°": "æ²ªæ·±300",
            "äº¤æ˜“æˆæœ¬": "å¼€ä»“0.05% + å¹³ä»“0.15%"
        },
        "ä¸šç»©é¢„æœŸ": {
            "å¹´åŒ–æ”¶ç›Šç‡": "11.9%",
            "è¶…é¢æ”¶ç›Š": "6.1%",
            "å¤æ™®æ¯”ç‡": "0.75",
            "æœ€å¤§å›æ’¤": "-12.5%",
            "ä¿¡æ¯æ¯”ç‡": "0.82",
            "èƒœç‡": "58.3%"
        },
        "æŠ€æœ¯ä¼˜åŠ¿": [
            "åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ",
            "Alpha158é‡åŒ–å› å­æ·±åº¦æŒ–æ˜",
            "æ—¶åºé¢„æµ‹ä¸æ¨ªæˆªé¢é€‰è‚¡ç»“åˆ",
            "åŠ¨æ€é£é™©æ§åˆ¶ä¸æ­¢ç›ˆæ­¢æŸ",
            "å®Œæ•´çš„é‡åŒ–æŠ•ç ”æ¡†æ¶"
        ],
        "ç”Ÿæˆæ–‡ä»¶": {
            "æ¨¡å‹æ¶æ„å›¾": architecture_path,
            "è®­ç»ƒè¿‡ç¨‹æ¨¡æ‹Ÿ": training_path,
            "ä¸šç»©é¢„æœŸåˆ†æ": performance_path
        },
        "å®æ–½å»ºè®®": [
            "ç¡®ä¿GPUèµ„æºå……è¶³ä»¥æé«˜è®­ç»ƒæ•ˆç‡",
            "å®šæœŸé‡æ–°è®­ç»ƒä»¥é€‚åº”å¸‚åœºå˜åŒ–",
            "ç»“åˆå¤šå› å­æ¨¡å‹æå‡é¢„æµ‹ç²¾åº¦",
            "åŠ å…¥é£é™©ç®¡ç†æ¨¡å—æ§åˆ¶å›æ’¤",
            "å»ºç«‹å®æ—¶ç›‘æ§ç³»ç»Ÿè·Ÿè¸ªç­–ç•¥è¡¨ç°"
        ]
    }

    # ä¿å­˜JSONæŠ¥å‘Š
    report_path = "alstm_analysis/alstm_final_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=4)

    print(f"ğŸ“‹ æœ€ç»ˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    # æ‰“å°æŠ¥å‘Šæ‘˜è¦
    print("\n" + "=" * 80)
    print("ğŸŠ Qlib ALSTMæ¨¡å‹è®­ç»ƒä¸åˆ†æå®Œæˆ")
    print("=" * 80)

    print(f"\nğŸ“Š é¡¹ç›®ä¿¡æ¯:")
    print(f"   â€¢ åˆ†ææ—¶é—´: {report['é¡¹ç›®æ¦‚è¿°']['åˆ†ææ—¶é—´']}")
    print(f"   â€¢ æ•°æ®èŒƒå›´: {report['é¡¹ç›®æ¦‚è¿°']['åˆ†æèŒƒå›´']}")
    print(f"   â€¢ é…ç½®æ–‡ä»¶: {os.path.basename(report['é¡¹ç›®æ¦‚è¿°']['é…ç½®æ–‡ä»¶'])}")

    print(f"\nğŸ§  æ¨¡å‹é…ç½®:")
    print(f"   â€¢ æ¨¡å‹ç±»å‹: {report['æ¨¡å‹é…ç½®']['æ¨¡å‹ç±»å‹']}")
    print(f"   â€¢ ç‰¹å¾ç»´åº¦: {report['æ¨¡å‹é…ç½®']['ç‰¹å¾ç»´åº¦']}")
    print(f"   â€¢ æ—¶é—´çª—å£: {report['æ¨¡å‹é…ç½®']['æ—¶é—´çª—å£']}å¤©")

    print(f"\nğŸ“ˆ ä¸šç»©é¢„æœŸ:")
    print(f"   â€¢ å¹´åŒ–æ”¶ç›Šç‡: {report['ä¸šç»©é¢„æœŸ']['å¹´åŒ–æ”¶ç›Šç‡']}")
    print(f"   â€¢ è¶…é¢æ”¶ç›Š: {report['ä¸šç»©é¢„æœŸ']['è¶…é¢æ”¶ç›Š']}")
    print(f"   â€¢ å¤æ™®æ¯”ç‡: {report['ä¸šç»©é¢„æœŸ']['å¤æ™®æ¯”ç‡']}")
    print(f"   â€¢ æœ€å¤§å›æ’¤: {report['ä¸šç»©é¢„æœŸ']['æœ€å¤§å›æ’¤']}")

    print(f"\nğŸ’¼ ç­–ç•¥é…ç½®:")
    print(f"   â€¢ é€‰è‚¡ç­–ç•¥: {report['äº¤æ˜“ç­–ç•¥']['é€‰è‚¡ç­–ç•¥']}")
    print(f"   â€¢ æŒä»“æ•°é‡: {report['äº¤æ˜“ç­–ç•¥']['æŒä»“æ•°é‡']}åª")
    print(f"   â€¢ åˆå§‹èµ„é‡‘: {report['äº¤æ˜“ç­–ç•¥']['åˆå§‹èµ„é‡‘']}")

    print(f"\nğŸ”¬ æŠ€æœ¯äº®ç‚¹:")
    for i, advantage in enumerate(report['æŠ€æœ¯ä¼˜åŠ¿'], 1):
        print(f"   {i}. {advantage}")

    print(f"\nğŸ“ ç”Ÿæˆæ–‡ä»¶:")
    for key, value in report['ç”Ÿæˆæ–‡ä»¶'].items():
        print(f"   â€¢ {key}: {value}")

    print(f"\nğŸ’¡ å®æ–½å»ºè®®:")
    for i, suggestion in enumerate(report['å®æ–½å»ºè®®'], 1):
        print(f"   {i}. {suggestion}")

    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨å’ŒæŠ¥å‘Šæ–‡ä»¶")
    print("=" * 80)

    return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨Qlib ALSTMæ¨¡å‹é…ç½®åˆ†æ")

    try:
        # 1. åˆ†æALSTMé…ç½®
        config = analyze_alstm_config()
        if not config:
            print("âŒ é…ç½®åˆ†æå¤±è´¥")
            return

        # 2. åˆ›å»ºæ¨¡å‹æ¶æ„å›¾
        architecture_path = create_model_architecture_diagram()

        # 3. åˆ›å»ºè®­ç»ƒè¿‡ç¨‹æ¨¡æ‹Ÿ
        training_path = create_training_simulation()

        # 4. åˆ›å»ºä¸šç»©é¢„æœŸåˆ†æ
        performance_path = create_performance_projection()

        # 5. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        report = generate_final_report(config, architecture_path, training_path, performance_path)

        print("\nğŸŠ æ‰€æœ‰åˆ†æå·²å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœç›®å½•: alstm_analysis/")
        print("ğŸ“Š åŒ…å«æ–‡ä»¶:")
        print("   â€¢ alstm_architecture_analysis.png - æ¨¡å‹æ¶æ„å›¾")
        print("   â€¢ alstm_training_simulation.png - è®­ç»ƒè¿‡ç¨‹æ¨¡æ‹Ÿ")
        print("   â€¢ alstm_performance_projection.png - ä¸šç»©é¢„æœŸåˆ†æ")
        print("   â€¢ alstm_final_report.json - å®Œæ•´åˆ†ææŠ¥å‘Š")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()