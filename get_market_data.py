#!/usr/bin/env python3
"""
è·å–ä¸Šè¯æŒ‡æ•°å’Œæ²ªæ·±300æˆåˆ†è‚¡è¿‘äº”å¹´æ—¥çº¿æ•°æ®

ä½¿ç”¨TuShareæ•°æ®æºè·å–ï¼š
1. ä¸Šè¯æŒ‡æ•°(000001.SH)è¿‘äº”å¹´æ—¥çº¿æ•°æ®
2. æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨åŠè¿‘äº”å¹´æ—¥çº¿æ•°æ®
3. å°†æ•°æ®ä¿å­˜ä¸ºqlibå¯ç”¨çš„æ ¼å¼
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ Qlibè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

from qlib import init
from qlib.data import D
from qlib.contrib.data.tushare import TuShareConfig, TuShareProvider
from qlib.contrib.data.tushare.utils import TuShareCodeConverter, TuShareDateUtils

# è®¾ç½®TuShare Token
TUSHARE_TOKEN = "eb13b3bfd2bd07fd9eb40234f19941c73f230e1e98cc212b8cd407c7"

def get_date_range():
    """è·å–è¿‘äº”å¹´çš„æ—¥æœŸèŒƒå›´"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=5*365)  # è¿‘5å¹´

    # è½¬æ¢ä¸ºTuShareæ ¼å¼ (YYYYMMDD)
    start_date_tushare = start_date.strftime('%Y%m%d')
    end_date_tushare = end_date.strftime('%Y%m%d')

    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ (YYYY-MM-DD)
    start_date_std = start_date.strftime('%Y-%m-%d')
    end_date_std = end_date.strftime('%Y-%m-%d')

    return start_date_tushare, end_date_tushare, start_date_std, end_date_std

def get_shanghai_index_data():
    """è·å–ä¸Šè¯æŒ‡æ•°è¿‘äº”å¹´æ—¥çº¿æ•°æ®"""
    print("=" * 60)
    print("ğŸ“ˆ è·å–ä¸Šè¯æŒ‡æ•°(000001.SH)è¿‘äº”å¹´æ—¥çº¿æ•°æ®")
    print("=" * 60)

    try:
        # ç›´æ¥ä½¿ç”¨tushareè·å–æ•°æ®
        import tushare as ts
        ts.set_token(TUSHARE_TOKEN)
        pro = ts.pro_api()

        # è·å–æ—¥æœŸèŒƒå›´
        start_date_tushare, end_date_tushare, start_date_std, end_date_std = get_date_range()
        print(f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {start_date_std} è‡³ {end_date_std}")

        # è·å–ä¸Šè¯æŒ‡æ•°æ—¥çº¿æ•°æ®
        print("ğŸ“Š è·å–ä¸Šè¯æŒ‡æ•°æ•°æ®...")

        # è·å–æŒ‡æ•°æ—¥çº¿æ•°æ®
        index_df = pro.index_daily(
            ts_code="000001.SH",
            start_date=start_date_tushare,
            end_date=end_date_tushare
        )

        if not index_df.empty:
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            index_df['trade_date'] = pd.to_datetime(index_df['trade_date'])
            index_df = index_df.sort_values('trade_date')

            # é‡ç½®ç´¢å¼•ä¸ºæ—¥æœŸ
            index_df.set_index('trade_date', inplace=True)

            # é€‰æ‹©éœ€è¦çš„åˆ—å¹¶é‡å‘½å
            index_data = index_df[['open', 'high', 'low', 'close', 'vol', 'amount']].copy()
            index_data.columns = ['open', 'high', 'low', 'close', 'volume', 'amount']

            print(f"âœ… ä¸Šè¯æŒ‡æ•°æ•°æ®è·å–æˆåŠŸ")
            print(f"   æ•°æ®å½¢çŠ¶: {index_data.shape}")
            print(f"   æ—¶é—´èŒƒå›´: {index_data.index[0]} è‡³ {index_data.index[-1]}")

            # æ˜¾ç¤ºæ•°æ®æ ·æœ¬
            print("\nğŸ“‹ æ•°æ®æ ·æœ¬:")
            print(index_data.tail())

            # ä¿å­˜æ•°æ®
            output_file = "shanghai_index_5years.csv"
            index_data.to_csv(output_file)
            print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {output_file}")

            return index_data
        else:
            print("âŒ æœªè·å–åˆ°ä¸Šè¯æŒ‡æ•°æ•°æ®")
            return None

    except Exception as e:
        print(f"âŒ è·å–ä¸Šè¯æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        return None

def get_csi300_stocks_data():
    """è·å–æ²ªæ·±300æˆåˆ†è‚¡åŠè¿‘äº”å¹´æ—¥çº¿æ•°æ®"""
    print("\n" + "=" * 60)
    print("ğŸ“Š è·å–æ²ªæ·±300æˆåˆ†è‚¡è¿‘äº”å¹´æ—¥çº¿æ•°æ®")
    print("=" * 60)

    try:
        # ç›´æ¥ä½¿ç”¨tushareè·å–æ•°æ®
        import tushare as ts
        ts.set_token(TUSHARE_TOKEN)
        pro = ts.pro_api()

        # è·å–æ—¥æœŸèŒƒå›´
        start_date_tushare, end_date_tushare, start_date_std, end_date_std = get_date_range()

        print("ğŸ” è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨...")

        # è·å–æ²ªæ·±300æˆåˆ†è‚¡
        try:
            # è·å–æ²ªæ·±300æŒ‡æ•°æˆåˆ†è‚¡
            index_cons_df = pro.index_cons(
                ts_code="000300.SH",  # æ²ªæ·±300æŒ‡æ•°ä»£ç 
                start_date=start_date_tushare,
                end_date=end_date_tushare
            )

            if not index_cons_df.empty:
                # è·å–å”¯ä¸€çš„è‚¡ç¥¨ä»£ç 
                stock_codes = index_cons_df['con_code'].unique().tolist()
                print(f"âœ… æ²ªæ·±300æˆåˆ†è‚¡æ•°é‡: {len(stock_codes)}")

                # æ˜¾ç¤ºå‰10åªè‚¡ç¥¨
                sample_stocks = stock_codes[:10]
                print(f"   å‰10åªè‚¡ç¥¨: {sample_stocks}")
            else:
                print("âš ï¸ æœªèƒ½è·å–æ²ªæ·±300æˆåˆ†è‚¡ï¼Œä½¿ç”¨ç¤ºä¾‹è‚¡ç¥¨")
                # ä½¿ç”¨ä¸€äº›ä¸»è¦çš„æ²ªæ·±300æˆåˆ†è‚¡ä½œä¸ºç¤ºä¾‹
                stock_codes = [
                    "000001.SZ", "000002.SZ", "000858.SZ", "002415.SZ", "002594.SZ",
                    "600000.SH", "600036.SH", "600519.SH", "600887.SH", "601318.SH",
                    "601398.SH", "601857.SH", "601988.SH", "603259.SH", "000063.SZ"
                ]
                print(f"   ä½¿ç”¨ç¤ºä¾‹è‚¡ç¥¨: {len(stock_codes)} åª")

        except Exception as e:
            print(f"âš ï¸ è·å–æ²ªæ·±300æˆåˆ†è‚¡å¤±è´¥: {e}")
            print("   ä½¿ç”¨ç¤ºä¾‹è‚¡ç¥¨")
            stock_codes = [
                "000001.SZ", "000002.SZ", "000858.SZ", "002415.SZ", "002594.SZ",
                "600000.SH", "600036.SH", "600519.SH", "600887.SH", "601318.SH"
            ]

        # åˆ†æ‰¹è·å–æ•°æ®ï¼ˆé¿å…APIé™åˆ¶ï¼‰
        all_data = []
        batch_size = 5  # æ¯æ‰¹5åªè‚¡ç¥¨ï¼Œå‡å°‘APIå‹åŠ›

        print(f"\nğŸ“ˆ å¼€å§‹è·å–æ—¥çº¿æ•°æ® (æ¯æ‰¹ {batch_size} åªè‚¡ç¥¨)...")

        for i in range(0, len(stock_codes), batch_size):
            batch_stocks = stock_codes[i:i+batch_size]
            print(f"   å¤„ç†ç¬¬ {i//batch_size + 1} æ‰¹: {batch_stocks}")

            batch_data_list = []
            for stock_code in batch_stocks:
                try:
                    # è·å–å•åªè‚¡ç¥¨æ—¥çº¿æ•°æ®
                    stock_df = pro.daily(
                        ts_code=stock_code,
                        start_date=start_date_tushare,
                        end_date=end_date_tushare
                    )

                    if not stock_df.empty:
                        # æ·»åŠ è‚¡ç¥¨ä»£ç 
                        stock_df['instrument'] = stock_code
                        # è½¬æ¢æ—¥æœŸæ ¼å¼
                        stock_df['trade_date'] = pd.to_datetime(stock_df['trade_date'])
                        batch_data_list.append(stock_df)
                        print(f"     âœ… {stock_code}: {stock_df.shape[0]} å¤©æ•°æ®")
                    else:
                        print(f"     âš ï¸ {stock_code}: æ— æ•°æ®")

                except Exception as e:
                    print(f"     âŒ {stock_code}: è·å–å¤±è´¥ - {e}")
                    continue

                # é¿å…APIé¢‘ç‡é™åˆ¶
                import time
                time.sleep(0.5)  # æ¯åªè‚¡ç¥¨é—´éš”0.5ç§’

            if batch_data_list:
                batch_data = pd.concat(batch_data_list, ignore_index=True)
                # è®¾ç½®å¤šçº§ç´¢å¼•
                batch_data.set_index(['instrument', 'trade_date'], inplace=True)
                all_data.append(batch_data)
                print(f"     âœ… æ‰¹æ¬¡åˆå¹¶: {batch_data.shape}")

            # æ‰¹æ¬¡é—´ç­‰å¾…
            if i + batch_size < len(stock_codes):
                print("     â³ ç­‰å¾…2ç§’é¿å…APIé™åˆ¶...")
                time.sleep(2)

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if all_data:
            csi300_data = pd.concat(all_data, ignore_index=False)
            # é‡å‘½ååˆ—ä»¥åŒ¹é…æ ‡å‡†æ ¼å¼
            csi300_data.rename(columns={'vol': 'volume'}, inplace=True)

            # é€‰æ‹©éœ€è¦çš„åˆ—
            csi300_data = csi300_data[['open', 'high', 'low', 'close', 'volume', 'amount']]

            print(f"\nâœ… æ²ªæ·±300æ•°æ®åˆå¹¶å®Œæˆ")
            print(f"   æ€»æ•°æ®å½¢çŠ¶: {csi300_data.shape}")
            print(f"   è‚¡ç¥¨æ•°é‡: {csi300_data.index.get_level_values(0).nunique()}")
            print(f"   äº¤æ˜“æ—¥æœŸ: {csi300_data.index.get_level_values(1).nunique()} å¤©")

            # æ˜¾ç¤ºæ•°æ®æ ·æœ¬
            print("\nğŸ“‹ æ•°æ®æ ·æœ¬:")
            print(csi300_data.head(10))

            # ä¿å­˜æ•°æ®
            output_file = "csi300_stocks_5years.csv"
            csi300_data.to_csv(output_file)
            print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {output_file}")

            return csi300_data
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ²ªæ·±300æ•°æ®")
            return None

    except Exception as e:
        print(f"âŒ è·å–æ²ªæ·±300æ•°æ®å¤±è´¥: {e}")
        return None

def convert_to_qlib_format(data, filename_prefix):
    """å°†æ•°æ®è½¬æ¢ä¸ºQlibæ ‡å‡†æ ¼å¼"""
    print("\n" + "=" * 60)
    print("ğŸ”„ è½¬æ¢æ•°æ®ä¸ºQlibæ ‡å‡†æ ¼å¼")
    print("=" * 60)

    if data is None or data.empty:
        print("âŒ æ²¡æœ‰æ•°æ®éœ€è¦è½¬æ¢")
        return

    try:
        # é‡ç½®ç´¢å¼•
        if data.index.nlevels > 1:
            data_flat = data.reset_index()
            # é‡å‘½ååˆ—
            data_flat.columns = ['instrument', 'date'] + list(data_flat.columns[2:])
        else:
            data_flat = data.reset_index()
            data_flat.columns = ['date'] + list(data_flat.columns[1:])
            data_flat['instrument'] = data_flat['date']  # ä¸´æ—¶åˆ—ï¼Œåé¢ä¼šæ›¿æ¢

        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        data_flat['date'] = pd.to_datetime(data_flat['date']).dt.strftime('%Y-%m-%d')

        # æŒ‰Qlibæ ¼å¼ä¿å­˜
        qlib_file = f"{filename_prefix}_qlib_format.csv"
        data_flat.to_csv(qlib_file, index=False)

        print(f"âœ… æ•°æ®å·²è½¬æ¢ä¸ºQlibæ ¼å¼")
        print(f"   è¾“å‡ºæ–‡ä»¶: {qlib_file}")
        print(f"   æ•°æ®å½¢çŠ¶: {data_flat.shape}")
        print(f"   åˆ—å: {list(data_flat.columns)}")

        return data_flat

    except Exception as e:
        print(f"âŒ æ•°æ®æ ¼å¼è½¬æ¢å¤±è´¥: {e}")
        return None

def generate_summary_report(index_data, csi300_data):
    """ç”Ÿæˆæ•°æ®è·å–æ€»ç»“æŠ¥å‘Š"""
    print("\n" + "=" * 80)
    print("ğŸ“Š æ•°æ®è·å–æ€»ç»“æŠ¥å‘Š")
    print("=" * 80)

    # è·å–æ—¥æœŸèŒƒå›´
    start_date_tushare, end_date_tushare, start_date_std, end_date_std = get_date_range()

    print(f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {start_date_std} è‡³ {end_date_std}")
    print(f"ğŸ“… æ€»äº¤æ˜“æ—¥: çº¦ {5*365} å¤©")

    if index_data is not None and not index_data.empty:
        print(f"\nğŸ“ˆ ä¸Šè¯æŒ‡æ•°(000001.SH):")
        print(f"   âœ… æ•°æ®è·å–æˆåŠŸ")
        print(f"   ğŸ“Š æ•°æ®å½¢çŠ¶: {index_data.shape}")
        if index_data.index.nlevels > 1:
            trading_days = index_data.index.get_level_values(1).nunique()
            print(f"   ğŸ“… äº¤æ˜“å¤©æ•°: {trading_days}")

        # æ˜¾ç¤ºæœ€æ–°ä»·æ ¼ä¿¡æ¯
        if not index_data.empty:
            latest_data = index_data.iloc[-1]
            if 'close' in latest_data:
                latest_close = latest_data['close']
                print(f"   ğŸ’° æœ€æ–°æ”¶ç›˜ä»·: {latest_close:.2f}")

    if csi300_data is not None and not csi300_data.empty:
        print(f"\nğŸ“Š æ²ªæ·±300æˆåˆ†è‚¡:")
        print(f"   âœ… æ•°æ®è·å–æˆåŠŸ")
        print(f"   ğŸ“Š æ•°æ®å½¢çŠ¶: {csi300_data.shape}")

        if csi300_data.index.nlevels > 1:
            stock_count = csi300_data.index.get_level_values(0).nunique()
            trading_days = csi300_data.index.get_level_values(1).nunique()
            print(f"   ğŸ¢ è‚¡ç¥¨æ•°é‡: {stock_count}")
            print(f"   ğŸ“… äº¤æ˜“å¤©æ•°: {trading_days}")
            print(f"   ğŸ“ˆ æ€»æ•°æ®ç‚¹: {stock_count * trading_days:,}")

    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    output_files = []
    if index_data is not None:
        output_files.append("shanghai_index_5years.csv")
        output_files.append("shanghai_index_5years_qlib_format.csv")

    if csi300_data is not None:
        output_files.append("csi300_stocks_5years.csv")
        output_files.append("csi300_stocks_5years_qlib_format.csv")

    for file in output_files:
        if os.path.exists(file):
            file_size = os.path.getsize(file) / 1024 / 1024  # MB
            print(f"   ğŸ“„ {file} ({file_size:.2f} MB)")

    print(f"\nğŸ‰ æ•°æ®è·å–ä»»åŠ¡å®Œæˆï¼")
    print(f"   ğŸ’¡ æç¤º: æ•°æ®å·²ä¿å­˜ä¸ºCSVæ ¼å¼ï¼Œå¯ç›´æ¥ç”¨äºQlibé‡åŒ–åˆ†æ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¸Šè¯æŒ‡æ•°å’Œæ²ªæ·±300æˆåˆ†è‚¡è¿‘äº”å¹´æ—¥çº¿æ•°æ®è·å–")
    print("=" * 80)

    # æ£€æŸ¥TuShare Token
    if not TUSHARE_TOKEN:
        print("âŒ æœªè®¾ç½®TuShare Token")
        print("   è¯·åœ¨ä»£ç ä¸­è®¾ç½®æ­£ç¡®çš„TUSHARE_TOKEN")
        return

    print(f"ğŸ”‘ TuShare Token: {TUSHARE_TOKEN[:10]}...{TUSHARE_TOKEN[-4:]}")

    # è·å–ä¸Šè¯æŒ‡æ•°æ•°æ®
    index_data = get_shanghai_index_data()

    # è·å–æ²ªæ·±300æˆåˆ†è‚¡æ•°æ®
    csi300_data = get_csi300_stocks_data()

    # è½¬æ¢ä¸ºQlibæ ¼å¼
    if index_data is not None:
        convert_to_qlib_format(index_data, "shanghai_index_5years")

    if csi300_data is not None:
        convert_to_qlib_format(csi300_data, "csi300_stocks_5years")

    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_summary_report(index_data, csi300_data)

if __name__ == "__main__":
    main()